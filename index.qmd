---
title: "EDUC 6003 Advanced Statistics"
author: "Hammed Akande"
format: html
editor: visual
---

# Chapter 1- Reliability Index Analysis

## Introduction to Reliability Index Analysis

This tutorial will serve as a Guide to Enhanced Reliability Estimation with R

### What is Reliability?

Reliability refers to the consistency and precision of measurement instruments. In psychological testing, it assesses the extent to which a test produces stable and consistent results.

#### Importance of Reliability

*Measurement Precision*: Ensures that the scores accurately reflect the true attributes being measured.

*Research Validity*: High reliability is a prerequisite for valid conclusions and replicable research findings.

*Error Reduction*: Minimizes the impact of random errors, enhancing the clarity of observed relationships between constructs.

#### Types of Reliability

*Internal Consistency*: Degree to which items within a test measure the same construct.

*Test-Retest Reliability*: Consistency of scores over time.

*Inter-Rater Reliability*: Agreement between different raters or observers.

## Classical Test Theory (CTT) and Coefficient Alpha

Classical Test Theory Overview: CTT posits that each observed score is composed of a true score and an error score:

$$ X = T + E $$

where:

ùëã= Observed score ùëá= True score ùê∏= Error score

### Coefficient Alpha (Cronbach's Alpha)

This is a widely used measure of internal consistency reliability within CTT. It estimates the extent to which items on a test measure the same underlying construct.

$$
\alpha = \frac{N}{N-1} \left(1 - \frac{\sum \sigma^2_{E}}{\sigma^2_{X}}\right)
$$

Where:

$\alpha$ = Cronbach's Alpha

ùëÅ = Number of items in the test

$\sigma^2_{E}$ = Variance of the error scores

$\sigma^2_{X}$ = Variance of the observed total scores

#### Assumptions of Alpha

*Unidimensionality*: All items measure a single construct.

*Tau Equivalence*: Each item has the same true score variance.

*Independence of Errors*: Error terms are uncorrelated across items.

#### Limitations of Alpha

*Sensitivity to Tau Equivalence*: Violations can lead to underestimation or overestimation of reliability.

*Assumes Unidimensionality*: Not suitable for multidimensional scales without adjustments.

*Ignores Factor Structure*: Does not account for the underlying factor model of the test.

### Coefficient Omega

Coefficient Omega is a more robust alternative to Cronbach's Alpha, especially when the assumption of tau-equivalence (equal factor loadings) is violated. Omega takes into account the factor structure of the test, making it suitable for both unidimensional and multidimensional scales.

#### Types of Omega

*Omega Total (œâ‚Çú*): Accounts for all common factors, both general and specific.

*Omega Hierarchical (œâ‚Çï)*: Represents the proportion of variance attributable to a general factor alone.

Omega Total is given by:

$$
\omega_t = \frac{\sum_{i=1}^{k} \lambda_i}{\sum_{i=1}^{k} \lambda_i + \sum_{i=1}^{k} \theta_i}
$$

Where:

$\omega_t$ = Omega Total

$\lambda_i$ = Factor loading for item

$\theta_i$ = Unique variance (error variance) for item

$k$ = Total number of items

For a hierarchical model, Omega Hierarchical is:

$$
\omega_h = \frac{\lambda_g^2}{\lambda_g^2 + \sum_{i=1}^{k} \theta_i}
$$

where:

$\omega_h$ = Omega Hierarchical

$\lambda_g$ = Factor loading of the general factor

$\theta_i$ = Unique variance for item $i$

#### Advantages of Omega Over Alpha

*Factor Structure Incorporation*: Utilizes confirmatory factor analysis (CFA) to model the underlying structure.

*Less Sensitive to Tau Equivalence Violations*: Provides more accurate reliability estimates when tau equivalence is not met.

*Applicability to Multidimensional Scales*: Suitable for tests measuring multiple constructs.

## Calculations in R

Here, I will walk through the step-by-step process of calculating Cronbach's Alpha and Coefficient Omega using R.

Load the necessary packages.

```{r}

pacman::p_load(psych,lavaan,semTools,tidyverse,semTools,psych,tidyverse,lavaan,rio,parameters,
               nFactors,EGAnet,PCDimension)

```

## Loading the (BFI) dataset

The Big Five Inventory (BFI) is a widely used dataset in personality psychology, measuring the five major dimensions of personality. We'll focus on the Openness trait for this tutorial.

```{r}

# Make sure you've loaded the psych package


# Load the BFI dataset
data(bfi)

# load data file
bfi <- bfi
names(bfi)

# View the structure of the dataset
#str(bfi)




```

The dataset contains 2,800 participants with various demographic and personality-related variables. A1 to A5 correspond to items measuring the Openness trait.

### Selecting Openness Items

For this tutorial, we'll focus on five items measuring the Openness trait. These items are typically labeled as A1 to A5 in the BFI dataset.

#### a. Extracting Openness Items

```{r}

# Select columns that contain "O" in their names and remove rows with NA values
oppeness <- bfi %>%
  select(matches("^O")) %>%
  drop_na()

head(oppeness)

```

Each A variable represents a Likert-type item measuring Openness. Responses range from 1 to 6, treated as continuous variables for analysis.

### Handling Missing Data

Before we continue, let's check any missing data.

```{r}

# Check for missing values
sum(is.na(oppeness))


```

In this dataset, there are no missing values in the Openness items. If missing values were present, then we need to address that.

## Calculating Cronbach's Alpha

Recall that Cronbach's Alpha (Œ±) is a measure of internal consistency that measures how closely related a set of items are as a group.

### a. We can use the psych Package in R

```{r}

# Calculate Cronbach's Alpha using the psych package
#alpha_result <- psych::alpha(oppeness)

# Print the result
#print(alpha_result)



```

Because some items were negatively correlated with the first principal component, we probably should reverse them.

```{r}

# Reversing item O2 and O5

q <- c("O2","O5")
reverse <- function(x){
  x.reversed <- 7 +0 - x
}

oppeness[, c("O2R", "O5R")] <- reverse(oppeness[,c("O2","O5")])

# compare original and reversed responses
oppeness[1:6,]

```

Now, we can compute the alpha

```{r}

# compute alpha coefficient 

alpha_result <- psych::alpha(oppeness[, -c(2,5)])

# Print the result
print(alpha_result)


```

Explanation:

raw_alpha: The Cronbach's Alpha coefficient.

std.alpha: Standardized alpha, similar to raw_alpha.

G6(smc): Generalizability theory estimate with squared multiple correlations.

average_r: Average inter-item correlation.

S/N: Signal-to-noise ratio.

ase: Asymptotic standard error.

Confidence Intervals: Lower and upper bounds for alpha.

As we can see, the Cronbach's Alpha for the Openness items is 0.6, indicating strong internal consistency. The average inter-item correlation is 0.24, moderate and within psychological scales.

## Confirmatory Factor Analysis (CFA)

Confirmatory Factor Analysis (CFA) is used to verify the factor structure of a set of observed variables. In our case, we assume a unidimensional structure.

### a. Specifying the CFA Model

Let's specify a one-factor model where all items load on a single latent factor.

```{r}

# Specify model
mod1f <- "
openness =~ O1 + O2R + O3 + O4 + O5R
"

```

### b. Fitting the CFA Model

Fit the Model Using lavaan:

```{r}
#pacman::p_load(lavaan)
# Estimate model
fit.one.f <- cfa(mod1f, data=oppeness, std.lv=T, missing='direct', 
             estimator='MLR')

# The results can be viewed using the summary

summary(fit.one.f, fit.measures=T, standardized=T)



```

Explanation:

Estimator: Maximum Likelihood (ML).

Test Statistics: The Chi-square test is significant (ùëù\<0.001), indicating a poor fit.

Fit Indices:

CFI (0.94): above 0.90.

TLI (0.88): Below the threshold of 0.90.

RMSEA (0.068): Indicates relatively weak fit (‚â•0.05).

SRMR (0.029): Great fit (‚â§0.08).

```{r}

residuals(fit.one.f, type='cor')

```

The fit statistics from the Robust column in the summary suggest that this one-factor model provides a moderate fit to the data. While the Comparative Fit Index (CFI) of 0.94 indicates an acceptable fit, the Tucker-Lewis Index (TLI) of 0.88 is relatively lower, and the Root Mean Square Error of Approximation (RMSEA) is relatively high at 0.08.

The factor loadings (ùúÜÃÇ) show significant variation, ranging from 0.357 to 0.792, which implies that the assumption of equal loadings (tau equivalence) does not hold for this openness test. As a result, omega (œâu) should be a more suitable measure of reliability than Cronbach's alpha. We can compute the œâu estimate by running the `reliability` function from the semTools package on the one-factor model object (`fit1f`).

```{r}

reliability(fit.one.f)

```

`omega` and `omega2` measure reliability based on the variance expected by the model, while `omega3` measures it based on the actual variance seen in your data. The small difference between `omega` and `omega3` suggests that the model's predictions of variance are somewhat close to what‚Äôs observed in the sample.

## Calculating Categorical Omega

Recall that Coefficient Omega (œâ) is a reliability estimate that accounts for the factor structure of the test, providing a more accurate measure than Cronbach's Alpha, especially in the presence of multidimensionality or when tau-equivalence is violated.

Since factor loadings derived from polychoric correlations represent the link between the factor and the underlying latent response variables (not the actual responses from the items), using the œâu formula here would tell us how much of the variance in the latent response variables is explained by the factor. However, this doesn‚Äôt reflect the true variance in the sum of the observed item responses. Essentially, in this case, œâu would give us the reliability of a hypothetical total score based on the latent variables rather than the actual observed total score.

To correct for this, Green and Yang (2009b) proposed a new reliability estimate called œâu-cat, which adjusts the reliability calculation to align with the observed total score. This estimate is more accurate for unidimensional scales with categorical items, especially when the response patterns vary across items.

Since the psychoticism items use a 4-point rating scale, I fit the one-factor model using polychoric correlations and the WLSMV estimator (weighted least squares with mean and variance adjustment). This approach is recommended for confirmatory factor analysis involving polychoric correlations, as it is more robust than the maximum likelihood (ML) estimator.

```{r}
#load the data
potic <- import("potic.csv")

# Specify model
mod.one.fCat <- 'psyctcsm =~ DDP1 + DDP2 +
DDP3 + DDP4'


# Estimate model
fit.one.fCat <- cfa(mod.one.fCat, data=potic, std.lv=TRUE, ordered=T, estimator='WLSMV')

# Retrieving the results
summary(fit.one.fCat, fit.measures=TRUE, standardized=TRUE)


```

```{r}

# Estimate reliability

reliability(fit.one.fCat)


```

We can see that we have two estimates Cronbach‚Äôs alpha and differ a bit (0.80 & 0.77). The is because the 2nd alpha estimate is an example of ordinal alpha, which is calculated using a model based on polychoric correlations, while the first alpha was derived using the standard method based on product-moment covariances between the items. It's important to note that ordinal alpha measures the reliability of the sum of the continuous, latent-response variables rather than the observed categorical item responses. Additionally, it still assumes equal factor loadings (tau equivalence). Because of these limitations, I suggest disregarding the alpha value reported by semTools::reliability when the model uses polychoric correlations.

The values shown in the `omega` and `omega2` rows represent the œâu-cat estimate. The `omega3` row shows a variation where the denominator uses the observed sample variance of ( X ). So, we can see œâu-cat estimates suggest that 79% of the variance in the total score for the psychoticism scale is explained by the single psychoticism factor.

## Bifactor Models

A bifactor model is a useful way to represent a multidimensional structure. In this model, there‚Äôs a general factor that affects all items, while additional specific factors (or group factors) explain the relationships (covariation) between certain subsets of items beyond what the general factor accounts for.

For the model to work correctly, the general factor needs to be uncorrelated with the specific factors. In contrast to other Confirmatory Factor Analysis (CFA) models where all factors can correlate freely, allowing the general factor to correlate with a specific factor in a bifactor model can lead to issues like non-convergence or incorrect solutions.

### Omega Hierarchical (œâh)

When data fits well with a bifactor model, a reliability metric called **omega hierarchical (**$œâ_h$) is used. This measure reflects how much of the total score's variance is attributable to the single general factor, even though the data involves multiple dimensions.

Here, let's demonstrate the estimation of $œâ_h$ using R, I use data that from Flake, Ferland, & Flora, 2017 collected by administering the PCS to 154 students in an introductory statistics course.

```{r}
pcs <- import("pcs.csv")
names(pcs)

```

```{r}

modBf <- "
gen =~ TE1+TE2+TE3+TE4+TE5+OE1+OE2+OE3+OE4+LVA1+LVA2+LVA3+LVA4 +EM1+EM2+EM3+EM4+EM5+EM6
s1 =~ TE1 + TE2 + TE3 + TE4 + TE5
s2 =~ OE1 + OE2 + OE3 + OE4
s3 =~ LVA1 + LVA2 + LVA3 + LVA4
s4 =~ EM1 + EM2 + EM3 + EM4 + EM5 + EM6
"

#Specify model
fitBf <- cfa(modBf, data=pcs, std.lv=T, estimator='MLR', orthogonal=T)

#Retrieving the results
summary(fitBf, fit.measures=TRUE, standardized=T)

```

```{r}

fitmeasures(fitBf)

```

From the results above, we can the bifactor model fits the PCS data well, with robust model-fit statistics, CFI = 0.978, TLI = 0.972, RMSEA = 0.053. Thus, it is reasonable to calculate $œâ_h$ to estimate how reliably the PCS total score measures the general psychological-cost factor.

```{r}

reliability(fitBf)

```

The values shown under the "gen" column relate to the general psychological cost factor. The omega estimate (0.974) doesn‚Äôt take the specific factors into account when calculating the variance of the total score, so it‚Äôs not the appropriate reliability measure for the PCS total score. Instead, the **omega2** and **omega3** values under "gen" represent **omega hierarchical (**$œâ_h$). The difference between them is that **omega2** uses the model-implied variance of the total score, while **omega3** relies on the observed variance from the sample.

In simple terms, both $œâ_h$ values tell us that **91% of the variance in the PCS total score** is explained by the general psychological cost factor, after accounting for the specific factors that influence different content areas.

### Higher-Order Models

In the bifactor model example, I treated the multidimensional nature of the PCS items as a distraction when measuring a broad, general psychological cost construct. However, in other cases, researchers may propose a different structure where a broad overarching factor indirectly influences all the test items by acting through more specific, narrower constructs that directly affect different subsets of items. This kind of setup suggests a **higher-order model**, where a higher-order (or second-order) factor drives differences in several lower-order (first-order) factors, which, in turn, influence the individual item responses.

In this model, researchers assess how well the test captures both the overall score (reflecting the broad higher-order construct) and the subscale scores (reflecting the more specific lower-order constructs).

When the data fit a higher-order model, the reliability of the total score is measured by **omega-higher-order (**$œâ_{ho}$), which represents the proportion of the total score‚Äôs variance that can be attributed to the higher-order factor. The calculation of œâho uses parameter estimates from the higher-order model.

```{r}
#Specify the higher-order factor model for the PCS items

homod <- 'TE =~ TE1 + TE2 + TE3 + TE4 + TE5 
      OE =~ OE1 + OE2 + OE3 + OE4
      LV =~ LVA1 + LVA2 + LVA3 + LVA4
      EM =~ EM1 + EM2 + EM3 + EM4 + EM5 + EM6
      cost =~ TE + OE + LV + EM'
```

```{r}

#Estimate the model and get the results
fitHo <- cfa(homod, data=pcs, std.lv=T, estimator='MLM')
summary(fitHo, fit.measures=T)

```

#### Let's obtain omega-ho from a higher-order model for the Psychological Cost Scale

```{r}

reliabilityL2(fitHo, 'cost')

```

```{r}

#Obtain omega estimates for the subscale scores as measures of the lower-order factors
reliability(fitHo)
```

## Exploratory Omega Estimates

So far, the examples have relied on semTools‚Äô `reliability` (or `reliabilityL2`) function to calculate omega estimates based on CFA models. However, these omega estimates are only valid if the underlying model for the test is correctly specified. For instance, using $œâ_u$ as a reliability estimate wouldn‚Äôt be appropriate if the true model is multidimensional, as indicated by a poor fit for a single-factor model.

When a hypothesized CFA model doesn‚Äôt adequately fit the data‚Äîwhich is common in the early stages of test development‚ÄîExploratory Factor Analysis (EFA) can help identify the test‚Äôs dimensional structure. After determining the optimal number of factors for a test, you can use the `omega` function from the **psych** package (Revelle, 2020) to estimate omega based on the EFA parameters. This estimate will reflect the proportion of total score variance attributable to a general factor that influences all items.

```{r}

#Determine number of factors

n_factors(pcs, package = "all")

```

```{r}

#Determine omega for 4 factor model
omega(pcs, nfactors = 4, plot = F)

```

The results from the exploratory factor analysis indicate that the four-factor model provides a strong fit, with an overall omega total of 0.98, suggesting excellent reliability for the total score. The omega hierarchical value of 0.85 indicates that 85% of the total-score variance is attributable to a general factor, showing that the general psychological cost factor plays a dominant role in explaining the variance across items. Additionally, the individual subscales also show good reliability, with their omega total values ranging from 0.90 to 0.94.

#Chapter 2- Regression

## Simple Linear Regression (SLR)

Linear model and Linear regression are technicall