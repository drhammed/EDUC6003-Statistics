---
title: "EDUC 6003 Advanced Statistics"
author: "Hammed Akande"
format: html
editor: visual
---

# Chapter 1

## Introduction to Reliability Index Analysis

This tutorial will serve as a Guide to Enhanced Reliability Estimation with R

### What is Reliability?

Reliability refers to the consistency and precision of measurement instruments. In psychological testing, it assesses the extent to which a test produces stable and consistent results.

#### Importance of Reliability

*Measurement Precision*: Ensures that the scores accurately reflect the true attributes being measured.

*Research Validity*: High reliability is a prerequisite for valid conclusions and replicable research findings.

*Error Reduction*: Minimizes the impact of random errors, enhancing the clarity of observed relationships between constructs.

#### Types of Reliability

*Internal Consistency*: Degree to which items within a test measure the same construct.

*Test-Retest Reliability*: Consistency of scores over time.

*Inter-Rater Reliability*: Agreement between different raters or observers.

## Classical Test Theory (CTT) and Coefficient Alpha

Classical Test Theory Overview: CTT posits that each observed score is composed of a true score and an error score:

$$ X = T + E $$

where:

ùëã= Observed score ùëá= True score ùê∏= Error score

### Coefficient Alpha (Cronbach's Alpha)

This is a widely used measure of internal consistency reliability within CTT. It estimates the extent to which items on a test measure the same underlying construct.

$$
\alpha = \frac{N}{N-1} \left(1 - \frac{\sum \sigma^2_{E}}{\sigma^2_{X}}\right)
$$

Where:

$\alpha$ = Cronbach's Alpha

ùëÅ = Number of items in the test

$\sigma^2_{E}$ = Variance of the error scores

$\sigma^2_{X}$ = Variance of the observed total scores

#### Assumptions of Alpha

*Unidimensionality*: All items measure a single construct.

*Tau Equivalence*: Each item has the same true score variance.

*Independence of Errors*: Error terms are uncorrelated across items.

#### Limitations of Alpha

*Sensitivity to Tau Equivalence*: Violations can lead to underestimation or overestimation of reliability.

*Assumes Unidimensionality*: Not suitable for multidimensional scales without adjustments.

*Ignores Factor Structure*: Does not account for the underlying factor model of the test.

### Coefficient Omega

Coefficient Omega is a more robust alternative to Cronbach's Alpha, especially when the assumption of tau-equivalence (equal factor loadings) is violated. Omega takes into account the factor structure of the test, making it suitable for both unidimensional and multidimensional scales.

#### Types of Omega

*Omega Total (œâ‚Çú*): Accounts for all common factors, both general and specific.

*Omega Hierarchical (œâ‚Çï)*: Represents the proportion of variance attributable to a general factor alone.

Omega Total is given by:

$$
\omega_t = \frac{\sum_{i=1}^{k} \lambda_i}{\sum_{i=1}^{k} \lambda_i + \sum_{i=1}^{k} \theta_i}
$$

Where:

$\omega_t$ = Omega Total

$\lambda_i$ = Factor loading for item

$\theta_i$ = Unique variance (error variance) for item

$k$ = Total number of items

For a hierarchical model, Omega Hierarchical is:

$$
\omega_h = \frac{\lambda_g^2}{\lambda_g^2 + \sum_{i=1}^{k} \theta_i}
$$

where:

$\omega_h$ = Omega Hierarchical

$\lambda_g$ = Factor loading of the general factor

$\theta_i$ = Unique variance for item $i$

#### Advantages of Omega Over Alpha

*Factor Structure Incorporation*: Utilizes confirmatory factor analysis (CFA) to model the underlying structure.

*Less Sensitive to Tau Equivalence Violations*: Provides more accurate reliability estimates when tau equivalence is not met.

*Applicability to Multidimensional Scales*: Suitable for tests measuring multiple constructs.

## Calculations in R

Here, I will walk through the step-by-step process of calculating Cronbach's Alpha and Coefficient Omega using R.

Load the necessary packages.

```{r}

pacman::p_load(psych,lavaan,semTools,tidyverse,semTools,psych,tidyverse,lavaan,rio)

```

## Loading the (BFI) dataset

The Big Five Inventory (BFI) is a widely used dataset in personality psychology, measuring the five major dimensions of personality. We'll focus on the Openness trait for this tutorial.

```{r}

# Make sure you've loaded the psych package


# Load the BFI dataset
data(bfi)

# load data file
bfi <- bfi
names(bfi)

# View the structure of the dataset
#str(bfi)




```

The dataset contains 2,800 participants with various demographic and personality-related variables. A1 to A5 correspond to items measuring the Openness trait.

### Selecting Openness Items

For this tutorial, we'll focus on five items measuring the Openness trait. These items are typically labeled as A1 to A5 in the BFI dataset.

#### a. Extracting Openness Items

```{r}

# Select columns that contain "O" in their names and remove rows with NA values
oppeness <- bfi %>%
  select(matches("^O")) %>%
  drop_na()

head(oppeness)

```

Each A variable represents a Likert-type item measuring Openness. Responses range from 1 to 6, treated as continuous variables for analysis.

### Handling Missing Data

Before we continue, let's check any missing data.

```{r}

# Check for missing values
sum(is.na(oppeness))


```

In this dataset, there are no missing values in the Openness items. If missing values were present, then we need to address that.

## Calculating Cronbach's Alpha

Recall that Cronbach's Alpha (Œ±) is a measure of internal consistency that measures how closely related a set of items are as a group.

### a. We can use the psych Package in R

```{r}

# Calculate Cronbach's Alpha using the psych package
#alpha_result <- psych::alpha(oppeness)

# Print the result
#print(alpha_result)



```

Because some items were negatively correlated with the first principal component, we probably should reverse them.

```{r}

# Reversing item O2 and O5

q <- c("O2","O5")
reverse <- function(x){
  x.reversed <- 7 +0 - x
}

oppeness[, c("O2R", "O5R")] <- reverse(oppeness[,c("O2","O5")])

# compare original and reversed responses
oppeness[1:6,]

```

Now, we can compute the alpha

```{r}

# compute alpha coefficient 

alpha_result <- psych::alpha(oppeness[, -c(2,5)])

# Print the result
print(alpha_result)


```

Explanation:

raw_alpha: The Cronbach's Alpha coefficient.

std.alpha: Standardized alpha, similar to raw_alpha.

G6(smc): Generalizability theory estimate with squared multiple correlations.

average_r: Average inter-item correlation.

S/N: Signal-to-noise ratio.

ase: Asymptotic standard error.

Confidence Intervals: Lower and upper bounds for alpha.

As we can see, the Cronbach's Alpha for the Openness items is 0.6, indicating strong internal consistency. The average inter-item correlation is 0.24, moderate and within psychological scales.

## Confirmatory Factor Analysis (CFA)

Confirmatory Factor Analysis (CFA) is used to verify the factor structure of a set of observed variables. In our case, we assume a unidimensional structure.

### a. Specifying the CFA Model

Let's specify a one-factor model where all items load on a single latent factor.

```{r}

# Specify model
mod1f <- "
openness =~ O1 + O2R + O3 + O4 + O5R
"

```

### b. Fitting the CFA Model

Fit the Model Using lavaan:

```{r}
#pacman::p_load(lavaan)
# Estimate model
fit.one.f <- cfa(mod1f, data=oppeness, std.lv=T, missing='direct', 
             estimator='MLR')

# The results can be viewed using the summary

summary(fit.one.f, fit.measures=T, standardized=T)



```

Explanation:

Estimator: Maximum Likelihood (ML).

Test Statistics: The Chi-square test is significant (ùëù\<0.001), indicating a poor fit.

Fit Indices:

CFI (0.94): above 0.90.

TLI (0.88): Below the threshold of 0.90.

RMSEA (0.068): Indicates relatively weak fit (‚â•0.05).

SRMR (0.029): Great fit (‚â§0.08).

```{r}

residuals(fit.one.f, type='cor')

```

The fit statistics from the Robust column in the summary suggest that this one-factor model provides a moderate fit to the data. While the Comparative Fit Index (CFI) of 0.94 indicates an acceptable fit, the Tucker-Lewis Index (TLI) of 0.88 is relatively lower, and the Root Mean Square Error of Approximation (RMSEA) is relatively high at 0.08.

The factor loadings (ùúÜÃÇ) show significant variation, ranging from 0.357 to 0.792, which implies that the assumption of equal loadings (tau equivalence) does not hold for this openness test. As a result, omega (œâu) should be a more suitable measure of reliability than Cronbach's alpha. We can compute the œâu estimate by running the `reliability` function from the semTools package on the one-factor model object (`fit1f`).

```{r}

reliability(fit.one.f)

```

`omega` and `omega2` measure reliability based on the variance expected by the model, while `omega3` measures it based on the actual variance seen in your data. The small difference between `omega` and `omega3` suggests that the model's predictions of variance are somewhat close to what‚Äôs observed in the sample.

## Calculating Categorical Omega

Recall that Coefficient Omega (œâ) is a reliability estimate that accounts for the factor structure of the test, providing a more accurate measure than Cronbach's Alpha, especially in the presence of multidimensionality or when tau-equivalence is violated.

Since factor loadings derived from polychoric correlations represent the link between the factor and the underlying latent response variables (not the actual responses from the items), using the œâu formula here would tell us how much of the variance in the latent response variables is explained by the factor. However, this doesn‚Äôt reflect the true variance in the sum of the observed item responses. Essentially, in this case, œâu would give us the reliability of a hypothetical total score based on the latent variables rather than the actual observed total score.

To correct for this, Green and Yang (2009b) proposed a new reliability estimate called œâu-cat, which adjusts the reliability calculation to align with the observed total score. This estimate is more accurate for unidimensional scales with categorical items, especially when the response patterns vary across items.

Since the psychoticism items use a 4-point rating scale, I fit the one-factor model using polychoric correlations and the WLSMV estimator (weighted least squares with mean and variance adjustment). This approach is recommended for confirmatory factor analysis involving polychoric correlations, as it is more robust than the maximum likelihood (ML) estimator.

```{r}
#load the data
potic <- import("potic.csv")

# Specify model
mod.one.fCat <- 'psyctcsm =~ DDP1 + DDP2 +
DDP3 + DDP4'


# Estimate model
fit.one.fCat <- cfa(mod.one.fCat, data=potic, std.lv=TRUE, ordered=T, estimator='WLSMV')

# Retrieving the results
summary(fit.one.fCat, fit.measures=TRUE, standardized=TRUE)


```

```{r}

# Estimate reliability

reliability(fit.one.fCat)


```

We can see that we have two estimates Cronbach‚Äôs alpha and differ a bit (0.80 & 0.77). The is because the 2nd alpha estimate is an example of ordinal alpha, which is calculated using a model based on polychoric correlations, while the first alpha was derived using the standard method based on product-moment covariances between the items. It's important to note that ordinal alpha measures the reliability of the sum of the continuous, latent-response variables rather than the observed categorical item responses. Additionally, it still assumes equal factor loadings (tau equivalence). Because of these limitations, I suggest disregarding the alpha value reported by semTools::reliability when the model uses polychoric correlations.

The values shown in the `omega` and `omega2` rows represent the œâu-cat estimate. The `omega3` row shows a variation where the denominator uses the observed sample variance of ( X ). So, we can see œâu-cat estimates suggest that 79% of the variance in the total score for the psychoticism scale is explained by the single psychoticism factor.



```{r}

```





```{r}
#| echo: false
#2 * 2

#The `echo: false` option disables the printing of code (only output is displayed).

```
