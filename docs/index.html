<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Hammed Akande">

<title>EDUC 6003 Advanced Statistics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">EDUC 6003 Advanced Statistics</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="./index.html" aria-current="page"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#chapter-1--reliability-index-analysis" id="toc-chapter-1--reliability-index-analysis" class="nav-link active" data-scroll-target="#chapter-1--reliability-index-analysis">Chapter 1- Reliability Index Analysis</a>
  <ul class="collapse">
  <li><a href="#introduction-to-reliability-index-analysis" id="toc-introduction-to-reliability-index-analysis" class="nav-link" data-scroll-target="#introduction-to-reliability-index-analysis">Introduction to Reliability Index Analysis</a>
  <ul class="collapse">
  <li><a href="#what-is-reliability" id="toc-what-is-reliability" class="nav-link" data-scroll-target="#what-is-reliability">What is Reliability?</a></li>
  </ul></li>
  <li><a href="#classical-test-theory-ctt-and-coefficient-alpha" id="toc-classical-test-theory-ctt-and-coefficient-alpha" class="nav-link" data-scroll-target="#classical-test-theory-ctt-and-coefficient-alpha">Classical Test Theory (CTT) and Coefficient Alpha</a>
  <ul class="collapse">
  <li><a href="#coefficient-alpha-cronbachs-alpha" id="toc-coefficient-alpha-cronbachs-alpha" class="nav-link" data-scroll-target="#coefficient-alpha-cronbachs-alpha">Coefficient Alpha (Cronbach’s Alpha)</a></li>
  <li><a href="#coefficient-omega" id="toc-coefficient-omega" class="nav-link" data-scroll-target="#coefficient-omega">Coefficient Omega</a></li>
  </ul></li>
  <li><a href="#calculations-in-r" id="toc-calculations-in-r" class="nav-link" data-scroll-target="#calculations-in-r">Calculations in R</a></li>
  <li><a href="#loading-the-bfi-dataset" id="toc-loading-the-bfi-dataset" class="nav-link" data-scroll-target="#loading-the-bfi-dataset">Loading the (BFI) dataset</a>
  <ul class="collapse">
  <li><a href="#selecting-openness-items" id="toc-selecting-openness-items" class="nav-link" data-scroll-target="#selecting-openness-items">Selecting Openness Items</a></li>
  <li><a href="#handling-missing-data" id="toc-handling-missing-data" class="nav-link" data-scroll-target="#handling-missing-data">Handling Missing Data</a></li>
  </ul></li>
  <li><a href="#calculating-cronbachs-alpha" id="toc-calculating-cronbachs-alpha" class="nav-link" data-scroll-target="#calculating-cronbachs-alpha">Calculating Cronbach’s Alpha</a>
  <ul class="collapse">
  <li><a href="#a.-we-can-use-the-psych-package-in-r" id="toc-a.-we-can-use-the-psych-package-in-r" class="nav-link" data-scroll-target="#a.-we-can-use-the-psych-package-in-r">a. We can use the psych Package in R</a></li>
  </ul></li>
  <li><a href="#confirmatory-factor-analysis-cfa" id="toc-confirmatory-factor-analysis-cfa" class="nav-link" data-scroll-target="#confirmatory-factor-analysis-cfa">Confirmatory Factor Analysis (CFA)</a>
  <ul class="collapse">
  <li><a href="#a.-specifying-the-cfa-model" id="toc-a.-specifying-the-cfa-model" class="nav-link" data-scroll-target="#a.-specifying-the-cfa-model">a. Specifying the CFA Model</a></li>
  <li><a href="#b.-fitting-the-cfa-model" id="toc-b.-fitting-the-cfa-model" class="nav-link" data-scroll-target="#b.-fitting-the-cfa-model">b. Fitting the CFA Model</a></li>
  </ul></li>
  <li><a href="#calculating-categorical-omega" id="toc-calculating-categorical-omega" class="nav-link" data-scroll-target="#calculating-categorical-omega">Calculating Categorical Omega</a></li>
  <li><a href="#bifactor-models" id="toc-bifactor-models" class="nav-link" data-scroll-target="#bifactor-models">Bifactor Models</a>
  <ul class="collapse">
  <li><a href="#omega-hierarchical-ωh" id="toc-omega-hierarchical-ωh" class="nav-link" data-scroll-target="#omega-hierarchical-ωh">Omega Hierarchical (ωh)</a></li>
  <li><a href="#higher-order-models" id="toc-higher-order-models" class="nav-link" data-scroll-target="#higher-order-models">Higher-Order Models</a></li>
  </ul></li>
  <li><a href="#exploratory-omega-estimates" id="toc-exploratory-omega-estimates" class="nav-link" data-scroll-target="#exploratory-omega-estimates">Exploratory Omega Estimates</a></li>
  </ul></li>
  <li><a href="#chapter-2--simple-linear-regression-slr" id="toc-chapter-2--simple-linear-regression-slr" class="nav-link" data-scroll-target="#chapter-2--simple-linear-regression-slr">Chapter 2- Simple Linear Regression (SLR)</a></li>
  <li><a href="#chapter-3--multiple-linear-regression" id="toc-chapter-3--multiple-linear-regression" class="nav-link" data-scroll-target="#chapter-3--multiple-linear-regression">Chapter 3- Multiple Linear Regression</a>
  <ul class="collapse">
  <li><a href="#build-multiple-regression-in-r" id="toc-build-multiple-regression-in-r" class="nav-link" data-scroll-target="#build-multiple-regression-in-r">Build Multiple Regression in R</a></li>
  </ul></li>
  <li><a href="#chapter-4--least-square-approach" id="toc-chapter-4--least-square-approach" class="nav-link" data-scroll-target="#chapter-4--least-square-approach">Chapter 4- Least Square Approach</a>
  <ul class="collapse">
  <li><a href="#example-of-least-square-approach-using-data" id="toc-example-of-least-square-approach-using-data" class="nav-link" data-scroll-target="#example-of-least-square-approach-using-data">Example of Least Square Approach using data</a></li>
  <li><a href="#predictions" id="toc-predictions" class="nav-link" data-scroll-target="#predictions">Predictions</a></li>
  <li><a href="#residuals" id="toc-residuals" class="nav-link" data-scroll-target="#residuals">Residuals</a></li>
  <li><a href="#estimating-the-variance" id="toc-estimating-the-variance" class="nav-link" data-scroll-target="#estimating-the-variance">Estimating the Variance</a></li>
  <li><a href="#variation-decomposition" id="toc-variation-decomposition" class="nav-link" data-scroll-target="#variation-decomposition">Variation Decomposition</a></li>
  <li><a href="#coefficient-of-determination" id="toc-coefficient-of-determination" class="nav-link" data-scroll-target="#coefficient-of-determination">Coefficient of Determination</a></li>
  </ul></li>
  <li><a href="#chapter-5---moderation-and-mediation-analysis" id="toc-chapter-5---moderation-and-mediation-analysis" class="nav-link" data-scroll-target="#chapter-5---moderation-and-mediation-analysis">Chapter 5 - Moderation and Mediation Analysis</a>
  <ul class="collapse">
  <li><a href="#understanding-moderation-in-statistical-analysis" id="toc-understanding-moderation-in-statistical-analysis" class="nav-link" data-scroll-target="#understanding-moderation-in-statistical-analysis">Understanding Moderation in Statistical Analysis</a>
  <ul class="collapse">
  <li><a href="#exploring-moderation-and-its-relationship-to-interaction" id="toc-exploring-moderation-and-its-relationship-to-interaction" class="nav-link" data-scroll-target="#exploring-moderation-and-its-relationship-to-interaction">Exploring Moderation and Its Relationship to Interaction</a></li>
  <li><a href="#example-age-as-a-moderator" id="toc-example-age-as-a-moderator" class="nav-link" data-scroll-target="#example-age-as-a-moderator">Example – Age as a Moderator</a></li>
  <li><a href="#example-2--moderation-with-a-continuous-moderator" id="toc-example-2--moderation-with-a-continuous-moderator" class="nav-link" data-scroll-target="#example-2--moderation-with-a-continuous-moderator">Example 2- Moderation with a Continuous Moderator</a></li>
  </ul></li>
  <li><a href="#mean-centering-in-moderation-models" id="toc-mean-centering-in-moderation-models" class="nav-link" data-scroll-target="#mean-centering-in-moderation-models">Mean Centering in Moderation Models</a></li>
  <li><a href="#mediation" id="toc-mediation" class="nav-link" data-scroll-target="#mediation">Mediation</a>
  <ul class="collapse">
  <li><a href="#traditional-mediation-analysis-and-the-baron-kenny-approach" id="toc-traditional-mediation-analysis-and-the-baron-kenny-approach" class="nav-link" data-scroll-target="#traditional-mediation-analysis-and-the-baron-kenny-approach">Traditional Mediation Analysis and the Baron &amp; Kenny Approach</a></li>
  <li><a href="#using-bootstrapping" id="toc-using-bootstrapping" class="nav-link" data-scroll-target="#using-bootstrapping">Using Bootstrapping</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#chapter-6---introduction-to-structural-equation-modeling-sem-in-r" id="toc-chapter-6---introduction-to-structural-equation-modeling-sem-in-r" class="nav-link" data-scroll-target="#chapter-6---introduction-to-structural-equation-modeling-sem-in-r">Chapter 6 - Introduction to Structural Equation Modeling (SEM) in R</a>
  <ul class="collapse">
  <li><a href="#using-lavaan-package" id="toc-using-lavaan-package" class="nav-link" data-scroll-target="#using-lavaan-package">Using Lavaan package</a></li>
  <li><a href="#including-the-mean-structure" id="toc-including-the-mean-structure" class="nav-link" data-scroll-target="#including-the-mean-structure">Including the Mean Structure</a></li>
  <li><a href="#examining-model-parameters" id="toc-examining-model-parameters" class="nav-link" data-scroll-target="#examining-model-parameters">Examining Model Parameters</a></li>
  <li><a href="#standardized-estimates" id="toc-standardized-estimates" class="nav-link" data-scroll-target="#standardized-estimates">Standardized estimates</a></li>
  <li><a href="#path-analysis-with-housing-data" id="toc-path-analysis-with-housing-data" class="nav-link" data-scroll-target="#path-analysis-with-housing-data">Path Analysis with Housing Data</a>
  <ul class="collapse">
  <li><a href="#ill-conditioning" id="toc-ill-conditioning" class="nav-link" data-scroll-target="#ill-conditioning">Ill-Conditioning</a></li>
  <li><a href="#evaluating-model-fit" id="toc-evaluating-model-fit" class="nav-link" data-scroll-target="#evaluating-model-fit">Evaluating Model Fit</a></li>
  <li><a href="#model-diagnostics" id="toc-model-diagnostics" class="nav-link" data-scroll-target="#model-diagnostics">Model Diagnostics</a></li>
  <li><a href="#modification-indices" id="toc-modification-indices" class="nav-link" data-scroll-target="#modification-indices">Modification Indices</a></li>
  <li><a href="#testing-mediation-effects" id="toc-testing-mediation-effects" class="nav-link" data-scroll-target="#testing-mediation-effects">Testing Mediation Effects</a></li>
  <li><a href="#latent-variable-models-in-sem" id="toc-latent-variable-models-in-sem" class="nav-link" data-scroll-target="#latent-variable-models-in-sem">Latent Variable Models in SEM</a></li>
  <li><a href="#structural-model" id="toc-structural-model" class="nav-link" data-scroll-target="#structural-model">Structural Model</a></li>
  <li><a href="#choosing-estimators" id="toc-choosing-estimators" class="nav-link" data-scroll-target="#choosing-estimators">Choosing Estimators</a></li>
  <li><a href="#handling-missing-data-in-sem" id="toc-handling-missing-data-in-sem" class="nav-link" data-scroll-target="#handling-missing-data-in-sem">Handling Missing Data in SEM</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">EDUC 6003 Advanced Statistics</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Hammed Akande </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="chapter-1--reliability-index-analysis" class="level1">
<h1>Chapter 1- Reliability Index Analysis</h1>
<section id="introduction-to-reliability-index-analysis" class="level2">
<h2 class="anchored" data-anchor-id="introduction-to-reliability-index-analysis">Introduction to Reliability Index Analysis</h2>
<p>This tutorial will serve as a Guide to Enhanced Reliability Estimation with R</p>
<section id="what-is-reliability" class="level3">
<h3 class="anchored" data-anchor-id="what-is-reliability">What is Reliability?</h3>
<p>Reliability refers to the consistency and precision of measurement instruments. In psychological testing, it assesses the extent to which a test produces stable and consistent results.</p>
<section id="importance-of-reliability" class="level4">
<h4 class="anchored" data-anchor-id="importance-of-reliability">Importance of Reliability</h4>
<p><em>Measurement Precision</em>: Ensures that the scores accurately reflect the true attributes being measured.</p>
<p><em>Research Validity</em>: High reliability is a prerequisite for valid conclusions and replicable research findings.</p>
<p><em>Error Reduction</em>: Minimizes the impact of random errors, enhancing the clarity of observed relationships between constructs.</p>
</section>
<section id="types-of-reliability" class="level4">
<h4 class="anchored" data-anchor-id="types-of-reliability">Types of Reliability</h4>
<p><em>Internal Consistency</em>: Degree to which items within a test measure the same construct.</p>
<p><em>Test-Retest Reliability</em>: Consistency of scores over time.</p>
<p><em>Inter-Rater Reliability</em>: Agreement between different raters or observers.</p>
</section>
</section>
</section>
<section id="classical-test-theory-ctt-and-coefficient-alpha" class="level2">
<h2 class="anchored" data-anchor-id="classical-test-theory-ctt-and-coefficient-alpha">Classical Test Theory (CTT) and Coefficient Alpha</h2>
<p>Classical Test Theory Overview: CTT posits that each observed score is composed of a true score and an error score:</p>
<p><span class="math display">\[ X = T + E \]</span></p>
<p>where:</p>
<p>𝑋= Observed score 𝑇= True score 𝐸= Error score</p>
<section id="coefficient-alpha-cronbachs-alpha" class="level3">
<h3 class="anchored" data-anchor-id="coefficient-alpha-cronbachs-alpha">Coefficient Alpha (Cronbach’s Alpha)</h3>
<p>This is a widely used measure of internal consistency reliability within CTT. It estimates the extent to which items on a test measure the same underlying construct.</p>
<p><span class="math display">\[
\alpha = \frac{N}{N-1} \left(1 - \frac{\sum \sigma^2_{E}}{\sigma^2_{X}}\right)
\]</span></p>
<p>Where:</p>
<p><span class="math inline">\(\alpha\)</span> = Cronbach’s Alpha</p>
<p>𝑁 = Number of items in the test</p>
<p><span class="math inline">\(\sigma^2_{E}\)</span> = Variance of the error scores</p>
<p><span class="math inline">\(\sigma^2_{X}\)</span> = Variance of the observed total scores</p>
<section id="assumptions-of-alpha" class="level4">
<h4 class="anchored" data-anchor-id="assumptions-of-alpha">Assumptions of Alpha</h4>
<p><em>Unidimensionality</em>: All items measure a single construct.</p>
<p><em>Tau Equivalence</em>: Each item has the same true score variance.</p>
<p><em>Independence of Errors</em>: Error terms are uncorrelated across items.</p>
</section>
<section id="limitations-of-alpha" class="level4">
<h4 class="anchored" data-anchor-id="limitations-of-alpha">Limitations of Alpha</h4>
<p><em>Sensitivity to Tau Equivalence</em>: Violations can lead to underestimation or overestimation of reliability.</p>
<p><em>Assumes Unidimensionality</em>: Not suitable for multidimensional scales without adjustments.</p>
<p><em>Ignores Factor Structure</em>: Does not account for the underlying factor model of the test.</p>
</section>
</section>
<section id="coefficient-omega" class="level3">
<h3 class="anchored" data-anchor-id="coefficient-omega">Coefficient Omega</h3>
<p>Coefficient Omega is a more robust alternative to Cronbach’s Alpha, especially when the assumption of tau-equivalence (equal factor loadings) is violated. Omega takes into account the factor structure of the test, making it suitable for both unidimensional and multidimensional scales.</p>
<section id="types-of-omega" class="level4">
<h4 class="anchored" data-anchor-id="types-of-omega">Types of Omega</h4>
<p><em>Omega Total (ωₜ</em>): Accounts for all common factors, both general and specific.</p>
<p><em>Omega Hierarchical (ωₕ)</em>: Represents the proportion of variance attributable to a general factor alone.</p>
<p>Omega Total is given by:</p>
<p><span class="math display">\[
\omega_t = \frac{\sum_{i=1}^{k} \lambda_i}{\sum_{i=1}^{k} \lambda_i + \sum_{i=1}^{k} \theta_i}
\]</span></p>
<p>Where:</p>
<p><span class="math inline">\(\omega_t\)</span> = Omega Total</p>
<p><span class="math inline">\(\lambda_i\)</span> = Factor loading for item</p>
<p><span class="math inline">\(\theta_i\)</span> = Unique variance (error variance) for item</p>
<p><span class="math inline">\(k\)</span> = Total number of items</p>
<p>For a hierarchical model, Omega Hierarchical is:</p>
<p><span class="math display">\[
\omega_h = \frac{\lambda_g^2}{\lambda_g^2 + \sum_{i=1}^{k} \theta_i}
\]</span></p>
<p>where:</p>
<p><span class="math inline">\(\omega_h\)</span> = Omega Hierarchical</p>
<p><span class="math inline">\(\lambda_g\)</span> = Factor loading of the general factor</p>
<p><span class="math inline">\(\theta_i\)</span> = Unique variance for item <span class="math inline">\(i\)</span></p>
</section>
<section id="advantages-of-omega-over-alpha" class="level4">
<h4 class="anchored" data-anchor-id="advantages-of-omega-over-alpha">Advantages of Omega Over Alpha</h4>
<p><em>Factor Structure Incorporation</em>: Utilizes confirmatory factor analysis (CFA) to model the underlying structure.</p>
<p><em>Less Sensitive to Tau Equivalence Violations</em>: Provides more accurate reliability estimates when tau equivalence is not met.</p>
<p><em>Applicability to Multidimensional Scales</em>: Suitable for tests measuring multiple constructs.</p>
</section>
</section>
</section>
<section id="calculations-in-r" class="level2">
<h2 class="anchored" data-anchor-id="calculations-in-r">Calculations in R</h2>
<p>Here, I will walk through the step-by-step process of calculating Cronbach’s Alpha and Coefficient Omega using R.</p>
<p>Load the necessary packages.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>pacman<span class="sc">::</span><span class="fu">p_load</span>(psych,lavaan,semTools,tidyverse,semTools,psych,tidyverse,lavaan,rio,parameters,</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>               nFactors,EGAnet,PCDimension)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="loading-the-bfi-dataset" class="level2">
<h2 class="anchored" data-anchor-id="loading-the-bfi-dataset">Loading the (BFI) dataset</h2>
<p>The Big Five Inventory (BFI) is a widely used dataset in personality psychology, measuring the five major dimensions of personality. We’ll focus on the Openness trait for this tutorial.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make sure you've loaded the psych package</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the BFI dataset</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(bfi)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># load data file</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>bfi <span class="ot">&lt;-</span> bfi</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(bfi)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] "A1"        "A2"        "A3"        "A4"        "A5"        "C1"       
 [7] "C2"        "C3"        "C4"        "C5"        "E1"        "E2"       
[13] "E3"        "E4"        "E5"        "N1"        "N2"        "N3"       
[19] "N4"        "N5"        "O1"        "O2"        "O3"        "O4"       
[25] "O5"        "gender"    "education" "age"      </code></pre>
</div>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View the structure of the dataset</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co">#str(bfi)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The dataset contains 2,800 participants with various demographic and personality-related variables. A1 to A5 correspond to items measuring the Openness trait.</p>
<section id="selecting-openness-items" class="level3">
<h3 class="anchored" data-anchor-id="selecting-openness-items">Selecting Openness Items</h3>
<p>For this tutorial, we’ll focus on five items measuring the Openness trait. These items are typically labeled as A1 to A5 in the BFI dataset.</p>
<section id="a.-extracting-openness-items" class="level4">
<h4 class="anchored" data-anchor-id="a.-extracting-openness-items">a. Extracting Openness Items</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Select columns that contain "O" in their names and remove rows with NA values</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>oppeness <span class="ot">&lt;-</span> bfi <span class="sc">%&gt;%</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="fu">matches</span>(<span class="st">"^O"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">drop_na</span>()</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(oppeness)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  O1 O2 O3 O4 O5
1  3  6  3  4  3
2  4  2  4  3  3
3  4  2  5  5  2
4  3  3  4  3  5
5  3  3  4  3  3
6  4  3  5  6  1</code></pre>
</div>
</div>
<p>Each A variable represents a Likert-type item measuring Openness. Responses range from 1 to 6, treated as continuous variables for analysis.</p>
</section>
</section>
<section id="handling-missing-data" class="level3">
<h3 class="anchored" data-anchor-id="handling-missing-data">Handling Missing Data</h3>
<p>Before we continue, let’s check any missing data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check for missing values</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">is.na</span>(oppeness))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0</code></pre>
</div>
</div>
<p>In this dataset, there are no missing values in the Openness items. If missing values were present, then we need to address that.</p>
</section>
</section>
<section id="calculating-cronbachs-alpha" class="level2">
<h2 class="anchored" data-anchor-id="calculating-cronbachs-alpha">Calculating Cronbach’s Alpha</h2>
<p>Recall that Cronbach’s Alpha (α) is a measure of internal consistency that measures how closely related a set of items are as a group.</p>
<section id="a.-we-can-use-the-psych-package-in-r" class="level3">
<h3 class="anchored" data-anchor-id="a.-we-can-use-the-psych-package-in-r">a. We can use the psych Package in R</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate Cronbach's Alpha using the psych package</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co">#alpha_result &lt;- psych::alpha(oppeness)</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co">#print(alpha_result)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Because some items were negatively correlated with the first principal component, we probably should reverse them.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Reversing item O2 and O5</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>q <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"O2"</span>,<span class="st">"O5"</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>reverse <span class="ot">&lt;-</span> <span class="cf">function</span>(x){</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  x.reversed <span class="ot">&lt;-</span> <span class="dv">7</span> <span class="sc">+</span><span class="dv">0</span> <span class="sc">-</span> x</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>oppeness[, <span class="fu">c</span>(<span class="st">"O2R"</span>, <span class="st">"O5R"</span>)] <span class="ot">&lt;-</span> <span class="fu">reverse</span>(oppeness[,<span class="fu">c</span>(<span class="st">"O2"</span>,<span class="st">"O5"</span>)])</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="co"># compare original and reversed responses</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>oppeness[<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>,]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  O1 O2 O3 O4 O5 O2R O5R
1  3  6  3  4  3   1   4
2  4  2  4  3  3   5   4
3  4  2  5  5  2   5   5
4  3  3  4  3  5   4   2
5  3  3  4  3  3   4   4
6  4  3  5  6  1   4   6</code></pre>
</div>
</div>
<p>Now, we can compute the alpha</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compute alpha coefficient </span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>alpha_result <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">alpha</span>(oppeness[, <span class="sc">-</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">5</span>)])</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(alpha_result)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Reliability analysis   
Call: psych::alpha(x = oppeness[, -c(2, 5)])

  raw_alpha std.alpha G6(smc) average_r S/N   ase mean   sd median_r
       0.6      0.61    0.57      0.24 1.6 0.012  4.6 0.81     0.23

    95% confidence boundaries 
         lower alpha upper
Feldt     0.58   0.6  0.63
Duhachek  0.58   0.6  0.63

 Reliability if an item is dropped:
    raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r
O1       0.54      0.54    0.48      0.23 1.2    0.014 0.0087  0.23
O3       0.50      0.50    0.44      0.20 1.0    0.015 0.0065  0.20
O4       0.61      0.62    0.56      0.29 1.7    0.012 0.0040  0.29
O2R      0.57      0.57    0.51      0.25 1.3    0.014 0.0077  0.21
O5R      0.52      0.53    0.48      0.22 1.1    0.015 0.0109  0.21

 Item statistics 
       n raw.r std.r r.cor r.drop mean  sd
O1  2726  0.61  0.65  0.51   0.39  4.8 1.1
O3  2726  0.68  0.69  0.59   0.45  4.4 1.2
O4  2726  0.50  0.52  0.29   0.22  4.9 1.2
O2R 2726  0.66  0.60  0.44   0.34  4.3 1.6
O5R 2726  0.67  0.66  0.52   0.42  4.5 1.3

Non missing response frequency for each item
       1    2    3    4    5    6 miss
O1  0.01 0.04 0.08 0.22 0.33 0.33    0
O3  0.03 0.05 0.10 0.28 0.34 0.20    0
O4  0.02 0.05 0.06 0.17 0.32 0.39    0
O2R 0.06 0.10 0.15 0.14 0.26 0.29    0
O5R 0.02 0.07 0.13 0.19 0.32 0.27    0</code></pre>
</div>
</div>
<p>Explanation:</p>
<p>raw_alpha: The Cronbach’s Alpha coefficient.</p>
<p>std.alpha: Standardized alpha, similar to raw_alpha.</p>
<p>G6(smc): Generalizability theory estimate with squared multiple correlations.</p>
<p>average_r: Average inter-item correlation.</p>
<p>S/N: Signal-to-noise ratio.</p>
<p>ase: Asymptotic standard error.</p>
<p>Confidence Intervals: Lower and upper bounds for alpha.</p>
<p>As we can see, the Cronbach’s Alpha for the Openness items is 0.6, indicating strong internal consistency. The average inter-item correlation is 0.24, moderate and within psychological scales.</p>
</section>
</section>
<section id="confirmatory-factor-analysis-cfa" class="level2">
<h2 class="anchored" data-anchor-id="confirmatory-factor-analysis-cfa">Confirmatory Factor Analysis (CFA)</h2>
<p>Confirmatory Factor Analysis (CFA) is used to verify the factor structure of a set of observed variables. In our case, we assume a unidimensional structure.</p>
<section id="a.-specifying-the-cfa-model" class="level3">
<h3 class="anchored" data-anchor-id="a.-specifying-the-cfa-model">a. Specifying the CFA Model</h3>
<p>Let’s specify a one-factor model where all items load on a single latent factor.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify model</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>mod1f <span class="ot">&lt;-</span> <span class="st">"</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="st">openness =~ O1 + O2R + O3 + O4 + O5R</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="st">"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="b.-fitting-the-cfa-model" class="level3">
<h3 class="anchored" data-anchor-id="b.-fitting-the-cfa-model">b. Fitting the CFA Model</h3>
<p>Fit the Model Using lavaan:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">#pacman::p_load(lavaan)</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate model</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>fit.one.f <span class="ot">&lt;-</span> <span class="fu">cfa</span>(mod1f, <span class="at">data=</span>oppeness, <span class="at">std.lv=</span>T, <span class="at">missing=</span><span class="st">'direct'</span>, </span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">estimator=</span><span class="st">'MLR'</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co"># The results can be viewed using the summary</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit.one.f, <span class="at">fit.measures=</span>T, <span class="at">standardized=</span>T)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-19 ended normally after 22 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        15

  Number of observations                          2726
  Number of missing patterns                         1

Model Test User Model:
                                              Standard      Scaled
  Test Statistic                                80.583      67.248
  Degrees of freedom                                 5           5
  P-value (Chi-square)                           0.000       0.000
  Scaling correction factor                                  1.198
    Yuan-Bentler correction (Mplus variant)                       

Model Test Baseline Model:

  Test statistic                              1375.389    1049.226
  Degrees of freedom                                10          10
  P-value                                        0.000       0.000
  Scaling correction factor                                  1.311

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.945       0.940
  Tucker-Lewis Index (TLI)                       0.889       0.880
                                                                  
  Robust Comparative Fit Index (CFI)                         0.946
  Robust Tucker-Lewis Index (TLI)                            0.891

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)             -22078.661  -22078.661
  Scaling correction factor                                  1.167
      for the MLR correction                                      
  Loglikelihood unrestricted model (H1)     -22038.369  -22038.369
  Scaling correction factor                                  1.174
      for the MLR correction                                      
                                                                  
  Akaike (AIC)                               44187.322   44187.322
  Bayesian (BIC)                             44275.980   44275.980
  Sample-size adjusted Bayesian (SABIC)      44228.321   44228.321

Root Mean Square Error of Approximation:

  RMSEA                                          0.074       0.068
  90 Percent confidence interval - lower         0.061       0.055
  90 Percent confidence interval - upper         0.089       0.081
  P-value H_0: RMSEA &lt;= 0.050                    0.002       0.012
  P-value H_0: RMSEA &gt;= 0.080                    0.280       0.066
                                                                  
  Robust RMSEA                                               0.074
  90 Percent confidence interval - lower                     0.058
  90 Percent confidence interval - upper                     0.090
  P-value H_0: Robust RMSEA &lt;= 0.050                         0.006
  P-value H_0: Robust RMSEA &gt;= 0.080                         0.285

Standardized Root Mean Square Residual:

  SRMR                                           0.029       0.029

Parameter Estimates:

  Standard errors                             Sandwich
  Information bread                           Observed
  Observed information based on                Hessian

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  openness =~                                                           
    O1                0.616    0.029   21.346    0.000    0.616    0.546
    O2R               0.701    0.041   17.170    0.000    0.701    0.449
    O3                0.792    0.032   24.649    0.000    0.792    0.649
    O4                0.357    0.030   11.749    0.000    0.357    0.294
    O5R               0.685    0.036   19.194    0.000    0.685    0.517

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .O1                4.819    0.022  223.110    0.000    4.819    4.273
   .O2R               4.300    0.030  143.782    0.000    4.300    2.754
   .O3                4.439    0.023  189.916    0.000    4.439    3.637
   .O4                4.898    0.023  210.231    0.000    4.898    4.027
   .O5R               4.516    0.025  177.976    0.000    4.516    3.409

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .O1                0.893    0.037   23.923    0.000    0.893    0.702
   .O2R               1.947    0.068   28.607    0.000    1.947    0.798
   .O3                0.862    0.050   17.172    0.000    0.862    0.579
   .O4                1.352    0.052   25.967    0.000    1.352    0.914
   .O5R               1.286    0.059   21.822    0.000    1.286    0.732
    openness          1.000                               1.000    1.000</code></pre>
</div>
</div>
<p>Explanation:</p>
<p>Estimator: Maximum Likelihood (ML).</p>
<p>Test Statistics: The Chi-square test is significant (𝑝&lt;0.001), indicating a poor fit.</p>
<p>Fit Indices:</p>
<p>CFI (0.94): above 0.90.</p>
<p>TLI (0.88): Below the threshold of 0.90.</p>
<p>RMSEA (0.068): Indicates relatively weak fit (≥0.05).</p>
<p>SRMR (0.029): Great fit (≤0.08).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">residuals</span>(fit.one.f, <span class="at">type=</span><span class="st">'cor'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$type
[1] "cor.bollen"

$cov
        O1    O2R     O3     O4    O5R
O1   0.000                            
O2R -0.026  0.000                     
O3   0.037 -0.024  0.000              
O4   0.013 -0.052  0.000  0.000       
O5R -0.044  0.090 -0.022  0.027  0.000

$mean
 O1 O2R  O3  O4 O5R 
  0   0   0   0   0 </code></pre>
</div>
</div>
<p>The fit statistics from the Robust column in the summary suggest that this one-factor model provides a moderate fit to the data. While the Comparative Fit Index (CFI) of 0.94 indicates an acceptable fit, the Tucker-Lewis Index (TLI) of 0.88 is relatively lower, and the Root Mean Square Error of Approximation (RMSEA) is relatively high at 0.08.</p>
<p>The factor loadings (𝜆̂) show significant variation, ranging from 0.357 to 0.792, which implies that the assumption of equal loadings (tau equivalence) does not hold for this openness test. As a result, omega (ωu) should be a more suitable measure of reliability than Cronbach’s alpha. We can compute the ωu estimate by running the <code>reliability</code> function from the semTools package on the one-factor model object (<code>fit1f</code>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">reliability</span>(fit.one.f)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        openness
alpha  0.6025464
omega  0.6103741
omega2 0.6103741
omega3 0.6098642
avevar 0.2484010</code></pre>
</div>
</div>
<p><code>omega</code> and <code>omega2</code> measure reliability based on the variance expected by the model, while <code>omega3</code> measures it based on the actual variance seen in your data. The small difference between <code>omega</code> and <code>omega3</code> suggests that the model’s predictions of variance are somewhat close to what’s observed in the sample.</p>
</section>
</section>
<section id="calculating-categorical-omega" class="level2">
<h2 class="anchored" data-anchor-id="calculating-categorical-omega">Calculating Categorical Omega</h2>
<p>Recall that Coefficient Omega (ω) is a reliability estimate that accounts for the factor structure of the test, providing a more accurate measure than Cronbach’s Alpha, especially in the presence of multidimensionality or when tau-equivalence is violated.</p>
<p>Since factor loadings derived from polychoric correlations represent the link between the factor and the underlying latent response variables (not the actual responses from the items), using the ωu formula here would tell us how much of the variance in the latent response variables is explained by the factor. However, this doesn’t reflect the true variance in the sum of the observed item responses. Essentially, in this case, ωu would give us the reliability of a hypothetical total score based on the latent variables rather than the actual observed total score.</p>
<p>To correct for this, Green and Yang (2009b) proposed a new reliability estimate called ωu-cat, which adjusts the reliability calculation to align with the observed total score. This estimate is more accurate for unidimensional scales with categorical items, especially when the response patterns vary across items.</p>
<p>Since the psychoticism items use a 4-point rating scale, I fit the one-factor model using polychoric correlations and the WLSMV estimator (weighted least squares with mean and variance adjustment). This approach is recommended for confirmatory factor analysis involving polychoric correlations, as it is more robust than the maximum likelihood (ML) estimator.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">#load the data</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>potic <span class="ot">&lt;-</span> <span class="fu">import</span>(<span class="st">"data/potic.csv"</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify model</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>mod.one.fCat <span class="ot">&lt;-</span> <span class="st">'psyctcsm =~ DDP1 + DDP2 +</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="st">DDP3 + DDP4'</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate model</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>fit.one.fCat <span class="ot">&lt;-</span> <span class="fu">cfa</span>(mod.one.fCat, <span class="at">data=</span>potic, <span class="at">std.lv=</span><span class="cn">TRUE</span>, <span class="at">ordered=</span>T, <span class="at">estimator=</span><span class="st">'WLSMV'</span>)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Retrieving the results</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit.one.fCat, <span class="at">fit.measures=</span><span class="cn">TRUE</span>, <span class="at">standardized=</span><span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-19 ended normally after 10 iterations

  Estimator                                       DWLS
  Optimization method                           NLMINB
  Number of model parameters                        20

                                                  Used       Total
  Number of observations                           498         500

Model Test User Model:
                                              Standard      Scaled
  Test Statistic                                 7.117      14.910
  Degrees of freedom                                 2           2
  P-value (Chi-square)                           0.028       0.001
  Scaling correction factor                                  0.480
  Shift parameter                                            0.089
    simple second-order correction                                

Model Test Baseline Model:

  Test statistic                              1635.647    1316.086
  Degrees of freedom                                 6           6
  P-value                                        0.000       0.000
  Scaling correction factor                                  1.244

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.997       0.990
  Tucker-Lewis Index (TLI)                       0.991       0.970
                                                                  
  Robust Comparative Fit Index (CFI)                         0.969
  Robust Tucker-Lewis Index (TLI)                            0.908

Root Mean Square Error of Approximation:

  RMSEA                                          0.072       0.114
  90 Percent confidence interval - lower         0.020       0.065
  90 Percent confidence interval - upper         0.132       0.171
  P-value H_0: RMSEA &lt;= 0.050                    0.200       0.019
  P-value H_0: RMSEA &gt;= 0.080                    0.479       0.880
                                                                  
  Robust RMSEA                                               0.147
  90 Percent confidence interval - lower                     0.089
  90 Percent confidence interval - upper                     0.213
  P-value H_0: Robust RMSEA &lt;= 0.050                         0.004
  P-value H_0: Robust RMSEA &gt;= 0.080                         0.970

Standardized Root Mean Square Residual:

  SRMR                                           0.033       0.033

Parameter Estimates:

  Parameterization                               Delta
  Standard errors                           Robust.sem
  Information                                 Expected
  Information saturated (h1) model        Unstructured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  psyctcsm =~                                                           
    DDP1              0.894    0.028   31.538    0.000    0.894    0.894
    DDP2              0.753    0.028   26.711    0.000    0.753    0.753
    DDP3              0.698    0.030   23.314    0.000    0.698    0.698
    DDP4              0.513    0.040   12.738    0.000    0.513    0.513

Thresholds:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
    DDP1|t1          -0.716    0.062  -11.591    0.000   -0.716   -0.716
    DDP1|t2          -0.040    0.056   -0.716    0.474   -0.040   -0.040
    DDP1|t3           0.296    0.057    5.185    0.000    0.296    0.296
    DDP1|t4           1.034    0.069   15.065    0.000    1.034    1.034
    DDP2|t1          -0.580    0.060   -9.693    0.000   -0.580   -0.580
    DDP2|t2           0.208    0.057    3.668    0.000    0.208    0.208
    DDP2|t3           0.562    0.060    9.431    0.000    0.562    0.562
    DDP2|t4           1.096    0.070   15.570    0.000    1.096    1.096
    DDP3|t1          -1.203    0.074  -16.298    0.000   -1.203   -1.203
    DDP3|t2          -0.425    0.058   -7.318    0.000   -0.425   -0.425
    DDP3|t3           0.081    0.056    1.432    0.152    0.081    0.081
    DDP3|t4           0.913    0.066   13.909    0.000    0.913    0.913
    DDP4|t1          -1.605    0.092  -17.382    0.000   -1.605   -1.605
    DDP4|t2          -1.060    0.069  -15.285    0.000   -1.060   -1.060
    DDP4|t3          -0.521    0.059   -8.817    0.000   -0.521   -0.521
    DDP4|t4           0.431    0.058    7.406    0.000    0.431    0.431

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .DDP1              0.201                               0.201    0.201
   .DDP2              0.433                               0.433    0.433
   .DDP3              0.513                               0.513    0.513
   .DDP4              0.737                               0.737    0.737
    psyctcsm          1.000                               1.000    1.000</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate reliability</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="fu">reliability</span>(fit.one.fCat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>For constructs with categorical indicators, Zumbo et al.`s (2007) "ordinal alpha" is calculated in addition to the standard alpha, which treats ordinal variables as numeric. See Chalmers (2018) for a critique of "alpha.ord" and the response by Zumbo &amp; Kroc (2019). Likewise, average variance extracted is calculated from polychoric (polyserial) not Pearson correlations.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>           psyctcsm
alpha     0.7680870
alpha.ord 0.8007496
omega     0.7902953
omega2    0.7902953
omega3    0.7932682
avevar    0.5289638</code></pre>
</div>
</div>
<p>We can see that we have two estimates Cronbach’s alpha and differ a bit (0.80 &amp; 0.77). The is because the 2nd alpha estimate is an example of ordinal alpha, which is calculated using a model based on polychoric correlations, while the first alpha was derived using the standard method based on product-moment covariances between the items. It’s important to note that ordinal alpha measures the reliability of the sum of the continuous, latent-response variables rather than the observed categorical item responses. Additionally, it still assumes equal factor loadings (tau equivalence). Because of these limitations, I suggest disregarding the alpha value reported by semTools::reliability when the model uses polychoric correlations.</p>
<p>The values shown in the <code>omega</code> and <code>omega2</code> rows represent the ωu-cat estimate. The <code>omega3</code> row shows a variation where the denominator uses the observed sample variance of ( X ). So, we can see ωu-cat estimates suggest that 79% of the variance in the total score for the psychoticism scale is explained by the single psychoticism factor.</p>
</section>
<section id="bifactor-models" class="level2">
<h2 class="anchored" data-anchor-id="bifactor-models">Bifactor Models</h2>
<p>A bifactor model is a useful way to represent a multidimensional structure. In this model, there’s a general factor that affects all items, while additional specific factors (or group factors) explain the relationships (covariation) between certain subsets of items beyond what the general factor accounts for.</p>
<p>For the model to work correctly, the general factor needs to be uncorrelated with the specific factors. In contrast to other Confirmatory Factor Analysis (CFA) models where all factors can correlate freely, allowing the general factor to correlate with a specific factor in a bifactor model can lead to issues like non-convergence or incorrect solutions.</p>
<section id="omega-hierarchical-ωh" class="level3">
<h3 class="anchored" data-anchor-id="omega-hierarchical-ωh">Omega Hierarchical (ωh)</h3>
<p>When data fits well with a bifactor model, a reliability metric called <strong>omega hierarchical (</strong><span class="math inline">\(ω_h\)</span>) is used. This measure reflects how much of the total score’s variance is attributable to the single general factor, even though the data involves multiple dimensions.</p>
<p>Here, let’s demonstrate the estimation of <span class="math inline">\(ω_h\)</span> using R, I use data that from Flake, Ferland, &amp; Flora, 2017 collected by administering the PCS to 154 students in an introductory statistics course.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>pcs <span class="ot">&lt;-</span> <span class="fu">import</span>(<span class="st">"data/pcs.csv"</span>)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(pcs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] "TE1"  "TE2"  "TE3"  "TE4"  "TE5"  "OE1"  "OE2"  "OE3"  "OE4"  "LVA1"
[11] "LVA2" "LVA3" "LVA4" "EM1"  "EM2"  "EM3"  "EM4"  "EM5"  "EM6" </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>modBf <span class="ot">&lt;-</span> <span class="st">"</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="st">gen =~ TE1+TE2+TE3+TE4+TE5+OE1+OE2+OE3+OE4+LVA1+LVA2+LVA3+LVA4 +EM1+EM2+EM3+EM4+EM5+EM6</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="st">s1 =~ TE1 + TE2 + TE3 + TE4 + TE5</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="st">s2 =~ OE1 + OE2 + OE3 + OE4</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="st">s3 =~ LVA1 + LVA2 + LVA3 + LVA4</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="st">s4 =~ EM1 + EM2 + EM3 + EM4 + EM5 + EM6</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="st">"</span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a><span class="co">#Specify model</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>fitBf <span class="ot">&lt;-</span> <span class="fu">cfa</span>(modBf, <span class="at">data=</span>pcs, <span class="at">std.lv=</span>T, <span class="at">estimator=</span><span class="st">'MLR'</span>, <span class="at">orthogonal=</span>T)</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a><span class="co">#Retrieving the results</span></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fitBf, <span class="at">fit.measures=</span><span class="cn">TRUE</span>, <span class="at">standardized=</span>T)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-19 ended normally after 36 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        57

                                                  Used       Total
  Number of observations                           154         172

Model Test User Model:
                                              Standard      Scaled
  Test Statistic                               211.382     182.509
  Degrees of freedom                               133         133
  P-value (Chi-square)                           0.000       0.003
  Scaling correction factor                                  1.158
    Yuan-Bentler correction (Mplus variant)                       

Model Test Baseline Model:

  Test statistic                              2799.877    2260.239
  Degrees of freedom                               171         171
  P-value                                        0.000       0.000
  Scaling correction factor                                  1.239

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.970       0.976
  Tucker-Lewis Index (TLI)                       0.962       0.970
                                                                  
  Robust Comparative Fit Index (CFI)                         0.978
  Robust Tucker-Lewis Index (TLI)                            0.972

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)              -3456.819   -3456.819
  Scaling correction factor                                  1.269
      for the MLR correction                                      
  Loglikelihood unrestricted model (H1)      -3351.128   -3351.128
  Scaling correction factor                                  1.191
      for the MLR correction                                      
                                                                  
  Akaike (AIC)                                7027.638    7027.638
  Bayesian (BIC)                              7200.744    7200.744
  Sample-size adjusted Bayesian (SABIC)       7020.331    7020.331

Root Mean Square Error of Approximation:

  RMSEA                                          0.062       0.049
  90 Percent confidence interval - lower         0.046       0.031
  90 Percent confidence interval - upper         0.077       0.065
  P-value H_0: RMSEA &lt;= 0.050                    0.108       0.520
  P-value H_0: RMSEA &gt;= 0.080                    0.025       0.000
                                                                  
  Robust RMSEA                                               0.053
  90 Percent confidence interval - lower                     0.032
  90 Percent confidence interval - upper                     0.071
  P-value H_0: Robust RMSEA &lt;= 0.050                         0.387
  P-value H_0: Robust RMSEA &gt;= 0.080                         0.005

Standardized Root Mean Square Residual:

  SRMR                                           0.038       0.038

Parameter Estimates:

  Standard errors                             Sandwich
  Information bread                           Observed
  Observed information based on                Hessian

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  gen =~                                                                
    TE1               1.041    0.071   14.715    0.000    1.041    0.843
    TE2               1.045    0.084   12.430    0.000    1.045    0.794
    TE3               0.848    0.090    9.392    0.000    0.848    0.721
    TE4               0.984    0.075   13.097    0.000    0.984    0.834
    TE5               1.004    0.082   12.264    0.000    1.004    0.819
    OE1               0.787    0.083    9.537    0.000    0.787    0.631
    OE2               0.819    0.080   10.207    0.000    0.819    0.695
    OE3               0.738    0.089    8.319    0.000    0.738    0.605
    OE4               0.742    0.087    8.512    0.000    0.742    0.636
    LVA1              0.937    0.084   11.180    0.000    0.937    0.796
    LVA2              0.863    0.071   12.205    0.000    0.863    0.797
    LVA3              0.816    0.085    9.649    0.000    0.816    0.719
    LVA4              0.865    0.098    8.802    0.000    0.865    0.695
    EM1               0.968    0.095   10.215    0.000    0.968    0.715
    EM2               0.930    0.078   11.957    0.000    0.930    0.800
    EM3               0.959    0.091   10.542    0.000    0.959    0.731
    EM4               0.885    0.091    9.679    0.000    0.885    0.732
    EM5               1.043    0.086   12.121    0.000    1.043    0.816
    EM6               1.108    0.100   11.054    0.000    1.108    0.750
  s1 =~                                                                 
    TE1               0.351    0.114    3.071    0.002    0.351    0.285
    TE2               0.451    0.144    3.142    0.002    0.451    0.343
    TE3               0.402    0.170    2.360    0.018    0.402    0.342
    TE4               0.162    0.111    1.457    0.145    0.162    0.137
    TE5               0.269    0.154    1.747    0.081    0.269    0.219
  s2 =~                                                                 
    OE1               0.626    0.107    5.860    0.000    0.626    0.502
    OE2               0.516    0.096    5.399    0.000    0.516    0.438
    OE3               0.673    0.107    6.291    0.000    0.673    0.552
    OE4               0.739    0.085    8.738    0.000    0.739    0.634
  s3 =~                                                                 
    LVA1              0.253    0.107    2.357    0.018    0.253    0.215
    LVA2              0.573    0.081    7.081    0.000    0.573    0.529
    LVA3              0.422    0.104    4.051    0.000    0.422    0.372
    LVA4              0.528    0.104    5.074    0.000    0.528    0.424
  s4 =~                                                                 
    EM1               0.506    0.152    3.324    0.001    0.506    0.374
    EM2               0.346    0.086    4.026    0.000    0.346    0.298
    EM3               0.567    0.121    4.682    0.000    0.567    0.432
    EM4               0.562    0.098    5.707    0.000    0.562    0.464
    EM5               0.479    0.097    4.930    0.000    0.479    0.375
    EM6               0.651    0.148    4.403    0.000    0.651    0.440

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  gen ~~                                                                
    s1                0.000                               0.000    0.000
    s2                0.000                               0.000    0.000
    s3                0.000                               0.000    0.000
    s4                0.000                               0.000    0.000
  s1 ~~                                                                 
    s2                0.000                               0.000    0.000
    s3                0.000                               0.000    0.000
    s4                0.000                               0.000    0.000
  s2 ~~                                                                 
    s3                0.000                               0.000    0.000
    s4                0.000                               0.000    0.000
  s3 ~~                                                                 
    s4                0.000                               0.000    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .TE1               0.318    0.067    4.777    0.000    0.318    0.209
   .TE2               0.434    0.088    4.913    0.000    0.434    0.251
   .TE3               0.501    0.104    4.827    0.000    0.501    0.363
   .TE4               0.397    0.066    5.987    0.000    0.397    0.285
   .TE5               0.421    0.073    5.799    0.000    0.421    0.281
   .OE1               0.546    0.106    5.129    0.000    0.546    0.350
   .OE2               0.451    0.075    6.003    0.000    0.451    0.325
   .OE3               0.490    0.117    4.183    0.000    0.490    0.330
   .OE4               0.263    0.071    3.718    0.000    0.263    0.194
   .LVA1              0.442    0.064    6.873    0.000    0.442    0.320
   .LVA2              0.100    0.062    1.607    0.108    0.100    0.085
   .LVA3              0.443    0.075    5.892    0.000    0.443    0.344
   .LVA4              0.523    0.088    5.954    0.000    0.523    0.337
   .EM1               0.639    0.100    6.388    0.000    0.639    0.349
   .EM2               0.365    0.060    6.049    0.000    0.365    0.271
   .EM3               0.482    0.090    5.383    0.000    0.482    0.280
   .EM4               0.364    0.083    4.395    0.000    0.364    0.249
   .EM5               0.318    0.063    5.032    0.000    0.318    0.195
   .EM6               0.534    0.117    4.564    0.000    0.534    0.244
    gen               1.000                               1.000    1.000
    s1                1.000                               1.000    1.000
    s2                1.000                               1.000    1.000
    s3                1.000                               1.000    1.000
    s4                1.000                               1.000    1.000</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fitmeasures</span>(fitBf)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                         npar                          fmin 
                       57.000                         0.686 
                        chisq                            df 
                      211.382                       133.000 
                       pvalue                  chisq.scaled 
                        0.000                       182.509 
                    df.scaled                 pvalue.scaled 
                      133.000                         0.003 
         chisq.scaling.factor                baseline.chisq 
                        1.158                      2799.877 
                  baseline.df               baseline.pvalue 
                      171.000                         0.000 
        baseline.chisq.scaled            baseline.df.scaled 
                     2260.239                       171.000 
       baseline.pvalue.scaled baseline.chisq.scaling.factor 
                        0.000                         1.239 
                          cfi                           tli 
                        0.970                         0.962 
                   cfi.scaled                    tli.scaled 
                        0.976                         0.970 
                   cfi.robust                    tli.robust 
                        0.978                         0.972 
                         nnfi                           rfi 
                        0.962                         0.903 
                          nfi                          pnfi 
                        0.925                         0.719 
                          ifi                           rni 
                        0.971                         0.970 
                  nnfi.scaled                    rfi.scaled 
                        0.970                         0.896 
                   nfi.scaled                   pnfi.scaled 
                        0.919                         0.715 
                   ifi.scaled                    rni.scaled 
                        0.977                         0.976 
                  nnfi.robust                    rni.robust 
                        0.972                         0.978 
                         logl             unrestricted.logl 
                    -3456.819                     -3351.128 
                          aic                           bic 
                     7027.638                      7200.744 
                       ntotal                          bic2 
                      154.000                      7020.331 
            scaling.factor.h1             scaling.factor.h0 
                        1.191                         1.269 
                        rmsea                rmsea.ci.lower 
                        0.062                         0.046 
               rmsea.ci.upper                rmsea.ci.level 
                        0.077                         0.900 
                 rmsea.pvalue                rmsea.close.h0 
                        0.108                         0.050 
        rmsea.notclose.pvalue             rmsea.notclose.h0 
                        0.025                         0.080 
                 rmsea.scaled         rmsea.ci.lower.scaled 
                        0.049                         0.031 
        rmsea.ci.upper.scaled           rmsea.pvalue.scaled 
                        0.065                         0.520 
 rmsea.notclose.pvalue.scaled                  rmsea.robust 
                        0.000                         0.053 
        rmsea.ci.lower.robust         rmsea.ci.upper.robust 
                        0.032                         0.071 
          rmsea.pvalue.robust  rmsea.notclose.pvalue.robust 
                        0.387                         0.005 
                          rmr                    rmr_nomean 
                        0.056                         0.056 
                         srmr                  srmr_bentler 
                        0.038                         0.038 
          srmr_bentler_nomean                          crmr 
                        0.038                         0.040 
                  crmr_nomean                    srmr_mplus 
                        0.040                         0.038 
            srmr_mplus_nomean                         cn_05 
                        0.038                       118.233 
                        cn_01                           gfi 
                      127.659                         0.877 
                         agfi                          pgfi 
                        0.824                         0.614 
                          mfi                          ecvi 
                        0.775                         2.113 </code></pre>
</div>
</div>
<p>From the results above, we can the bifactor model fits the PCS data well, with robust model-fit statistics, CFI = 0.978, TLI = 0.972, RMSEA = 0.053. Thus, it is reasonable to calculate <span class="math inline">\(ω_h\)</span> to estimate how reliably the PCS total score measures the general psychological-cost factor.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">reliability</span>(fitBf)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>             gen         s1        s2        s3        s4
alpha  0.9638781 0.92504205 0.8992820 0.9052459 0.9405882
omega  0.9741033 0.56377307 0.7884791 0.6766430 0.7816839
omega2 0.9094893 0.09237594 0.3666293 0.1880759 0.2054075
omega3 0.9077636 0.09240479 0.3666634 0.1878380 0.2053012
avevar        NA         NA        NA        NA        NA</code></pre>
</div>
</div>
<p>The values shown under the “gen” column relate to the general psychological cost factor. The omega estimate (0.974) doesn’t take the specific factors into account when calculating the variance of the total score, so it’s not the appropriate reliability measure for the PCS total score. Instead, the <strong>omega2</strong> and <strong>omega3</strong> values under “gen” represent <strong>omega hierarchical (</strong><span class="math inline">\(ω_h\)</span>). The difference between them is that <strong>omega2</strong> uses the model-implied variance of the total score, while <strong>omega3</strong> relies on the observed variance from the sample.</p>
<p>In simple terms, both <span class="math inline">\(ω_h\)</span> values tell us that <strong>91% of the variance in the PCS total score</strong> is explained by the general psychological cost factor, after accounting for the specific factors that influence different content areas.</p>
</section>
<section id="higher-order-models" class="level3">
<h3 class="anchored" data-anchor-id="higher-order-models">Higher-Order Models</h3>
<p>In the bifactor model example, I treated the multidimensional nature of the PCS items as a distraction when measuring a broad, general psychological cost construct. However, in other cases, researchers may propose a different structure where a broad overarching factor indirectly influences all the test items by acting through more specific, narrower constructs that directly affect different subsets of items. This kind of setup suggests a <strong>higher-order model</strong>, where a higher-order (or second-order) factor drives differences in several lower-order (first-order) factors, which, in turn, influence the individual item responses.</p>
<p>In this model, researchers assess how well the test captures both the overall score (reflecting the broad higher-order construct) and the subscale scores (reflecting the more specific lower-order constructs).</p>
<p>When the data fit a higher-order model, the reliability of the total score is measured by <strong>omega-higher-order (</strong><span class="math inline">\(ω_{ho}\)</span>), which represents the proportion of the total score’s variance that can be attributed to the higher-order factor. The calculation of ωho uses parameter estimates from the higher-order model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Specify the higher-order factor model for the PCS items</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>homod <span class="ot">&lt;-</span> <span class="st">'TE =~ TE1 + TE2 + TE3 + TE4 + TE5 </span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="st">      OE =~ OE1 + OE2 + OE3 + OE4</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="st">      LV =~ LVA1 + LVA2 + LVA3 + LVA4</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="st">      EM =~ EM1 + EM2 + EM3 + EM4 + EM5 + EM6</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="st">      cost =~ TE + OE + LV + EM'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Estimate the model and get the results</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>fitHo <span class="ot">&lt;-</span> <span class="fu">cfa</span>(homod, <span class="at">data=</span>pcs, <span class="at">std.lv=</span>T, <span class="at">estimator=</span><span class="st">'MLM'</span>)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fitHo, <span class="at">fit.measures=</span>T)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-19 ended normally after 57 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        42

                                                  Used       Total
  Number of observations                           154         172

Model Test User Model:
                                              Standard      Scaled
  Test Statistic                               243.444     185.699
  Degrees of freedom                               148         148
  P-value (Chi-square)                           0.000       0.019
  Scaling correction factor                                  1.311
    Satorra-Bentler correction                                    

Model Test Baseline Model:

  Test statistic                              2799.877    2282.637
  Degrees of freedom                               171         171
  P-value                                        0.000       0.000
  Scaling correction factor                                  1.227

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.964       0.982
  Tucker-Lewis Index (TLI)                       0.958       0.979
                                                                  
  Robust Comparative Fit Index (CFI)                         0.981
  Robust Tucker-Lewis Index (TLI)                            0.978

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)              -3472.850   -3472.850
  Loglikelihood unrestricted model (H1)      -3351.128   -3351.128
                                                                  
  Akaike (AIC)                                7029.700    7029.700
  Bayesian (BIC)                              7157.252    7157.252
  Sample-size adjusted Bayesian (SABIC)       7024.315    7024.315

Root Mean Square Error of Approximation:

  RMSEA                                          0.065       0.041
  90 Percent confidence interval - lower         0.050       0.021
  90 Percent confidence interval - upper         0.079       0.056
  P-value H_0: RMSEA &lt;= 0.050                    0.052       0.832
  P-value H_0: RMSEA &gt;= 0.080                    0.039       0.000
                                                                  
  Robust RMSEA                                               0.047
  90 Percent confidence interval - lower                     0.020
  90 Percent confidence interval - upper                     0.066
  P-value H_0: Robust RMSEA &lt;= 0.050                         0.592
  P-value H_0: Robust RMSEA &gt;= 0.080                         0.002

Standardized Root Mean Square Residual:

  SRMR                                           0.045       0.045

Parameter Estimates:

  Standard errors                           Robust.sem
  Information                                 Expected
  Information saturated (h1) model          Structured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  TE =~                                               
    TE1               0.356    0.067    5.289    0.000
    TE2               0.364    0.065    5.554    0.000
    TE3               0.299    0.059    5.056    0.000
    TE4               0.323    0.058    5.605    0.000
    TE5               0.338    0.065    5.198    0.000
  OE =~                                               
    OE1               0.641    0.074    8.642    0.000
    OE2               0.616    0.060   10.334    0.000
    OE3               0.630    0.066    9.523    0.000
    OE4               0.647    0.064   10.078    0.000
  LV =~                                               
    LVA1              0.442    0.056    7.836    0.000
    LVA2              0.457    0.059    7.751    0.000
    LVA3              0.427    0.059    7.286    0.000
    LVA4              0.460    0.056    8.258    0.000
  EM =~                                               
    EM1               0.509    0.069    7.394    0.000
    EM2               0.462    0.066    7.018    0.000
    EM3               0.517    0.074    6.955    0.000
    EM4               0.483    0.067    7.179    0.000
    EM5               0.535    0.069    7.756    0.000
    EM6               0.595    0.080    7.430    0.000
  cost =~                                             
    TE                2.914    0.595    4.894    0.000
    OE                1.223    0.155    7.880    0.000
    LV                1.951    0.281    6.933    0.000
    EM                1.900    0.327    5.809    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .TE1               0.321    0.063    5.081    0.000
   .TE2               0.473    0.069    6.837    0.000
   .TE3               0.531    0.100    5.289    0.000
   .TE4               0.398    0.073    5.494    0.000
   .TE5               0.418    0.070    5.935    0.000
   .OE1               0.531    0.099    5.353    0.000
   .OE2               0.440    0.081    5.428    0.000
   .OE3               0.495    0.099    5.001    0.000
   .OE4               0.315    0.055    5.719    0.000
   .LVA1              0.443    0.081    5.466    0.000
   .LVA2              0.170    0.035    4.851    0.000
   .LVA3              0.412    0.064    6.473    0.000
   .LVA4              0.533    0.090    5.945    0.000
   .EM1               0.637    0.085    7.508    0.000
   .EM2               0.367    0.062    5.872    0.000
   .EM3               0.493    0.075    6.564    0.000
   .EM4               0.387    0.064    6.017    0.000
   .EM5               0.315    0.062    5.059    0.000
   .EM6               0.554    0.085    6.515    0.000
   .TE                1.000                           
   .OE                1.000                           
   .LV                1.000                           
   .EM                1.000                           
    cost              1.000                           </code></pre>
</div>
</div>
<section id="lets-obtain-omega-ho-from-a-higher-order-model-for-the-psychological-cost-scale" class="level4">
<h4 class="anchored" data-anchor-id="lets-obtain-omega-ho-from-a-higher-order-model-for-the-psychological-cost-scale">Let’s obtain omega-ho from a higher-order model for the Psychological Cost Scale</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">reliabilityL2</span>(fitHo, <span class="st">'cost'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       omegaL1        omegaL2 partialOmegaL1 
     0.9088176      0.9410190      0.9734520 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Obtain omega estimates for the subscale scores as measures of the lower-order factors</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="fu">reliability</span>(fitHo)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              TE        OE        LV        EM
alpha  0.9250420 0.8992820 0.9052459 0.9405882
omega  0.9260209 0.9000548 0.9077522 0.9415490
omega2 0.9260209 0.9000548 0.9077522 0.9415490
omega3 0.9256773 0.9014397 0.9125259 0.9404921
avevar 0.7155347 0.6925123 0.7111716 0.7299181</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="exploratory-omega-estimates" class="level2">
<h2 class="anchored" data-anchor-id="exploratory-omega-estimates">Exploratory Omega Estimates</h2>
<p>So far, the examples have relied on semTools’ <code>reliability</code> (or <code>reliabilityL2</code>) function to calculate omega estimates based on CFA models. However, these omega estimates are only valid if the underlying model for the test is correctly specified. For instance, using <span class="math inline">\(ω_u\)</span> as a reliability estimate wouldn’t be appropriate if the true model is multidimensional, as indicated by a poor fit for a single-factor model.</p>
<p>When a hypothesized CFA model doesn’t adequately fit the data—which is common in the early stages of test development—Exploratory Factor Analysis (EFA) can help identify the test’s dimensional structure. After determining the optimal number of factors for a test, you can use the <code>omega</code> function from the <strong>psych</strong> package (Revelle, 2020) to estimate omega based on the EFA parameters. This estimate will reflect the proportion of total score variance attributable to a general factor that influences all items.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Determine number of factors</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="fu">n_factors</span>(pcs, <span class="at">package =</span> <span class="st">"all"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Method Agreement Procedure:

The choice of 4 dimensions is supported by 7 (25.93%) methods out of 27 (beta, Scree (SE), EGA (glasso), Velicer's MAP, BIC, Fit_off, BIC).</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Determine omega for 4 factor model</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="fu">omega</span>(pcs, <span class="at">nfactors =</span> <span class="dv">4</span>, <span class="at">plot =</span> F)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required namespace: GPArotation</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Omega 
Call: omegah(m = m, nfactors = nfactors, fm = fm, key = key, flip = flip, 
    digits = digits, title = title, sl = sl, labels = labels, 
    plot = plot, n.obs = n.obs, rotate = rotate, Phi = Phi, option = option, 
    covar = covar)
Alpha:                 0.96 
G.6:                   0.98 
Omega Hierarchical:    0.85 
Omega H asymptotic:    0.88 
Omega Total            0.98 

Schmid Leiman Factor loadings greater than  0.2 
        g   F1*   F2*   F3*   F4*   h2   h2   u2   p2  com
TE1  0.81              0.39       0.81 0.81 0.19 0.80 1.50
TE2  0.76              0.40       0.75 0.75 0.25 0.77 1.53
TE3  0.70              0.35       0.62 0.62 0.38 0.80 1.52
TE4  0.78              0.29       0.72 0.72 0.28 0.84 1.41
TE5  0.77              0.34       0.74 0.74 0.26 0.80 1.46
OE1  0.61        0.55             0.67 0.67 0.33 0.56 2.02
OE2  0.67        0.46             0.66 0.66 0.34 0.68 1.81
OE3  0.61        0.54             0.68 0.68 0.32 0.54 2.02
OE4  0.63        0.62             0.80 0.80 0.20 0.50 2.02
LVA1 0.75                    0.28 0.67 0.67 0.33 0.85 1.37
LVA2 0.80                    0.48 0.87 0.87 0.13 0.73 1.66
LVA3 0.71        0.20        0.37 0.71 0.71 0.29 0.72 1.69
LVA4 0.70                    0.43 0.67 0.67 0.33 0.72 1.68
EM1  0.69  0.39                   0.66 0.66 0.34 0.73 1.64
EM2  0.76  0.38                   0.75 0.75 0.25 0.77 1.57
EM3  0.72  0.47                   0.73 0.73 0.27 0.71 1.76
EM4  0.72  0.48                   0.74 0.74 0.26 0.70 1.76
EM5  0.78  0.43                   0.81 0.81 0.19 0.76 1.59
EM6  0.73  0.48                   0.78 0.78 0.22 0.68 1.78

With Sums of squares  of:
    g   F1*   F2*   F3*   F4*    h2 
 9.95  1.21  1.29  0.70  0.68 10.16 

general/max  0.98   max/min =   14.84
mean percent general =  0.72    with sd =  0.1 and cv of  0.13 
Explained Common Variance of the general factor =  0.72 

The degrees of freedom are 101  and the fit is  1 
The number of observations was  172  with Chi Square =  161.11  with prob &lt;  0.00013
The root mean square of the residuals is  0.02 
The df corrected root mean square of the residuals is  0.03
RMSEA index =  0.059  and the 10 % confidence intervals are  0.041 0.076
BIC =  -358.79

Compare this with the adequacy of just a general factor and no group factors
The degrees of freedom for just the general factor are 152  and the fit is  4.49 
The number of observations was  172  with Chi Square =  732.57  with prob &lt;  8.2e-77
The root mean square of the residuals is  0.1 
The df corrected root mean square of the residuals is  0.11 

RMSEA index =  0.149  and the 10 % confidence intervals are  0.139 0.16
BIC =  -49.85 

Measures of factor score adequacy             
                                                 g  F1*  F2*  F3*  F4*
Correlation of scores with factors            0.93 0.79 0.86 0.72 0.77
Multiple R square of scores with factors      0.86 0.63 0.73 0.52 0.59
Minimum correlation of factor score estimates 0.73 0.26 0.47 0.04 0.18

 Total, General and Subset omega for each subset
                                                 g  F1*  F2*  F3* F4*
Omega total for total scores and subscales    0.98 0.94 0.90 0.92 0.9
Omega general for total scores and subscales  0.85 0.69 0.52 0.76 0.7
Omega group for total scores and subscales    0.08 0.25 0.38 0.16 0.2</code></pre>
</div>
</div>
<p>The results from the exploratory factor analysis indicate that the four-factor model provides a strong fit, with an overall omega total of 0.98, suggesting excellent reliability for the total score. The omega hierarchical value of 0.85 indicates that 85% of the total-score variance is attributable to a general factor, showing that the general psychological cost factor plays a dominant role in explaining the variance across items. Additionally, the individual subscales also show good reliability, with their omega total values ranging from 0.90 to 0.94.</p>
</section>
</section>
<section id="chapter-2--simple-linear-regression-slr" class="level1">
<h1>Chapter 2- Simple Linear Regression (SLR)</h1>
<p>Linear model and Linear regression are technically synonyms and we often use either terms when quantifying the effect of a “<strong>continuous”</strong> independent variable on a”<strong>continuous”</strong> dependent variable. The difference between this and ANOVA is that <strong>ANOVA</strong> is usually used when quantifying the effect of a “<strong>discrete (or categorical)”</strong> independent variable on a”<strong>continuous”</strong> dependent variable. So, it is important to note that- <em>ANOVA is also a linear regression!</em> In fact, if you run “anova” function on linear model object, you’ll most likely get the same p-value.</p>
<p><strong>Regression</strong> generally refers to the fact that we are quantifying the relationship between a response variable and (one or more) predictor variables. In the case of <strong>SLR</strong>, both the response and the predictor are <em>numeric</em> variables and we are using a single predictor (independent) variable. Later we will use multiple predictor variables (multiple regression). Also, this models tells us that our model for Y is a linear combination of the predictors X. (In this case just one predictor)! For now, this always results in a model that is a line, but this is not always the case (and we may see this later on in the tutorial).</p>
<p>Like ANOVA, in SLR, we often talk about the assumptions that this model makes. This include-</p>
<ol type="1">
<li>Linearity- the relationship between Y and x is linear, of the form <span class="math inline">\(\beta_0 + \beta_1x\)</span>.</li>
<li>Independent. The errors <span class="math inline">\(\epsilon\)</span> are independent.</li>
<li>Normality. The errors, <span class="math inline">\(\epsilon\)</span> are normally distributed. I.e. the “error” around the line follows a normal distribution.</li>
<li>Equality of Variance. At each value of x, the variance of Y is the same.</li>
</ol>
<p>To learn extensively about the model assumptions, you may want to check this invited lecture I gave last Winter. <a href="https://drhammed.github.io/Biol322_2024_lecture/#2">Testing Model Assumptions</a>.</p>
<p>For this lab, we will be using a year dataset on Corvettes sales in Virginia Beach, Virginia. Using this data, ten Corvettes (between 1 and 6yrs old) were randomly selected and the below data shows the sales price (in hundreds of dollars) denoted by y and the age (in years) denoted by x.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Corvettes-01.PNG" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<section id="tasks" class="level4">
<h4 class="anchored" data-anchor-id="tasks">Tasks</h4>
<ol type="1">
<li>Graph the data in a scatterplot to determine if there is a possible linear relationship.</li>
<li>Compute and interpret the linear correlation coefficient, r.</li>
<li>Determine the regression equation for the data.</li>
<li>Graph the regression equation and the data points.</li>
<li>Identify outliers and potential influential observations.</li>
<li>Compute and interpret the coefficient of determination, r2.</li>
<li>Obtain the residuals and create a residual plot. Decide whether it is reasonable to consider that the assumptions for regression analysis are met by the variables in questions.</li>
<li>Using 5% significance level, can we say the data provide sufficient evidence to conclude that the slope of the population regression line is not 0 and, hence, that age is useful as a predictor of sales price for Corvettes?</li>
<li>Obtain and interpret a 95% confidence interval for the slope, β, of the population regression line that relates age to sales price for Corvettes.</li>
<li>Obtain a point estimate for the mean sales price of all 4-year-old Corvettes.</li>
<li>Determine a 95% confidence interval for the mean sales price of all 4-year-old Corvettes.</li>
<li>Find the predicted sales price of Jack Smith’s 4-year-old Corvette.</li>
<li>Determine a 95% prediction interval for the sales price of Jack Smith’s 4-year-old Corvette.</li>
</ol>
<p>This is the <a href="https://drive.google.com/drive/folders/1nb1zgxr_IIV9271-BWmffmMSukOYf3ja?usp=sharing">link</a> to the main google drive folder for all the data to complete this tutorial!</p>
<p>To start, we need to load in the packages and data</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>pacman<span class="sc">::</span><span class="fu">p_load</span>(ggplot2,dplyr,ggplot2,ggpubr,lmtest,data.table,car)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"data/corvettes.csv"</span>)</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Rename columns ( x = Age and y = Price)</span></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">Age =</span> x, <span class="at">Price =</span> y)</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a><span class="co">#check the first few rows</span></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Age Price
1   6 12500
2   6 11500
3   6 13000
4   4 16000
5   2 21900
6   5 15000</code></pre>
</div>
</div>
<p><strong>1: Graph the Data in a Scatterplot</strong> Let’s create a scatterplot to visualize the relationship between Age and SalesPrice. Also, we can rename the x and y to be Age and Price respectively.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatterplot of Age vs. SalesPrice</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> Age, <span class="at">y =</span> Price)) <span class="sc">+</span></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Scatterplot of Age vs. Sales Price"</span>, <span class="at">x =</span> <span class="st">"Age"</span>, <span class="at">y =</span> <span class="st">"Price"</span>) <span class="sc">+</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-25-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Interpretation- The points seem to follow a linear pattern, although with a negative relationship.</p>
<p><strong>2: Compute and Interpret the Linear Correlation Coefficient</strong></p>
<p>The Pearson Correlation is a statistical method that calculates the strength and direction of linear relationships between continuous variables. It produces a sample correlation coefficient, r, which can be used to evaluate whether there is a linear relationship among the same variables in the population. This population correlation coefficient is represented by ρ (“rho”) and is a parametric measure.</p>
<p>Pearson correlation indicates:</p>
<ul>
<li><p>Whether there is a statistically significant linear relationship between two continuous variables</p></li>
<li><p>It also shows the strength of this linear relationship (i.e., how close the relationship is to being a perfectly straight line)</p></li>
<li><p>Finally, it reveals the direction of this linear relationship (increasing or decreasing)</p></li>
</ul>
<p>It is however important to note that Pearson Correlation cannot address non-linear relationships or relationships among categorical variables. To address relationships that involve categorical variables and/or non-linear relationships, you need to consider the equivalent non-parametric test (e.g., Spearman’s rank correlation).</p>
<p>Also, while Pearson Correlation reveals <em>associations</em> among (continuous) variables, you should remember that “<em>Correlation</em> <em>does not imply causation,</em>” no matter how large the correlation coefficient is.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute correlation</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>df_cor <span class="ot">&lt;-</span> <span class="fu">cor</span>(df<span class="sc">$</span>Age, df<span class="sc">$</span>Price)</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>df_cor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -0.9678716</code></pre>
</div>
</div>
<p><strong>Interpretation</strong></p>
<p>The correlation coefficient is <strong>-0.968</strong>. This r-value indicates a robust negative linear correlation, given its proximity to -1 and negative sign. This strong negative linear correlation suggests that data points should closely cluster around a downward-sloping regression line, (<em>which aligns with the graph above</em>). Consequently, the presence of a strong negative linear relationship between Age and Price supports the continuation of linear regression analysis.</p>
<p><strong>3. Regression equation for the data.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit linear model</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(Price <span class="sc">~</span> Age, <span class="at">data =</span> df)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a><span class="co"># model summary</span></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = Price ~ Age, data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-1999.03  -781.31   -63.59   896.12  2420.39 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  29160.2     1143.3   25.51 5.98e-09 ***
Age          -2790.3      256.3  -10.89 4.48e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1425 on 8 degrees of freedom
Multiple R-squared:  0.9368,    Adjusted R-squared:  0.9289 
F-statistic: 118.5 on 1 and 8 DF,  p-value: 4.484e-06</code></pre>
</div>
</div>
<p>From the output, we can interpret the regression equation:</p>
<p>Price = <span class="math inline">\(\beta_0\)</span> <span class="math inline">\(+\)</span> <span class="math inline">\(\beta_1 .\)</span> Age</p>
<p>where <span class="math inline">\(\beta_0\)</span>​ is the intercept and <span class="math inline">\(\beta_1\)</span>​ is the slope.</p>
<p>So, from the result above, the regression equation is: Price = 29160.2 - (2790.3)(Age). So what if a newly sold Corvettes was 10years old? What would be the price? <em>Y</em> = 29160.2 - (2790.3)(10) which equals $1257.2</p>
<p><strong>4: Graph the Regression Equation and the Data Points</strong></p>
<p>Add the regression line to our scatterplot.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatterplot with regression line &amp; equation</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> Age, <span class="at">y =</span> Price)) <span class="sc">+</span></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">"blue"</span>) <span class="sc">+</span></span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_regline_equation</span>(</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">label =</span> ..eq.label..),</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">label.x =</span> <span class="dv">3</span>, <span class="at">label.y =</span> <span class="fu">max</span>(df<span class="sc">$</span>Price) <span class="sc">-</span> <span class="dv">1000</span>, </span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">coef.digits =</span> <span class="dv">2</span></span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add R^2</span></span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_regline_equation</span>(</span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">label =</span> ..rr.label..),</span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">label.x =</span> <span class="dv">3</span>, <span class="at">label.y =</span> <span class="fu">max</span>(df<span class="sc">$</span>Price), </span>
<span id="cb53-15"><a href="#cb53-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">rr.digits =</span> <span class="dv">2</span></span>
<span id="cb53-16"><a href="#cb53-16" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb53-17"><a href="#cb53-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Scatterplot with Regression Line"</span>, <span class="at">x =</span> <span class="st">"Age"</span>, <span class="at">y =</span> <span class="st">"Price"</span>) <span class="sc">+</span></span>
<span id="cb53-18"><a href="#cb53-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in stat_regline_equation(aes(label = ..eq.label..), label.x = 3, :
Ignoring unknown parameters: `coef.digits`</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in stat_regline_equation(aes(label = ..rr.label..), label.x = 3, :
Ignoring unknown parameters: `rr.digits`</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: The dot-dot notation (`..eq.label..`) was deprecated in ggplot2 3.4.0.
ℹ Please use `after_stat(eq.label)` instead.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-28-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>5: Identify Outliers</strong></p>
<p>From the plot, there seem to be no points that lie far from the cluster of data points or far from the regression line; thus, no possible outliers.</p>
<p><strong>6. Compute and interpret the coefficient of determination,</strong> <span class="math inline">\(r^2\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># r-squared value</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>rsquared <span class="ot">&lt;-</span> <span class="fu">summary</span>(mod)<span class="sc">$</span>r.squared</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>rsquared</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9367754</code></pre>
</div>
</div>
<p>The <span class="math inline">\(r^2\)</span> = 0.937; therefore, about 93.7% of the variation in the price data is explained by age. I.e., as the car gets older, the value/price drops! The regression equation appears to be very useful for making predictions since the value of <span class="math inline">\(r^2\)</span> is close to 1.</p>
<p>Note- we also have adjusted R-square. R-square technically measures the variation of a regression model (variation in Y given x). R-squared either increases or remains the same when new predictors are added to the model. Adjusted R-squared measures the variation for a multiple regression model, and helps you determine goodness of fit. For the purpose of this SLR (one predictor, we are not adding more), so we can decide to intepret any of them. But if you have multiple predictors, you may want to look into Adj. <span class="math inline">\(r^2\)</span>)!</p>
<p><strong>7. Residuals</strong></p>
<p>Let’s plot residuals to check for patterns, which can indicate whether regression assumptions are met.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get residuals</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>residuals <span class="ot">&lt;-</span> <span class="fu">resid</span>(mod)</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Residual plot</span></span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> Age, <span class="at">y =</span> residuals)) <span class="sc">+</span></span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Residual Plot"</span>, <span class="at">x =</span> <span class="st">"Age"</span>, <span class="at">y =</span> <span class="st">"Residuals"</span>) <span class="sc">+</span></span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-30-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>We can also check the assumption of constant variance using the Breusch-Pagan Test.</p>
<p>The <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_a\)</span> can be considered to be:</p>
<p><span class="math inline">\(H_0\)</span> : Homoscedasticity. The errors have constant variance about the true model.</p>
<p><span class="math inline">\(H_a\)</span> : Heteroscedasticity. The errors have non-constant variance about the true model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">bptest</span>(mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    studentized Breusch-Pagan test

data:  mod
BP = 2.293, df = 1, p-value = 0.13</code></pre>
</div>
</div>
<p><strong>Interpretation</strong>- The residual plot shows a random scatter of the points. Here, we can see that at any fitted value, the mean of the residuals is roughly 0. As such, the linearity assumption holds true.In fact, that is why we generally add a horizontal line at <span class="math inline">\(y = 0\)</span> to emphasize this point.</p>
<p>Also, from the bpTest, we see a large p-value (0.13), so we do not reject the null hypothesis of homoscedasticity, and thus conclude constant variance assumption about the true model.</p>
<p><strong>Also, to assess the normality of the residuals</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Q-Q Plot of Residuals</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">sample =</span> residuals)) <span class="sc">+</span></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_qq</span>() <span class="sc">+</span></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_qq_line</span>(<span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Q-Q Plot of Residuals"</span>, <span class="at">x =</span> <span class="st">"Theoretical Quantiles"</span>, <span class="at">y =</span> <span class="st">"Sample Quantiles"</span>) <span class="sc">+</span></span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-32-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>We can also use the shapiro test to confirm the normality</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">shapiro.test</span>(<span class="fu">resid</span>(mod))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Shapiro-Wilk normality test

data:  resid(mod)
W = 0.97896, p-value = 0.9594</code></pre>
</div>
</div>
<p><span class="math inline">\(H_0\)</span>: The residuals are normally distributed.</p>
<p><span class="math inline">\(H_a\)</span>: The residuals are not normally distributed.</p>
<p>If the p-value is low (&lt; 0.05), it suggests evidence against the <span class="math inline">\(H_0\)</span>, indicating that the residuals may not follow a normal distribution. However, if the p-value is high (&gt; 0.05), it supports the <span class="math inline">\(H_0\)</span>, suggesting that the residuals are approximately normally distributed.</p>
<p>In short, we can say if the points of the plot do not closely follow a straight line, this would suggest that the data do not come from a normal distribution.</p>
<p><strong>8. Using 5% significance level, can we say the data provide sufficient evidence to conclude that the slope of the population regression line is not 0 and, hence, that age is useful as a predictor of sales price for Corvettes?</strong></p>
<p>Here, we need to state the hypothesis. The hypothesis from the question above is that-</p>
<p><span class="math inline">\(H_0\)</span>: <span class="math inline">\(\beta = 0\)</span> (Age is not a useful predictor of price.)</p>
<p><span class="math inline">\(H_a\)</span>: <span class="math inline">\(\beta \neq 0\)</span> (Age is a useful predictor of price.)</p>
<p>Now that we’ve done that, remember our alpha = 0.05 and our critical value or rejection region is that we should reject the null hypothesis if alpha is less than 0.05. Finally, to answer the question, check the regression output and see the “coefficient”. From the result of the regression, you can see that p-value &lt;0.001</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get p-value for slope</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>p_value <span class="ot">&lt;-</span> <span class="fu">summary</span>(mod)<span class="sc">$</span>coefficients[<span class="dv">2</span>, <span class="dv">4</span>]</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>p_value</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4.484274e-06</code></pre>
</div>
</div>
<p><strong>Interpretation</strong>- Since the P-value &lt; 0.05, we have evidence to reject the null hypothesis. In other words, we have enough evidence to conclude that the slope of the population regression line is not zero. In other words, age is a useful predictor of price for Corvettes.</p>
<p><strong>9. Obtain and interpret a 95% confidence interval for the slope, β , of the population regression line that relates age to sales price for Corvettes.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 95% confidence interval for the slope</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(mod, <span class="st">"Age"</span>, <span class="at">level =</span> <span class="fl">0.95</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        2.5 %    97.5 %
Age -3381.295 -2199.288</code></pre>
</div>
</div>
<p>Look at the result above, We are 95% confident that the slope of the true regression line is somewhere between -3381.295 and -2199.288. In other words, we are 95% confident that for every year older Corvettes get, their average price decreases somewhere between $3,381.295 and $2,199.288.</p>
<p><strong>10. Obtain a point estimate for the mean sales price of all 4-year-old Corvettes.</strong></p>
<p>We can use the model to predict the mean price for a Corvette of age 4.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict mean sales price for age 4</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mod, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">Age =</span> <span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       1 
17999.03 </code></pre>
</div>
</div>
<p>Look at the result, the point estimate (PRE_1) is $17,999.03.</p>
<p><strong>11. Determine a 95% confidence interval for the mean sales price of all 4-year-old Corvettes.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 95% confidence interval for mean price of 4-year-old Corvettes</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mod, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">Age =</span> <span class="dv">4</span>), <span class="at">interval =</span> <span class="st">"confidence"</span>, <span class="at">level =</span> <span class="fl">0.95</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       fit      lwr     upr
1 17999.03 16958.46 19039.6</code></pre>
</div>
</div>
<p>From the result, we are 95% confident that the mean sales price of all four-year-old Corvettes is somewhere between $16,958.46 and $19,039.6.</p>
<p><strong>12. Find the predicted sales price of Jack Smith’s selected 4-year-old Corvette.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicted sales price for a specific 4-year-old Corvette</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mod, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">Age =</span> <span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       1 
17999.03 </code></pre>
</div>
</div>
<p>The predicted sales price is $17,999.03.</p>
<p><strong>13. Determine a 95% prediction interval for the sales price of Jack Smith’s 4-year-old Corvette.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 95% prediction interval for Jack's 4-year-old Corvette</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mod, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">Age =</span> <span class="dv">4</span>), <span class="at">interval =</span> <span class="st">"prediction"</span>, <span class="at">level =</span> <span class="fl">0.95</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       fit      lwr      upr
1 17999.03 14552.92 21445.14</code></pre>
</div>
</div>
<p>We are 95% certain that the individual sales price of Jack Smithʼs Corvette will be somewhere between $14,552.92 and $21,445.14.</p>
</section>
</section>
<section id="chapter-3--multiple-linear-regression" class="level1">
<h1>Chapter 3- Multiple Linear Regression</h1>
<p>So far, we have learned how to calculate a linear regression equation and make predictions. However, what if there are other potential independent variables to consider? In fact, It is uncommon for a dataset or research study to have only one predictor. Similarly, it is rare for a response variable to depend solely on a single variable. In this chapter, we will expand our simple linear regression (SLR) model to include multiple predictors. Multiple regression allows us to incorporate multiple independent variables and assign weights to each of them, resulting in more accurate predictions. The process of conducting a multiple regression in R is similar to that of linear regression, with the difference being the inclusion of additional independent variables.</p>
<p>For this lab, we shall be using the “autompg” dataset containing car information. This dataset provides data on fuel economy from 1999 and 2008 for about 38 popular models of cars. It contains a response variable known as “mpg,” which records the city fuel efficiency of cars, alongside several predictor variables detailing the vehicle attributes. You can download the data from our google drive folder. See the link <a href="https://drive.google.com/file/d/1Hk_w8GMsFSajXT4sj57zhzax1oCm1zew/view?usp=sharing">here</a>. For anyone using R, you can find the dataset loaded with the <em>ggplot2</em> package.</p>
<p><em>Brief description of the variables in the data</em></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">Variable</th>
<th style="text-align: left;">Type</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">mpg</td>
<td style="text-align: left;">numeric</td>
<td style="text-align: left;">city fuel efficiency</td>
</tr>
<tr class="even">
<td style="text-align: left;">cyl</td>
<td style="text-align: left;">integer</td>
<td style="text-align: left;">number of cylinders</td>
</tr>
<tr class="odd">
<td style="text-align: left;">displ</td>
<td style="text-align: left;">numeric</td>
<td style="text-align: left;">engine displacement in liters</td>
</tr>
<tr class="even">
<td style="text-align: left;">hp</td>
<td style="text-align: left;">numeric</td>
<td style="text-align: left;">horse power</td>
</tr>
<tr class="odd">
<td style="text-align: left;">wt</td>
<td style="text-align: left;">numeric</td>
<td style="text-align: left;">Weight</td>
</tr>
<tr class="even">
<td style="text-align: left;">acc</td>
<td style="text-align: left;">numeric</td>
<td style="text-align: left;">acceleration</td>
</tr>
<tr class="odd">
<td style="text-align: left;">year</td>
<td style="text-align: left;">integer</td>
<td style="text-align: left;">year of manufacturing</td>
</tr>
</tbody>
</table>
<p>At this point, our focus will be on utilizing two variables, “wt” and “year,” as predictor variables. In other words, we aim to create a model that predicts a car’s fuel efficiency (mpg) based on its weight (wt) and the model year (year). To achieve this, we will formulate the following linear model:</p>
<p><span class="math display">\[ Y_i = \beta_i + \beta_1X_1 + \beta_2X_2 + \epsilon_i, \hspace4ex i = 1, 2, …,n\]</span></p>
<p>where <span class="math inline">\(\epsilon_i \sim N(0,\alpha^2)\)</span> , <span class="math inline">\(x_{i1}\)</span> = the weight (wt) of the <span class="math inline">\(i\)</span> car, and <span class="math inline">\(x_{i2}\)</span> as the model year (year) of the <span class="math inline">\(i\)</span> car.</p>
<p><strong>Load the data</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>auto <span class="ot">&lt;-</span> <span class="fu">fread</span>(<span class="st">"data/autompg.csv"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Task- before we do for multiple predictors, let’s quickly revist SLR and use one predictor. For this part, perform a simple linear regression of mpg against wt. What’s the R-squared? is weight a good predictor of mpg? (refer back to the tutorial on SLR- we just covered all of that)!</strong></p>
<p>Your model summary should look like below.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/model_summary_mpg_vs_wt-01.PNG" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p><em>Okay, now that we have done that- we can proceed to multiple linear regression. Recall, we want to build a model with mpg as dependent variable, while wt and year as independent variables.</em></p>
<section id="build-multiple-regression-in-r" class="level2">
<h2 class="anchored" data-anchor-id="build-multiple-regression-in-r">Build Multiple Regression in R</h2>
<p>Next, we’ll conduct a multiple linear regression using mpg as the dependent variable and both wt and year as predictors.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the multiple linear regression model</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>mlr_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> wt <span class="sc">+</span> year, <span class="at">data =</span> auto)</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mlr_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = mpg ~ wt + year, data = auto)

Residuals:
   Min     1Q Median     3Q    Max 
-8.852 -2.292 -0.100  2.039 14.325 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -1.464e+01  4.023e+00  -3.638 0.000312 ***
wt          -6.635e-03  2.149e-04 -30.881  &lt; 2e-16 ***
year         7.614e-01  4.973e-02  15.312  &lt; 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.431 on 387 degrees of freedom
Multiple R-squared:  0.8082,    Adjusted R-squared:  0.8072 
F-statistic: 815.6 on 2 and 387 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p><strong>Questions</strong></p>
<ol type="1">
<li>Looking at the result, you should see tables that are similar to the ones in our previous example (our model summary is new). Take a look at the “model summary” to determine the new R squared and Standard Error of the Estimate. Compare that with the previous regression output- <strong><em>has the inclusion of additional variables (year) resulted in an improvement in our model</em></strong>?</li>
</ol>
<p>Note- <em>the new R squared has improved, and the Standard Error has reduced! This indicates that our multiple regression model is more precise than the previous linear regression model.</em></p>
<ol start="2" type="1">
<li><strong><em>Do all our variables hold statistical significance</em></strong>?</li>
</ol>
<p>You can verify this by checking the table. The Pr(&gt; t|) indicate whether our independent variables have a statistically significant association with our dependent variable. It also helps us determine whether our model is a good fit for explaining the variation in the mpg.</p>
<p>In our case, we have evidence to believe it is, given that the significance is way below 0.05 (&lt;0.001).</p>
<p>Lastly, check the “estimate” column. Here we find the value for each of our independent variables (wt and year) and also the intercept.</p>
<p>So, how can we write our multiple regression equation? mpg (<em>Y</em>) = -14.64 – 0.0066(weight) + 0.761(year). Thus, if we added a new car and had some basic data like the year and weight, we would be able to estimate, with a relatively high degree of confidence, how many mpg would be used given the predictors.</p>
<p><strong>Interpretation</strong></p>
<p>Here, the constant = -14.64 represents our estimate for the intercept, i.e.- the mean miles per gallon for a car that has a weight of 0 pounds and was manufactured in 1900 (the start year of our dataset). As we can see here that the estimate is negative, which, in the real world, is physically impossible. However, this is not surprising because we cannot realistically expect our model to accurately predict the fuel efficiency of cars from 1900 that weigh 0 pounds because such vehicles never existed anyways! So, like simple linear regression, this value (intercept) represent the mean of Y when all predictors are set to 0.</p>
<p>However, the interpretation of the coefficients of our predictors is slightly different from previous SLR. For instance, the estimate of -0.0066 for “wt” = the expected average change in miles per gallon for a one-unit increase in weight for cars of a specific model year, with the year being held constant. Note that this estimate is negative, which aligns with our expectations, as, in general, fuel efficiency tends to decrease for larger vehicles. However, in the context of multiple linear regression, this interpretation is contingent upon a fixed value for another predictor, such as “year” in our case. This means that the relationship between fuel efficiency and weight might not hold true when additional factors, like the model year, are taken into account, potentially causing a reversal in the sign of our coefficient.</p>
<p>Lastly, the estimate of 0.761 for “year” = the expected average change in miles per gallon for a one-year increase in the model year for cars with a specific weight, where weight is held constant now. It is not far from expectation that this estimate is positive since one would anticipate that, over time, as technology advances, cars with the specific weight would achieve better fuel efficiency compared to their earlier counterparts.</p>
<p>Note- Sometimes, you may discover that the model is not statistically significant, or that one independent variable does not hold statistical significance. In such instances, you may want to rerun the model, eliminating insignificant or redundant variables. Ideally, it is good to do some variable importance selection on your predictors before including them in the model (or use some prior knowledge of the system). It may take several attempts to run multiple regression models to find the best-fitting model for the data. Generally, it is good to have model with a low standard error of the estimate, high R squared and relatively simple. A model with three independent variables, a relatively high R squared and low standard error may be preferable to a model with 19 independent variables and a high R squared and low standard error (this is why variable importance is crucial)!</p>
<p>To do variable importance selection, you can calculate the multicollinearity. In R, you can compute the Variance Inflation Factor (VIF).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate VIF for the multiple linear regression model</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>vif_mod <span class="ot">&lt;-</span> <span class="fu">vif</span>(mlr_model)</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>vif_mod</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      wt     year 
1.103646 1.103646 </code></pre>
</div>
</div>
<p>The VIF values indicate the degree of multicollinearity for each variable in the model. In our case, the VIF (for both wt and year) is around 1.104. Ideally, a VIF of 1 means that variables are not correlated and no multicollinearity in the regression model. Generally, a VIF &gt;6 is considered a sign of high multicollinearity between the predictor variables and can affect the stability and interpretability of your regression model. You may need to address multicollinearity by either removing one of the correlated variables (redundant) or you can use dimensionality reduction techniques like Principal Component Analysis (PCA) to reduce dimensions.</p>
</section>
</section>
<section id="chapter-4--least-square-approach" class="level1">
<h1>Chapter 4- Least Square Approach</h1>
<p>So far, we’ve talked about simple linear regression and its assumption and that simple linear regression models the dependent variable Y as a <strong>linear</strong> function of independent variable (or variables in the case of multiple predictors) X. This means we would expect a plot similar to the one below (you can use this <a href="https://drive.google.com/file/d/18BoUebca3hSG2nn_T545hSbxY526zIMg/view?usp=sharing">dataset</a> to reproduce the plot (<em>make a scatter plot of weight vs height</em>).</p>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-44-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Looking at the plot, do you think this line best summarizes the trend between the students height and weight?</p>
<p>Before we proceed, let’s introduce equation of the best fitting line.</p>
<p><span class="math display">\[\hat{y} = \beta_0 + \beta_1 x_1\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(\hat{y}_i\)</span> is the predicted response (or fitted value) for experimental unit <em>i</em></p></li>
<li><p><span class="math inline">\(y_i\)</span> denotes the observed response for experimental unit <em>i</em></p></li>
<li><p><span class="math inline">\(x_i\)</span> denotes the predictor value for experimental unit <em>i</em></p></li>
</ul>
<p>Now, let’s apply this formula on the plot above. Remember from the plot above, our regression equation is <span class="math inline">\(\hat{y}\)</span> = -266.53 + 6.14x or <span class="math inline">\(\hat{weight}\)</span> = -266.53 + 6.14 height</p>
<p>The first data on the plot shows that student 1 has a height of 63 inches and a weight of around 127 pounds (i.e.&nbsp;<span class="math inline">\(x_1\)</span> = 63 and <span class="math inline">\(y_1\)</span> = 127). Assuming we know this student’s height but not weight, we could use the equation of the line to predict the student’s weight. Thus, we’d predict the student’s weight to be -266.53 + 6.14(63) or 120.29 pounds. Which means our predicted y (<span class="math inline">\(\hat{y}\)</span>) = 120.29 pounds. Apparently, this is not the same as can be seen on the plot (<span class="math inline">\(y_1\)</span> = 127) and this means we have <strong>prediction</strong> or <strong>residual error</strong>. As a matter of fact, the residual error can be calculated as 127-120.29= 6.71 pounds. You can do the same for all values of x (heights) and get your observed (y) responses, your predicted responses and residual errors. In summary, when we use the equation <span class="math inline">\(\hat{y} = \beta_0 + \beta_1 x_1\)</span> to make prediction of the actual response of <span class="math inline">\(y_i\)</span>, we make prediction or residual error <span class="math inline">\(e_i = y_i - \hat{y}\)</span> (which means that the size of the residual error depends on the data point).</p>
<p>An important question, however, is “What is the best fitting line or how do we define a good line”? There are several lines we could use, and our aim is to identify one that is characterized by “minimal errors.” In other words, a line that fits the data “<strong>best</strong>” will be one where the <strong><em>n</em></strong> <strong>prediction errors, —</strong> each corresponding to an observed data point <strong>— are minimized overall</strong>. The next question is then, how do we identify such a line? There are numerous methods we could employ for this purpose. One way to achieve this is by applying the “<strong>least squares approach</strong>” which means we need to find the line that “minimizes the sum of squared prediction errors. In other words, we need to find the values of <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> that can make the sum of the squared residual errors as minimal as possible.</p>
<p>Mathematically, we need to find the values of <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> that minimizes</p>
<p><span class="math display">\[\text Q = \sum^{n}_{i==1} (y_i - \hat{y})^2\]</span></p>
<p>Where our</p>
<ul>
<li><p>prediction (residual) error for data point <em>i</em> = <span class="math inline">\(y_i - \hat{y}_i\)</span></p></li>
<li><p>the squared prediction (residual) error for data point <em>i</em> = <span class="math inline">\((y_i - \hat{y}_i)^2\)</span></p></li>
<li><p>Lastly, the summation symbol indicate that we should add up the squared prediction (residual) errors for all <em>n</em> data points.</p></li>
</ul>
<p>So, to summarize, imagine you fit two lines to the data and you want to know which one best describe the trend, you’d pick the line with the lowest sum of squared residual (prediction) error as the <strong>best line</strong>.</p>
<p>From the plot above, note that that if we (manually) adopt the least square method described above to find the equation of the line that minimizes the sum of squared residual error, we may encounter big issues. Specifically, we would need to execute this procedure for an infinite variety of potential lines (not convenient!). Luckily, someone has already done the laborious work of deducing formulas for both the intercept and slope in the equation of the line that minimizes the sum of squared residual error (derived using Calculus).</p>
<p>Here, we minimize the equation for the sum of the squared residual errors:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/LS_formula1.PNG" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>thus, we can get our least squares estiates for <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> by taking the derivative with respect to <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>, set to 0, and solve for <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>:</p>
<p><img src="images/LS_formula2-01.PNG" class="img-fluid"></p>
<p>and:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/b1_form-02.PNG" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>Given that the formulas for <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> are derived using the least square approach, you may see the regression equation being referred to as the <strong>least squares line, least squares regression line or the estimated regression equation</strong>. However, it is important to note that in this approach, we’ve made no distributional assumption about the data. We assumed they’re fixed and not random and follow a linear trend.</p>
<p>Ideally, you won’t have to worry about the formulas for <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> and this is because, there are so many statistical software that can find the least squares for you. However, a question that often pop-up is that- why do we try to minimize the sum of <em>squared</em> errors rather than just the errors themselves? The reason is that if we didn’t square the residual error above, the positive and negative residual errors would cancel each other out when we sum them, consequently yielding 0. This approach is referred to as <em>least squares</em> because it aims to <em>minimize</em> the sum of <em>squared</em> errors, thereby seeking to determine <em>the least squares.</em></p>
<section id="example-of-least-square-approach-using-data" class="level3">
<h3 class="anchored" data-anchor-id="example-of-least-square-approach-using-data">Example of Least Square Approach using data</h3>
<p>For this, we would use the “car” dataset. This is an open dataset available in R software (and online). Very briefly, it shows the relationship between the speed and stopping distance of cars. You can downoad it from our google folder <a href="https://drive.google.com/file/d/1_VhFQlnLENbyYVXNWlDGYDc6x5QdMznX/view?usp=sharing">here</a>. load this dataset to your R.</p>
<p>Traditionally, we would now compute <span class="math inline">\(\hat{b_1}\)</span> and <span class="math inline">\(\hat{b_0}\)</span> for the cars dataset. However, like I explained above, we can easily allow R or other software to do this for us.</p>
<p>From the data, note that our x = speed and y = dist. From your data, we need to calculate the three sums of squares defined above. For simplicity, we will regard to the summation sign above as “S”.</p>
<p>So, compute Sxy, Sxx, Syy</p>
<p>Sxy = sum((x - mean(x)) * (y - mean(y))) Sxx = sum((x - mean(x)) ^ 2) Syy = sum((y - mean(y)) ^ 2) c(Sxy, Sxx, Syy)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the built-in cars dataset in R</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"cars"</span>)</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define x and y from the car dataset</span></span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> cars<span class="sc">$</span>speed</span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> cars<span class="sc">$</span>dist</span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a><span class="co"># get the means of x and y</span></span>
<span id="cb84-9"><a href="#cb84-9" aria-hidden="true" tabindex="-1"></a>mean_x <span class="ot">&lt;-</span> <span class="fu">mean</span>(x)</span>
<span id="cb84-10"><a href="#cb84-10" aria-hidden="true" tabindex="-1"></a>mean_y <span class="ot">&lt;-</span> <span class="fu">mean</span>(y)</span>
<span id="cb84-11"><a href="#cb84-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-12"><a href="#cb84-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute Sxy, Sxx, Syy</span></span>
<span id="cb84-13"><a href="#cb84-13" aria-hidden="true" tabindex="-1"></a>Sxy <span class="ot">&lt;-</span> <span class="fu">sum</span>((x <span class="sc">-</span> mean_x) <span class="sc">*</span> (y <span class="sc">-</span> mean_y))</span>
<span id="cb84-14"><a href="#cb84-14" aria-hidden="true" tabindex="-1"></a>Sxx <span class="ot">&lt;-</span> <span class="fu">sum</span>((x <span class="sc">-</span> mean_x)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb84-15"><a href="#cb84-15" aria-hidden="true" tabindex="-1"></a>Syy <span class="ot">&lt;-</span> <span class="fu">sum</span>((y <span class="sc">-</span> mean_y)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb84-16"><a href="#cb84-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-17"><a href="#cb84-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the results</span></span>
<span id="cb84-18"><a href="#cb84-18" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">Sxy =</span> Sxy, <span class="at">Sxx =</span> Sxx, <span class="at">Syy =</span> Syy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     Sxy      Sxx      Syy 
 5387.40  1370.00 32538.98 </code></pre>
</div>
</div>
<p>Finally, we need to calculate the <span class="math inline">\(\hat{b_0}\)</span> and <span class="math inline">\(\hat{b_1}\)</span></p>
<p><span class="math inline">\(\hat{\beta_1}\)</span> = Sxy / Sxx</p>
<p><span class="math inline">\(\hat{\beta_0}\)</span> = mean(y) - <span class="math inline">\(\hat{\beta_1}\)</span> * mean(x)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate beta_1 (slope)</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>beta_1 <span class="ot">&lt;-</span> Sxy <span class="sc">/</span> Sxx</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate beta_0 (intercept)</span></span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>beta_0 <span class="ot">&lt;-</span> mean_y <span class="sc">-</span> beta_1 <span class="sc">*</span> mean_x</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a><span class="co"># print results</span></span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">beta_0 =</span> beta_0, <span class="at">beta_1 =</span> beta_1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    beta_0     beta_1 
-17.579095   3.932409 </code></pre>
</div>
</div>
<section id="interpretation" class="level4">
<h4 class="anchored" data-anchor-id="interpretation"><strong>Interpretation</strong></h4>
<p><strong>What do these values tell us about our dataset?</strong></p>
<p>Let’s use the regression line formula again, <span class="math inline">\(\hat{y} = \beta_0 + \beta_1 x_1\)</span></p>
<p>or more formal way,</p>
<p><span class="math inline">\(\hat{y}_{i, dist} = \beta_0 + \beta_1 {x_1,speed}\)</span></p>
<p>Remember <span class="math inline">\(\hat{\beta_0}\)</span> is the constant (intercept) and <span class="math inline">\(\hat{\beta_1}\)</span> is the slope.</p>
<p>From the result, the slope parameter <span class="math inline">\(\hat{\beta_1}\)</span> tells us that for every unit increase in speed of one mile per hour, the <strong>mean</strong> stopping distance increases by <span class="math inline">\(\hat{\beta_1}\)</span>. It is important to note that we’re talking about the mean estimate- If you remember, from the formula of equation of best fit line <span class="math inline">\(\beta_0 + \beta_1 x_1\)</span> represent the mean of y (here, distance) for a particular value of <span class="math inline">\(x\)</span> (speed). So, the slope (<span class="math inline">\(\hat{\beta_1}\)</span>) tells us how the mean of distance is affected by speed.</p>
<p>Specifically, the <span class="math inline">\(\hat{\beta_1}\)</span> = 3.93 implies that for every unit increase in speed (of one mile per hour), the <strong>estimated</strong> <em>mean</em> stopping distance increases by 3.93ft. Also note the word “estimated” since <span class="math inline">\(\hat{y}\)</span> is the estimated mean of the observed response Y, so <span class="math inline">\(\hat{\beta_1}\)</span> tells us how the estimated mean of Y is affected by changing <span class="math inline">\(x\)</span>.</p>
<p><strong>What does</strong> <span class="math inline">\(b_0\)</span> <strong>tell us?</strong></p>
<p>In a very brief term, the intercept (or <span class="math inline">\(\hat{\beta_0}\)</span>) represent the value of Y when all the predictors = 0 (i.e.- <strong>mean</strong> stopping distance for a car traveling zero miles per hour or not moving at all).</p>
<p>Here, the <span class="math inline">\(\hat{\beta_0}\)</span> tells us that a vechicle travelling at zero mile per hour is predicted to have -17.58 stopping distance. In other words, the estimated mean stopping distance for a car not moving is−17.58 ft. Obviously this doesn’t make sense, because does that mean when you apply the brakes to a car that is not moving, it moves backwards? Anyways this is not surprising becuase we “extrapolated” beyond the range of the x values (model scope). It doesn’t make sense to say you’re travelling at speed of zero miles per hour (so intercept here doesn’t make much sense)! More information on extrapolation can be found in this <a href="https://blog.minitab.com/en/adventures-in-statistics-2/regression-analysis-how-to-interpret-the-constant-y-intercept">blog</a> and we will see more of it shortly below in the tutorial.</p>
</section>
</section>
<section id="predictions" class="level3">
<h3 class="anchored" data-anchor-id="predictions">Predictions</h3>
<p>Let’s rewrite the estimated regression line</p>
<p><span class="math inline">\(\hat{y}_{i, dist} = \beta_0 + \beta_1 {x_1, speed}\)</span></p>
<p><span class="math inline">\(\hat{y}_i = -17.58 + 3.93x\)</span></p>
<p>or</p>
<p><span class="math inline">\(\hat{dist}_i = -17.58 + 3.93speed\)</span></p>
<p>We can now use this equation to make predictions. If you check the data, the speed ranges from 4 to 25.</p>
<p><strong>Question 1</strong>- Can we make a prediction for the stopping distance of a car traveling at 9 miles per hour?.</p>
<p><strong><em>Hint- It’s easy, slot in 9 in the equation above (</em></strong><span class="math inline">\(-17.58 + 3.93speed\)</span><strong><em>). Your answer should be ~17.79 (</em></strong>This tells us that the estimated mean stopping distance of a car traveling at 9 miles per hour is 17.79<strong><em>).</em></strong></p>
<p><strong>In the same way, we can make predictions for unknown data or unseen time point.</strong> For example,</p>
<p><strong>Question 2-</strong> make a prediction for the stopping distance of a car traveling at 6 miles per hour. This is referred to as <strong>interpolation</strong> as 6 is not an observed value of speed (But it is in the data range.)- you can check the speed and you’d agree that 6 is not there. Your answer should be <strong>6</strong></p>
<p>Finally, we can make a prediction for the stopping distance of a car that is outside of the data range (<strong>extrapolation!</strong>)</p>
<p><strong>Question 3-</strong> make a prediction for the stopping distance of a car traveling at 100 miles per hour. This is extrapolation as 100 is not within the range of speed and not an observed value. So, we are only transferring our model to that time point (learning from the model- Machine Learning)! <strong><em>Your answer should be = 375.42ft</em></strong></p>
<p>Although cars can travel 100 miles per hour today (although with fines from police), but maybe not many years ago! This is quite similar to the similar issue when interpreting <span class="math inline">\(\hat{b_0} = -17.58\)</span> (that is estimated mean stopping distance when speed = 0). This implies that we should be less confident in the estimated linear relationship outside our data range.</p>
</section>
<section id="residuals" class="level3">
<h3 class="anchored" data-anchor-id="residuals">Residuals</h3>
<p>Recall our residual formula, <span class="math inline">\(e_i = y_i - \hat{y_i}\)</span></p>
<p>We can calculate the residual for the prediction we made for a car traveling 9 miles per hour. First, we need to obtain the observed value of distance for this speed value (10). You can look at the data table, what’s the value of distance when speed = 9?</p>
<p>Answer, dist == 10.</p>
<p>Then, we calculate our <span class="math inline">\(e = 10 - 17.81\)</span> = -7.81.</p>
<p>The negative residual value indicates that the observed stopping distance is actually 7.81 feet less than what was predicted.</p>
</section>
<section id="estimating-the-variance" class="level3">
<h3 class="anchored" data-anchor-id="estimating-the-variance">Estimating the Variance</h3>
<p>We can now use the residuals for each data point to compute the variance</p>
<p>In regression case, for each <span class="math inline">\(y_i\)</span>, we can use a different estimate of the mean, that is <span class="math inline">\(\hat{y_i}\)</span> to calculate the variancee.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Calculate Predicted Values and Residuals</span></span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicted values (y-hat) based on the linear model</span></span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>y_hat <span class="ot">&lt;-</span> beta_0 <span class="sc">+</span> beta_1 <span class="sc">*</span> x</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Residuals (y - y-hat)</span></span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a>residuals <span class="ot">&lt;-</span> y <span class="sc">-</span> y_hat</span>
<span id="cb88-7"><a href="#cb88-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-8"><a href="#cb88-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-9"><a href="#cb88-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-10"><a href="#cb88-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, we can calculate the residual variance</span></span>
<span id="cb88-11"><a href="#cb88-11" aria-hidden="true" tabindex="-1"></a>variance <span class="ot">&lt;-</span> <span class="fu">sum</span>(residuals<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> (<span class="fu">length</span>(y) <span class="sc">-</span> <span class="dv">2</span>)</span>
<span id="cb88-12"><a href="#cb88-12" aria-hidden="true" tabindex="-1"></a>variance</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 236.5317</code></pre>
</div>
</div>
<p>Similar to the univariate measure of variance, variance = 236.53 lacks a meaningful practical interpretation in this context of stopping distance. However, by taking the square root, we can obtain the standard deviation of the residuals, often referred to as the <em>residual standard error.</em></p>
<p><strong>Question- take the square root to compute the residual standard error</strong></p>
<p>Your residual standard error should be ~ <strong>15.38.</strong></p>
<p><strong>Interpretation</strong>- This indicates that our average estimates of stopping distance are generally inaccurate by approximately 15.38 feet.</p>
</section>
<section id="variation-decomposition" class="level3">
<h3 class="anchored" data-anchor-id="variation-decomposition">Variation Decomposition</h3>
<p>Here, we will briefly define 3 of the metrics used for decomposition of variation.</p>
<section id="sum-of-squares-total" class="level4">
<h4 class="anchored" data-anchor-id="sum-of-squares-total">1. Sum of Squares Total</h4>
<p>The term “Sum of Squares Total,” denoted as SST, represent the total variation present in the observed y values.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/SST.PNG" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="sum-of-squares-regression" class="level4">
<h4 class="anchored" data-anchor-id="sum-of-squares-regression">2. Sum of Squares Regression</h4>
<p>The term “Sum of Squares Regression,” often abbreviated as SSReg, denotes the portion of variation in the observed y values that can be accounted for or explained by the regression.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/SSReg.PNG" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="sum-of-squares-error" class="level4">
<h4 class="anchored" data-anchor-id="sum-of-squares-error">3. Sum of Squares Error</h4>
<p>The term “Sum of Squares Error,” (SSE), denotes the portion of variation in the observed y values that remains unexplained or unaccounted for. You may frequently see SSE written as RSS, which stands for “Residual Sum of Squares.”</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/SSE.PNG" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>Now, you can use the formula of each of them to calculate their values in R.</p>
<ul>
<li><p>SST = sum((y - mean(y)) ^ 2)</p></li>
<li><p>SSReg = sum((y_hat - mean(y)) ^ 2)</p></li>
<li><p>SSE = sum((y - y_hat) ^ 2)</p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Total Sum of Squares (SST)</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>SST <span class="ot">&lt;-</span> <span class="fu">sum</span>((y <span class="sc">-</span> <span class="fu">mean</span>(y))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Regression Sum of Squares (SSReg)</span></span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a>SSReg <span class="ot">&lt;-</span> <span class="fu">sum</span>((y_hat <span class="sc">-</span> <span class="fu">mean</span>(y))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Sum of Squares Error (SSE or RSS)</span></span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a>SSE <span class="ot">&lt;-</span> <span class="fu">sum</span>((y <span class="sc">-</span> y_hat)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the results</span></span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">SST =</span> SST, <span class="at">SSReg =</span> SSReg, <span class="at">SSE =</span> SSE)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     SST    SSReg      SSE 
32538.98 21185.46 11353.52 </code></pre>
</div>
</div>
<p>When looking at these 3 metrics individually, they kind of lack a significant practical interpretation. However, we will see now and we can use them collectively to show a new statistic that can measure the strength of regression model.</p>
</section>
</section>
<section id="coefficient-of-determination" class="level3">
<h3 class="anchored" data-anchor-id="coefficient-of-determination">Coefficient of Determination</h3>
<p>The coefficient of determination is the fraction of the observed variation in y that can be accounted for or explained by the regression model.</p>
<p><span class="math display">\[R^2 = \frac {SSReg} {SST}\]</span></p>
<p>or</p>
<p><span class="math display">\[R^2 = 1- \frac {SSE} {SST}\]</span></p>
<p><strong>Question</strong>- compute the <span class="math inline">\(R^2\)</span> for our example data in R</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate r-squared</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>R_squared <span class="ot">&lt;-</span> SSReg <span class="sc">/</span> SST</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>R_squared</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.6510794</code></pre>
</div>
</div>
<p>Interpretation- From our example dataset, our calculated <span class="math inline">\(R^2\)</span> = 0.65. Thus, we can conclude that 65% of the observed variation in stopping distance can be explained by the linear relationship with speed.</p>
</section>
</section>
<section id="chapter-5---moderation-and-mediation-analysis" class="level1">
<h1>Chapter 5 - Moderation and Mediation Analysis</h1>
<p>Moderation</p>
<p>In many cases, the relationship we want to explore extend beyond a simple pair of variables interacting with each other. Often, additional elements may shape the dynamics of these relationships. For example, there might be underlying factors that modify how two variables are connected or provide reasons for their association. These questions are important for a deeper understanding but cannot be addressed using the basic methods like a simple linear regression, for example. Those methods were limited to examining the direct effect between two variables (say X and Y) without the flexibility to incorporate extra factors that might be at play.</p>
<p>Moderation and mediation analyses allow us to incorporate one or more additional variables into our models, giving us a more comprehensive view of how various factors might influence the relationship between two primary variables. In a very basic way, moderation and mediation introduce an extra variable to the existing relationship. While it is possible to include multiple moderating or mediating variables, it is generally less common due to the added complexity and the challen ges associated with interpreting such complex models. When adding a single additional variable, these methods help us address specific questions:</p>
<ul>
<li><p><strong>Moderation:</strong> How does the strength or direction of the relationship between variables X and Y change at different levels of a third variable, M?</p></li>
<li><p><strong>Mediation:</strong> Does a third aditional variable, M, serve as a mechanism through which X influences Y?</p></li>
</ul>
<p>In this tutorial, we will cover the application of both moderation and mediation analyses using R. Essentially, you will learn the steps to perform these analyses, as well as how to interpret the outcomes.</p>
<section id="understanding-moderation-in-statistical-analysis" class="level2">
<h2 class="anchored" data-anchor-id="understanding-moderation-in-statistical-analysis">Understanding Moderation in Statistical Analysis</h2>
<p>Moderation examines how the relationship between two variables is influenced by a third variable. Specifically, it assesses the extent to which the impact of one variable on another varies depending on the level or presence of an additional variable.</p>
<p><strong>Assumptions Regarding the Dependent Variable:</strong></p>
<p>Moderation analysis relies on linear regression techniques, so the outcome variable should be <strong>continuous</strong>. Also, the predictors in the model can be either continuous or categorical (binary).</p>
<p>As with regression analysis, there are assumptions that are quite important here:</p>
<ul>
<li><p><strong>Linearity:</strong> A crucial assumption for moderation is that the interaction between the variables is linear. This implies that the effect of the independent variable (X) on the dependent variable (Y) changes at a consistent rate as the moderator variable (M) increases or decreases. Moreover, the primary relationship between X and Y should also be <strong>linear</strong>. Ensuring both the moderation effect and the original relationship are linear is essential for accurate interpretation.</p></li>
<li><p><strong>Other Assumptions:</strong> Beyond linearity, moderation shares the same assumptions as multiple regression, such as homoscedasticity, independence of errors, and normality of residuals.</p></li>
</ul>
<p>So, essentially, moderation analysis allows us to determine whether the relationship between two variables is shaped by a third variable. For accurate interpretation, both the moderation effect and the direct relationship between the primary variables should show linearity. Aside from this, moderation operates under the standard assumptions of multiple regression.</p>
<p>When we say that a moderator influences the relationship between two other variables, we mean that the nature or strength of that relationship changes based on the level or category of the moderator. In other words, the relationship between X and Y isn’t uniform across all conditions but varies with moderator M.</p>
<section id="exploring-moderation-and-its-relationship-to-interaction" class="level3">
<h3 class="anchored" data-anchor-id="exploring-moderation-and-its-relationship-to-interaction">Exploring Moderation and Its Relationship to Interaction</h3>
<p>As in any statistical models, we have to evaluate moderation effects through statistical methods. Ideally, if you visualize the relationship between two variables across different levels of a moderator and notice that the regression lines are not parallel, this indicates <strong>moderation</strong>. Why is that? Parallel lines suggest that the relationship between the two primary variables remains constant regardless of the moderator’s level, meaning the moderator doesn’t influence the relationship. However, if the lines have different slopes, it signifies that the strength or direction of the relationship changes depending on the moderator.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/interaction_1.png" class="img-fluid figure-img"></p>
<figcaption>Moderation Effect Plot</figcaption>
</figure>
</div>
<p>You might have heard of <strong>interaction</strong> terms before? This is technically the same logic. We say we have <em>interaction</em> when the effect of one variable on an outcome depends on the level of another variable. Essentially, this is what we’re observing with moderation. In fact, we call the graph illustrating non-parallel slopes as an “interaction plot” rather than a “moderation plot.” So, how do moderation and interaction differ?</p>
<p>I’d say the distinction between moderation and interaction is subtle and primarily lies in their interpretation rather than their mathematical foundation. Moderation implies a specific primary relationship: Variable X influences Variable Y, and Variable M alters this influence. In contrast, an interaction doesn’t necessarily assume a direct primary relationship. It simply indicates that both X and M are related to Y and that their combined effect on Y is not purely additive. This means that the relationship between X and Y might vary at different levels of M, or alternatively, the relationship between M and Y might change depending on the level of X. The interaction can work in either direction.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/mediation_model_1.png" class="img-fluid figure-img"></p>
<figcaption>Moderation</figcaption>
</figure>
</div>
</section>
<section id="example-age-as-a-moderator" class="level3">
<h3 class="anchored" data-anchor-id="example-age-as-a-moderator">Example – Age as a Moderator</h3>
<p>Imagine a study exploring the relationship between the number of hours employees engage in professional development activities and their overall job performance. Suppose a basic regression analysis reveals that more hours spent on professional development are associated with higher job performance:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co">#lm(job_performance ~ professional_hours, data = employee_data) %&gt;% summary()</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>However, we might wonder if this positive relationship is true for all employees, regardless of their age. Specifically, does the impact of professional development hours on job performance differ between younger employees and those who are more experienced or older? In this context, age acts as a potential moderator. We hypothesize that the effect of professional development on job performance may vary depending on an employee’s age group.</p>
<p><strong>Hypothesis:</strong></p>
<ul>
<li><p><strong>Younger Employees:</strong> Might benefit more from professional development hours as they are still building their skills and knowledge.</p></li>
<li><p><strong>Older Employees:</strong> May experience a different level of impact, possibly due to having more established skills or different learning preferences.</p></li>
</ul>
<p><strong>Simulating Data in R:</strong></p>
<p>To test this moderation effect, we can simulate some data in R. Here’s a basic example:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="co">#load libraries</span></span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>pacman<span class="sc">::</span><span class="fu">p_load</span>(dplyr, ggplot2,magrittr,interactions,Hmisc,mediation)</span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a><span class="co">#set seed</span></span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">999</span>)</span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-8"><a href="#cb95-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-9"><a href="#cb95-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's simulate data</span></span>
<span id="cb95-10"><a href="#cb95-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-11"><a href="#cb95-11" aria-hidden="true" tabindex="-1"></a><span class="co"># sample size</span></span>
<span id="cb95-12"><a href="#cb95-12" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb95-13"><a href="#cb95-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-14"><a href="#cb95-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate age with a higher probability for Younger and Older groups</span></span>
<span id="cb95-15"><a href="#cb95-15" aria-hidden="true" tabindex="-1"></a>employee_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb95-16"><a href="#cb95-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">professional_hours =</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">20</span>, <span class="at">sd =</span> <span class="dv">5</span>),</span>
<span id="cb95-17"><a href="#cb95-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">age =</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="dv">25</span><span class="sc">:</span><span class="dv">40</span>, <span class="dv">41</span><span class="sc">:</span><span class="dv">60</span>), n, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="fl">0.6</span><span class="sc">/</span><span class="dv">16</span>, <span class="dv">16</span>), <span class="fu">rep</span>(<span class="fl">0.4</span><span class="sc">/</span><span class="dv">20</span>, <span class="dv">20</span>))) )</span>
<span id="cb95-18"><a href="#cb95-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-19"><a href="#cb95-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-20"><a href="#cb95-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-21"><a href="#cb95-21" aria-hidden="true" tabindex="-1"></a><span class="co"># We can also create a binary moderator variable: Younger (&lt;=40) vs. Older (&gt;40)</span></span>
<span id="cb95-22"><a href="#cb95-22" aria-hidden="true" tabindex="-1"></a>employee_data <span class="ot">&lt;-</span> employee_data <span class="sc">%&gt;%</span></span>
<span id="cb95-23"><a href="#cb95-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">age_group =</span> <span class="fu">ifelse</span>(age <span class="sc">&lt;=</span> <span class="dv">40</span>, <span class="st">"Younger"</span>, <span class="st">"Older"</span>))</span>
<span id="cb95-24"><a href="#cb95-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-25"><a href="#cb95-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Assume job performance is influenced by professional_hours and moderated by age_group</span></span>
<span id="cb95-26"><a href="#cb95-26" aria-hidden="true" tabindex="-1"></a>employee_data <span class="ot">&lt;-</span> employee_data <span class="sc">%&gt;%</span></span>
<span id="cb95-27"><a href="#cb95-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">job_performance =</span> </span>
<span id="cb95-28"><a href="#cb95-28" aria-hidden="true" tabindex="-1"></a>           <span class="fu">ifelse</span>(age_group <span class="sc">==</span> <span class="st">"Younger"</span>, </span>
<span id="cb95-29"><a href="#cb95-29" aria-hidden="true" tabindex="-1"></a>                  <span class="dv">50</span> <span class="sc">+</span> <span class="dv">5</span> <span class="sc">*</span> professional_hours <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">500</span>, <span class="dv">0</span>, <span class="fl">1.5</span>), </span>
<span id="cb95-30"><a href="#cb95-30" aria-hidden="true" tabindex="-1"></a>                  <span class="dv">50</span> <span class="sc">+</span> <span class="dv">1</span> <span class="sc">*</span> professional_hours <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">500</span>, <span class="dv">0</span>, <span class="fl">1.5</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, we can fit the model. We are interested in how age influences the relationship between hours spent on professional development activities (professional_hours) and overall job performance (job_performance).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="co">#fit linear model first</span></span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(job_performance <span class="sc">~</span> professional_hours <span class="sc">+</span> age, <span class="at">data =</span> employee_data) <span class="sc">%&gt;%</span> <span class="fu">summary</span>()</span>
<span id="cb96-4"><a href="#cb96-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-5"><a href="#cb96-5" aria-hidden="true" tabindex="-1"></a>mod</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = job_performance ~ professional_hours + age, data = employee_data)

Residuals:
    Min      1Q  Median      3Q     Max 
-76.964 -15.344   1.889  16.449  47.747 

Coefficients:
                    Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)        176.85613    5.50243   32.14   &lt;2e-16 ***
professional_hours   3.49500    0.19917   17.55   &lt;2e-16 ***
age                 -3.25877    0.09528  -34.20   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 21.61 on 497 degrees of freedom
Multiple R-squared:  0.7487,    Adjusted R-squared:  0.7477 
F-statistic: 740.3 on 2 and 497 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>From the result above, we can see Intercept ~ 184.78251. This value represents the estimated job performance score for an employee who has zero hours of professional development. While an employee with no professional development hours is unlikely in a real-world scenario, the intercept provides a baseline for the model.</p>
<p>Professional Development Hours (3.25): The coefficient for professional_hours is 3.25, which is highly significant (p-value &lt; 2e-16). This means that we have a strong positive relationship between professional development hours and job performance. Also, for each additional hour an employee spends on professional development activities, their job performance score is expected to increase by approximately 3.25 units, holding age constant.</p>
<p>Age (-3.35): Each additional year of age is associated with a 3.35-unit decrease in job performance score, holding professional development hours constant. This negative relationship is also highly significant (p &lt; 2e-16), suggesting that older employees in this sample tend to have lower job performance scores when controlling for their professional development hours.</p>
<p>Statistical Significance: The p-value associated with professional_hours and age is &lt; 0.001. This confirms that the relationship between our independent variables and dependent variable (job performance) is statistically significant at all conventional level of significance.</p>
<p>Model Fit:</p>
<p>Multiple R-squared (0.7578): Approximately 75.78% of the variability in job performance is explained by professional development hours alone. Adjusted R-squared (0.7568): After adjusting for the number of predictors, about 75.68% of the variance in job performance is explained by the model. F-statistic (777.4, p &lt; 2.2e-16): The overall model is statistically significant, suggesting that professional development hours reliably predict job performance.</p>
<p><strong>Please note: Due to stochasticity, the values above may change slightly when you run yours since we’re using simulated data - but it should not change that much.</strong></p>
<p><strong>Note:</strong></p>
<p>The coefficients represent the unique main effects of each predictor. Specifically, professional development hours and age each have a significant impact on job performance independently of one another.</p>
<p>While this model highlights the direct individual relationships, it does not inform us about whether the effect of professional development hours on job performance varies by age. In other words, we haven’t yet tested if age moderates the relationship between professional development and job performance.</p>
<p>To explore whether age acts as a moderator, we need to include an interaction (moderation) term between professional_hours and age in our model. This will allow us to assess if the impact of professional development on job performance differs across different age groups.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Finally, fit a moderation model</span></span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(job_performance <span class="sc">~</span> professional_hours <span class="sc">*</span> age_group, <span class="at">data =</span> employee_data)</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = job_performance ~ professional_hours * age_group, 
    data = employee_data)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.3865 -1.0182 -0.1125  1.1429  4.5200 

Coefficients:
                                    Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)                         50.19846    0.49537 101.336   &lt;2e-16 ***
professional_hours                   0.99558    0.02436  40.863   &lt;2e-16 ***
age_groupYounger                    -0.24337    0.60698  -0.401    0.689    
professional_hours:age_groupYounger  4.00837    0.02989 134.119   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.531 on 496 degrees of freedom
Multiple R-squared:  0.9987,    Adjusted R-squared:  0.9987 
F-statistic: 1.312e+05 on 3 and 496 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>From the result above, we observe that the <span class="math inline">\(R^2\)</span> value has increased from 0.7578 in the initial multiple regression model to 0.9988 after introducing the interaction/moderation term. This increase indicates that the model with the interaction term fits the data significantly better. Additionally, once we add the interaction between professional_hours and age_group, the unique effect of age_group becomes non-significant. Why does this shift occur? By including the interaction, we appropriately attribute variance to the combined effect of professional_hours and age_group rather than isolating their individual linear effects. This adjustment provides a more accurate representation of each variable’s unique impact. It’s important to remember that in regression modeling, each coefficient reflects the unique main effect of its corresponding variable while controlling for the others in the model.</p>
<p>Looking at the interaction/moderation term, it appears to be highly significant. But what does this imply? Moderation effects can be complex to interpret, so visualizing the relationship with a graph is often helpful. However, before we create the plot, let’s attempt to understand it conceptually.</p>
<p>Recall that the interaction term models how the relationship between professional_hours and job_performance varies based on age_group.</p>
<p>In our model, the coefficient for the interaction term is 3.97368. This means that the effect of professional_hours on job_performance is 3.97368 units stronger for the “Younger” age group compared to the “Older” age group.</p>
<p>Specifically:</p>
<p><em>For Older Employees:</em> The effect of professional_hours on job_performance is 1.00426 (the coefficient for professional_hours).</p>
<p><em>For Younger Employees:</em> The effect of professional_hours on job_performance is 1.00426 + 3.97368 = 4.97794.</p>
<p>This indicates that professional development hours have a significantly stronger positive impact on job performance for Younger employees than for Older employees. In other words, the relationship between professional development and job performance is contingent upon the employee’s age group—a classic case of moderation.</p>
<p>What Does This Mean for Our Study?</p>
<p>The interaction suggests that the effectiveness of professional development activities in enhancing job performance varies by age. We can say that younger employees benefit more from additional professional development hours compared to their older counterparts.</p>
<ul>
<li><p><strong>Main Effect of Professional Hours:</strong> Indicates the overall relationship between professional development hours and job performance.</p></li>
<li><p><strong>Main Effect of Age Group:</strong> Shows any direct differences in job performance between younger and older employees, regardless of professional hours.</p></li>
<li><p><strong>Interaction Term (professional_hours:age_group):</strong> Reveals whether the relationship between professional hours and job performance differs by age group.</p></li>
</ul>
<p><strong>Visualization:</strong></p>
<p>This moderated relationship can be visualized by plotting separate regression lines for different age groups, showing how the slope of the relationship between professional development hours and job performance changes with age.</p>
<p>let’s create an interaction plot:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>mod1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(job_performance <span class="sc">~</span> professional_hours <span class="sc">*</span> age_group, <span class="at">data =</span> employee_data)</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>interactions<span class="sc">::</span><span class="fu">interact_plot</span>(mod1, <span class="st">"professional_hours"</span>, <span class="at">modx =</span> <span class="st">"age_group"</span>,</span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a>                            <span class="at">modx.labels =</span> <span class="fu">c</span>(<span class="st">"Older"</span>, <span class="st">"Younger"</span>),</span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a>                            <span class="at">legend.main =</span> <span class="st">"Age_Group"</span>,</span>
<span id="cb100-6"><a href="#cb100-6" aria-hidden="true" tabindex="-1"></a>                            <span class="at">y.label =</span> <span class="st">"Job Performance"</span>,</span>
<span id="cb100-7"><a href="#cb100-7" aria-hidden="true" tabindex="-1"></a>                            <span class="at">x.label =</span> <span class="st">"Professional Hours"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-54-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>We can also use ggplot to do the same thing</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(employee_data, <span class="fu">aes</span>(<span class="at">x =</span> professional_hours, <span class="at">y =</span> job_performance, <span class="at">color =</span> age_group)) <span class="sc">+</span></span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Moderation Effect of Age on Professional Development and Job Performance"</span>,</span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Professional Development Hours"</span>,</span>
<span id="cb101-6"><a href="#cb101-6" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Job Performance"</span>,</span>
<span id="cb101-7"><a href="#cb101-7" aria-hidden="true" tabindex="-1"></a>       <span class="at">color =</span> <span class="st">"Age Group"</span>) <span class="sc">+</span></span>
<span id="cb101-8"><a href="#cb101-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-55-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The interaction plot shows that job performance increases with professional hours for both younger and older employees. However, the effect is much stronger for younger employees, as indicated by the steeper slope of their line compared to that of the older employees. This suggests that younger employees’ job performance is more positively influenced by additional professional hours than that of older employees. By visualizing the interaction, We can see that age_group moderates the relationship between professional_hours and job_performance.</p>
</section>
<section id="example-2--moderation-with-a-continuous-moderator" class="level3">
<h3 class="anchored" data-anchor-id="example-2--moderation-with-a-continuous-moderator">Example 2- Moderation with a Continuous Moderator</h3>
<p>So far, we’ve conducted moderation analyses using categorical moderators, such as age_group This process is relatively straightforward since it involves comparing a limited number of slopes—for instance, the slope for Younger versus that for older employees. However, what if we want to use a continuous variable as a moderator?</p>
<p>Consider the following scenario: Suppose we believe that the amount of social support an employee receives influences their job satisfaction, but we’re unsure if this relationship remains consistent across different levels of work experience. One reason for this uncertainty is that the impact of social support might vary depending on an employee’s years of experience. For instance, more experienced employees might utilize social support differently compared to their less experienced counterparts, potentially leading to varying effects on job satisfaction. Also, even if all employees receive similar levels of social support, the direct effect on their job satisfaction could differ based on their work experience, as more seasoned employees may have developed distinct coping strategies over time. Therefore, let’s investigate whether work experience moderates the relationship between social support and job satisfaction: Does the effect of social support on job satisfaction change depending on an employee’s level of work experience? Let’s explore this further.</p>
<p>Again, let’s simulate data in R (of course you can use your own data if you have):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed</span></span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">9999</span>)</span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a><span class="co"># sample size</span></span>
<span id="cb103-5"><a href="#cb103-5" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb103-6"><a href="#cb103-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-7"><a href="#cb103-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate data</span></span>
<span id="cb103-8"><a href="#cb103-8" aria-hidden="true" tabindex="-1"></a>data2 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb103-9"><a href="#cb103-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">social_support =</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>),        </span>
<span id="cb103-10"><a href="#cb103-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">work_experience =</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">10</span>, <span class="at">sd =</span> <span class="dv">2</span>)     </span>
<span id="cb103-11"><a href="#cb103-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb103-12"><a href="#cb103-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-13"><a href="#cb103-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's Create job satisfaction, influenced by social_support and moderated by work_experience</span></span>
<span id="cb103-14"><a href="#cb103-14" aria-hidden="true" tabindex="-1"></a>data2 <span class="ot">&lt;-</span> data2 <span class="sc">%&gt;%</span></span>
<span id="cb103-15"><a href="#cb103-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">job_satisfaction =</span> </span>
<span id="cb103-16"><a href="#cb103-16" aria-hidden="true" tabindex="-1"></a>           <span class="dv">30</span> <span class="sc">+</span> </span>
<span id="cb103-17"><a href="#cb103-17" aria-hidden="true" tabindex="-1"></a>           <span class="fl">0.5</span> <span class="sc">*</span> social_support <span class="sc">+</span> </span>
<span id="cb103-18"><a href="#cb103-18" aria-hidden="true" tabindex="-1"></a>           <span class="fl">1.2</span> <span class="sc">*</span> work_experience <span class="sc">+</span> </span>
<span id="cb103-19"><a href="#cb103-19" aria-hidden="true" tabindex="-1"></a>           <span class="fl">0.05</span> <span class="sc">*</span> social_support <span class="sc">*</span> work_experience <span class="sc">+</span> </span>
<span id="cb103-20"><a href="#cb103-20" aria-hidden="true" tabindex="-1"></a>           <span class="fu">rnorm</span>(n, <span class="dv">0</span>, <span class="dv">5</span>))  <span class="co"># Outcome variable with interaction effect</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here, we are examining how social support (the predictor variable) affects job satisfaction (the outcome variable) and whether this relationship is influenced by work experience (the continuous moderator).</p>
<p><strong>Conducting the Moderation Analysis</strong></p>
<p>To test whether work experience moderates the relationship between social support and job satisfaction, we can include an interaction term in our regression model. This interaction term allows us to assess if the slope of the relationship between social support and job satisfaction changes at different levels of work experience.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the moderation model with interaction term</span></span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a>mod_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(job_satisfaction <span class="sc">~</span> social_support <span class="sc">*</span> work_experience, <span class="at">data =</span> data2)</span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the model summary</span></span>
<span id="cb104-6"><a href="#cb104-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = job_satisfaction ~ social_support * work_experience, 
    data = data2)

Residuals:
     Min       1Q   Median       3Q      Max 
-18.3593  -3.4445  -0.0527   3.2653  13.3838 

Coefficients:
                               Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)                    32.92252    6.44879   5.105 4.72e-07 ***
social_support                  0.44652    0.12918   3.457 0.000594 ***
work_experience                 0.78332    0.63150   1.240 0.215414    
social_support:work_experience  0.05827    0.01265   4.605 5.24e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 5.229 on 496 degrees of freedom
Multiple R-squared:  0.8525,    Adjusted R-squared:  0.8516 
F-statistic: 955.6 on 3 and 496 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>From the result above, we can see the estimate of social support as 0.47. This means that for each additional unit increase in social support, job satisfaction increases by 0.47 units, holding work experience constant. Also, we can see a significant (p &lt; 2e-16) positive relationship.</p>
<p>Work Experience (0.78): For each additional year of work experience, there will be corresponding 0.78-unit increase in job satisfaction, holding social support constant.</p>
<p>The intereaction term (estimate ~ 0.06) is also significant, which means that work experience moderates the relationship between social support and job satisfaction.. The positive interaction term indicates that the effect of social support on job satisfaction increases by 0.06 units for each additional year of work experience.</p>
<p>Thus, we can conclude by saying that the positive interaction suggests that social support has a stronger positive effect on job satisfaction for employees with more work experience compared to those with less experience. For less experienced employees, the impact of social support on job satisfaction is positive but less pronounced.</p>
<p>Again, we can visualize the Moderation Effect. Like previous example, we can use the interact_plot function from the interactions package to create an interaction plot.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the interaction plot</span></span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>interactions<span class="sc">::</span><span class="fu">interact_plot</span>(mod_model, <span class="at">pred =</span> social_support, <span class="at">modx =</span> work_experience, </span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">interval =</span> <span class="cn">TRUE</span>, <span class="at">plot.points =</span> <span class="cn">TRUE</span>) <span class="sc">+</span></span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Moderation Effect of Work Experience on the Relationship Between Social Support and Job Satisfaction"</span>,</span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Social Support"</span>,</span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Job Satisfaction"</span>) <span class="sc">+</span></span>
<span id="cb106-7"><a href="#cb106-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-58-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The interaction plot shows how work experience moderates the relationship between social support and job satisfaction. The x-axis represents social support levels, while each line corresponds to a different level of work experience (+1 SD, Mean, -1 SD). The slope of each line indicates the strength of the positive relationship between social support and job satisfaction. Steeper slopes suggest a stronger positive relationship, meaning that increases in social support are associated with greater increases in job satisfaction for more experienced employees. Also, flatter slopes indicate a weaker effect for employees with less work experience.</p>
</section>
</section>
<section id="mean-centering-in-moderation-models" class="level2">
<h2 class="anchored" data-anchor-id="mean-centering-in-moderation-models">Mean Centering in Moderation Models</h2>
<p>Now that we have explored both categorical and continuous moderators, we need to look at mean centering.</p>
<p>Remember our regression model:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>mod_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(job_satisfaction <span class="sc">~</span> social_support <span class="sc">*</span> work_experience, <span class="at">data =</span> data2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In models like this, we may have concerns about the structure of the current setup. The main issue is <strong>multicollinearity</strong>, which occurs when predictor variables are highly correlated. In our model, we’ve included both social_support and work_experience as individual predictors, alongside their interaction term (social_support * work_experience). This setup can lead to high correlations between the interaction term and the main effects, complicating the interpretation of each predictor’s unique contribution.</p>
<p>But does multicollinearity pose a significant problem in this context? To address this, we need to create the interaction term explicitly and then examine its correlation with the primary predictors. By doing so, we can assess the extent of multicollinearity and decide whether mean centering is necessary to mitigate its effects.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>pacman<span class="sc">::</span><span class="fu">p_load</span>(dplyr, ggplot2,magrittr,interactions,Hmisc,mediation)</span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the interaction term</span></span>
<span id="cb108-4"><a href="#cb108-4" aria-hidden="true" tabindex="-1"></a>data2_mut <span class="ot">&lt;-</span> data2 <span class="sc">%&gt;%</span></span>
<span id="cb108-5"><a href="#cb108-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb108-6"><a href="#cb108-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">socialXexperience =</span> social_support <span class="sc">*</span> work_experience</span>
<span id="cb108-7"><a href="#cb108-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb108-8"><a href="#cb108-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-9"><a href="#cb108-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Examine the correlations between social_support, work_experience, and the interaction term</span></span>
<span id="cb108-10"><a href="#cb108-10" aria-hidden="true" tabindex="-1"></a>cor_mat <span class="ot">&lt;-</span> data2_mut <span class="sc">%&gt;%</span></span>
<span id="cb108-11"><a href="#cb108-11" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(social_support, work_experience, socialXexperience) <span class="sc">%&gt;%</span></span>
<span id="cb108-12"><a href="#cb108-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.matrix</span>() <span class="sc">%&gt;%</span></span>
<span id="cb108-13"><a href="#cb108-13" aria-hidden="true" tabindex="-1"></a>  Hmisc<span class="sc">::</span><span class="fu">rcorr</span>()</span>
<span id="cb108-14"><a href="#cb108-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-15"><a href="#cb108-15" aria-hidden="true" tabindex="-1"></a><span class="co"># correlation results</span></span>
<span id="cb108-16"><a href="#cb108-16" aria-hidden="true" tabindex="-1"></a>cor_mat</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                  social_support work_experience socialXexperience
social_support              1.00            0.01              0.73
work_experience             0.01            1.00              0.68
socialXexperience           0.73            0.68              1.00

n= 500 


P
                  social_support work_experience socialXexperience
social_support                   0.8993          0.0000           
work_experience   0.8993                         0.0000           
socialXexperience 0.0000         0.0000                           </code></pre>
</div>
</div>
<p>As seen above, the correlation between social_support and the interaction term socialXexperience is high (r = 0.73), and similarly, work_experience is r = 0.68 with socialXexperience. These high correlation values indicate that the interaction term shares a significant amount of variance with the main predictors, which may indicate potential multicollinearity issues.</p>
<p>So, this raises an important question: Should we abandon our moderation analysis due to this multicollinearity? Not really. A widely adopted solution to this problem is <strong>mean centering</strong>. Mean centering involves subtracting the mean of each predictor from its individual values, effectively transforming the variables so that they have a mean of zero. This process retains the original ranking of the data (individuals with higher scores remain higher, and vice versa) but reduces the correlation between the main predictors and the interaction term.</p>
<p>To perform mean centering, we can use the scale() function in R with the argument scale = FALSE. This ensures that we center the variables without scaling them to unit variance. We will create mean-centered versions of each predictor and the interaction term as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply mean centering to predictors and create the centered interaction term</span></span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a>data_centering <span class="ot">&lt;-</span> data2 <span class="sc">%&gt;%</span></span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb110-4"><a href="#cb110-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">social_support_c =</span> <span class="fu">scale</span>(social_support, <span class="at">scale =</span> <span class="cn">FALSE</span>),</span>
<span id="cb110-5"><a href="#cb110-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">work_experience_c =</span> <span class="fu">scale</span>(work_experience, <span class="at">scale =</span> <span class="cn">FALSE</span>),</span>
<span id="cb110-6"><a href="#cb110-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">socialXexperience_c =</span> social_support_c <span class="sc">*</span> work_experience_c</span>
<span id="cb110-7"><a href="#cb110-7" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, we can verify if this actually reduced the multicollinearity</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check the correlations after mean centering</span></span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-3"><a href="#cb111-3" aria-hidden="true" tabindex="-1"></a>cor_mat_centered <span class="ot">&lt;-</span> data_centering <span class="sc">%&gt;%</span></span>
<span id="cb111-4"><a href="#cb111-4" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(social_support_c, work_experience_c, socialXexperience_c) <span class="sc">%&gt;%</span></span>
<span id="cb111-5"><a href="#cb111-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.matrix</span>() <span class="sc">%&gt;%</span></span>
<span id="cb111-6"><a href="#cb111-6" aria-hidden="true" tabindex="-1"></a>  Hmisc<span class="sc">::</span><span class="fu">rcorr</span>()</span>
<span id="cb111-7"><a href="#cb111-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-8"><a href="#cb111-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the centered correlation matrix</span></span>
<span id="cb111-9"><a href="#cb111-9" aria-hidden="true" tabindex="-1"></a>cor_mat_centered</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                    social_support_c work_experience_c socialXexperience_c
social_support_c                1.00              0.01               -0.01
work_experience_c               0.01              1.00               -0.08
socialXexperience_c            -0.01             -0.08                1.00

n= 500 


P
                    social_support_c work_experience_c socialXexperience_c
social_support_c                     0.8993            0.7540             
work_experience_c   0.8993                             0.0890             
socialXexperience_c 0.7540           0.0890                               </code></pre>
</div>
</div>
<p>As expected, the correlations between the main predictors and the interaction term are now technically zero- so no multicollinearity.</p>
<p>Finally, let’s refit the Moderation Model with Centered Variables</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the regression model with mean-centered variables</span></span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a>centered_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(job_satisfaction <span class="sc">~</span> social_support_c <span class="sc">*</span> work_experience_c, <span class="at">data =</span> data_centering) </span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-4"><a href="#cb113-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(centered_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = job_satisfaction ~ social_support_c * work_experience_c, 
    data = data_centering)

Residuals:
     Min       1Q   Median       3Q      Max 
-18.3593  -3.4445  -0.0527   3.2653  13.3838 

Coefficients:
                                   Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)                        92.15552    0.23386 394.060  &lt; 2e-16 ***
social_support_c                    1.03308    0.02336  44.232  &lt; 2e-16 ***
work_experience_c                   3.67932    0.12297  29.920  &lt; 2e-16 ***
social_support_c:work_experience_c  0.05827    0.01265   4.605 5.24e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 5.229 on 496 degrees of freedom
Multiple R-squared:  0.8525,    Adjusted R-squared:  0.8516 
F-statistic: 955.6 on 3 and 496 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>The coefficients in this centered model will differ slightly from those in the uncentered model, but they represent the same underlying relationships. Importantly, we can see that the interaction term remains unchanged in magnitude and significance, indicating that the moderation effect is consistent. However, the interpretation of the main effects becomes different a bit:</p>
<p>Social Support (social_support_c): This is the effect of social support on job satisfaction when work_experience_c is zero (i.e., at the mean work experience). Work Experience (work_experience_c): Represents the effect of work experience on job satisfaction when social_support_c is zero (i.e., at the mean social support).</p>
<p>Lastly, let’s visualize our interaction plot</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="co"># interaction plot</span></span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a>interactions<span class="sc">::</span><span class="fu">interact_plot</span>(centered_model, <span class="at">pred =</span> social_support_c, <span class="at">modx =</span> work_experience_c) <span class="sc">+</span></span>
<span id="cb115-3"><a href="#cb115-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Moderation Effect of Work Experience on the Relationship Between Social Support and Job Satisfaction"</span>,</span>
<span id="cb115-4"><a href="#cb115-4" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Social Support (Centered)"</span>,</span>
<span id="cb115-5"><a href="#cb115-5" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Job Satisfaction"</span>) <span class="sc">+</span></span>
<span id="cb115-6"><a href="#cb115-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-64-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Here, the plot shows that as social support increases, job satisfaction rises more sharply for employees with greater work experience compared to those with less experience.</p>
</section>
<section id="mediation" class="level2">
<h2 class="anchored" data-anchor-id="mediation">Mediation</h2>
<p>In many cases, we want to understand not just whether variables are related, but how they are related This is where mediation analysis comes in. Mediation helps us determine whether the relationship between a predictor variable and an outcome variable can be linked to an intermediate variable, known as the mediator.</p>
<p>Consider a scenario where implementing a new teaching strategy—such as encouraging students to take handwritten notes instead of typing them on a laptop—leads to improved academic performance. At first, there appears to be a direct effect of the teaching method on learning outcomes. However, to truly understand why this improvement occurs, we might investigate whether taking handwritten notes encourages students to process information more deeply, thereby enhancing their learning.</p>
<p>In this context, mediation analysis allows us to explore whether the increased depth of information processing (the mediator) explains the relationship between the note-taking method (the predictor) and academic performance (the outcome). If our hypothesis is true, we would conclude that the method of note-taking influences learning outcomes indirectly through its effect on information processing.</p>
<p>Mediation is technically about explaining relationships. It provides a way to map out the causal pathways that link variables and thus, gives us a more comprehensive understanding of the underlying mechanisms. Statistically, mediation analysis assesses whether the relationship between an independent variable (X) and a dependent variable (Y) is accounted for by a third variable (M).</p>
<p><strong>Understanding Causality in Mediation</strong></p>
<p>While mediation analysis can suggest pathways of influence, it’s important to recognize that causality cannot be definitively established through mediation alone. Causal inferences require careful experimental design to ensure that the cause precedes the effect (Temporal Order), The cause and effect are related (Covariation), and Other potential explanations are ruled out (Elimination of Alternatives).</p>
<p>For example, if we collect cross-sectional data on traits like neuroticism, state anxiety, and anxiety disorders, we might propose a mediation model where neuroticism influences anxiety disorders through state anxiety. However, without longitudinal data or experimental manipulation, we cannot confidently assert the direction of causality or rule out other factors that might explain the observed relationships.</p>
<p>Therefore, when conducting or interpreting mediation analyses, it’s essential to have a strong (theoretical) rationale for assigning roles to each variable and to consider the design of the study to support causal claims.</p>
<section id="traditional-mediation-analysis-and-the-baron-kenny-approach" class="level3">
<h3 class="anchored" data-anchor-id="traditional-mediation-analysis-and-the-baron-kenny-approach">Traditional Mediation Analysis and the Baron &amp; Kenny Approach</h3>
<p>In 1986, Baron and Kenny introduced a widely-used framework for establishing mediation. Their approach involves a series of regression analyses to test the following criteria:</p>
<p>Direct Effect: The predictor (X) significantly affects the outcome (Y). Model: 𝑌∼ 𝑋</p>
<p>Mediator Effect: The predictor (X) significantly affects the mediator (M).</p>
<p>Model: 𝑀 ∼𝑋</p>
<p>Mediator’s Impact on Outcome: The mediator (M) significantly affects the outcome (Y) while controlling for the predictor (X).</p>
<p>Model: 𝑌 ∼ 𝑀 + 𝑋</p>
<p>Reduction in Direct Effect: The direct effect of the predictor (X) on the outcome (Y) is smaller when the mediator (M) is included in the model. - Compare the direct effect from step 1 to step 3.</p>
<p>If these conditions are met, Baron and Kenny concluded that mediation is present. Depending on whether the direct effect of X on Y becomes non-significant (full mediation) or remains significant but reduced (partial mediation), we can categorize the mediation accordingly.</p>
<p><strong>Using the Stream Analogy for Mediation</strong></p>
<p>Imagine a river flowing smoothly from point A to point B. The water represents the relationship between the predictor and the outcome. Now, suppose a tributary branches off from the main river, diverting some of the water flow. This tributary symbolizes the mediator.</p>
<p>No Mediation: All water continues directly from A to B with no diversion.</p>
<p>Partial Mediation: Some water flows through the tributary, indicating that part of the relationship is explained by the mediator.</p>
<p>Full Mediation: All water is diverted through the tributary, meaning the relationship between A and B is entirely explained by the mediator.</p>
<p>This analogy helps illustrate how mediation can account for varying degrees of influence between variables.</p>
</section>
<section id="using-bootstrapping" class="level3">
<h3 class="anchored" data-anchor-id="using-bootstrapping">Using Bootstrapping</h3>
<p>Traditionally, the Sobel test was employed to assess the significance of mediation effects. However, recent advancements suggest that bootstrapping methods offer superior performance. Bootstrapping is a powerful statistical method that involves repeatedly sampling with replacement from your dataset to estimate the distribution of a statistic. This technique is particularly useful when the assumptions required for traditional parametric tests, such as normality, are not met. In the context of mediation analysis, bootstrapping provides a more reliable way to assess the significance of indirect effects by minimizing the reliance on strict distributional assumptions.</p>
<p>The Bootstrapping Process:</p>
<p>Resample the Data: Draw a large number of samples (e.g., 1,000) from your dataset, each time selecting observations with replacement. This means some observations may appear multiple times in a single resample, while others may not be selected at all.</p>
<p>Calculate the Statistic: For each resampled dataset, compute the mediation effect. This involves fitting the mediator model (M ~ X) and the outcome model (Y ~ X + M) to estimate the indirect effect.</p>
<p>Build the Distribution: After performing the above steps across all resamples, you’ll obtain a distribution of mediation effect estimates.</p>
<p>Determine Confidence Intervals: From this distribution, derive the 95% confidence intervals for the mediation effect. If these intervals do not include zero, the mediation effect is considered statistically significant.</p>
<p>Let’s use R to do this:</p>
<p>Using the mediate Package</p>
<p>Here, We’ll utilize job dataset (a base data in R).</p>
<p>Fit the Mediator Model (M ~ X):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"jobs"</span>)</span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true" tabindex="-1"></a>df <span class="ot">=</span> jobs</span>
<span id="cb116-4"><a href="#cb116-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-5"><a href="#cb116-5" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">lm</span>(job_seek <span class="sc">~</span> treat, df) <span class="co"># x predicts the mediator</span></span>
<span id="cb116-6"><a href="#cb116-6" aria-hidden="true" tabindex="-1"></a>c <span class="ot">&lt;-</span> <span class="fu">lm</span>(depress2 <span class="sc">~</span> treat <span class="sc">+</span> job_seek, df) <span class="co"># x and m predict the outcome.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Calculate the direct and indirect effects for each of the 1000 random samples and look at the 95% confidence intervals.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>mediation <span class="ot">&lt;-</span> <span class="fu">mediate</span>(b, <span class="co"># Mediator model</span></span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a>                    c, <span class="co"># Outcome model</span></span>
<span id="cb117-3"><a href="#cb117-3" aria-hidden="true" tabindex="-1"></a>                    <span class="at">sims=</span><span class="dv">1000</span>, <span class="co"># Number of bootstrap samples</span></span>
<span id="cb117-4"><a href="#cb117-4" aria-hidden="true" tabindex="-1"></a>                    <span class="at">boot =</span> T, <span class="co"># Ask for bootstrapped confidence intervals</span></span>
<span id="cb117-5"><a href="#cb117-5" aria-hidden="true" tabindex="-1"></a>                    <span class="at">treat=</span><span class="st">"treat"</span>, <span class="co"># Name of the x variable</span></span>
<span id="cb117-6"><a href="#cb117-6" aria-hidden="true" tabindex="-1"></a>                    <span class="at">mediator=</span><span class="st">"job_seek"</span> <span class="co"># Name of the m variable</span></span>
<span id="cb117-7"><a href="#cb117-7" aria-hidden="true" tabindex="-1"></a>                    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Running nonparametric bootstrap</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mediation)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Causal Mediation Analysis 

Nonparametric Bootstrap Confidence Intervals with the Percentile Method

               Estimate 95% CI Lower 95% CI Upper p-value
ACME            -0.0152      -0.0404         0.01    0.19
ADE             -0.0481      -0.1375         0.04    0.30
Total Effect    -0.0633      -0.1569         0.03    0.17
Prop. Mediated   0.2399      -1.5375         2.99    0.29

Sample Size Used: 899 


Simulations: 1000 </code></pre>
</div>
</div>
<p>From the result above, we can intepret the result like below-</p>
<p>Average Direct Effect (ADE):</p>
<p>Estimate: -0.0481 95% Confidence Interval: [-0.1375, 0.04] p-value: 0.30 Interpretation: The direct effect of the independent variable on the outcome is estimated to be -0.0481. However, since the confidence interval includes zero and the p-value is 0.30 (which is above the conventional significance threshold of 0.05), this direct effect is not statistically significant. Average Causal Mediation Effect (ACME):</p>
<p>Estimate: -0.0152 95% Confidence Interval: [-0.0404, 0.01] p-value: 0.19 Interpretation: The indirect effect through the mediator is estimated at -0.0152. Similar to ADE, the confidence interval encompasses zero, and the p-value is 0.19, indicating that the mediation effect is not statistically significant.</p>
<p>Total Effect:</p>
<p>Estimate: -0.0633 95% Confidence Interval: [-0.1569, 0.03] p-value: 0.17 Interpretation: The overall effect of the independent variable on the outcome is estimated at -0.0633. Again, the confidence interval includes zero, and the p-value is 0.17, suggesting that the total effect is not statistically significant. Proportion Mediated:</p>
<p>Estimate: 0.2399 95% Confidence Interval: [-1.5375, 2.99] p-value: 0.29 Interpretation: Approximately 23.99% of the total effect is mediated by the intermediary variable. However, the wide confidence interval, which spans from negative to positive values, and the p-value of 0.29 indicate that this proportion is not statistically significant.</p>
<p>Looking at a plot might help intepret these better. If the horizontal line (the confidence interval) intersects the vertical line (0), then the effect is not significant.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mediation)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-68-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="chapter-6---introduction-to-structural-equation-modeling-sem-in-r" class="level1">
<h1>Chapter 6 - Introduction to Structural Equation Modeling (SEM) in R</h1>
<p>Structural Equation Modeling (SEM) is a good statistical method that can be used to examine complex relationships among variables. Briefly, SEM integrates elements of factor analysis and multiple regression and thus enables us to test and estimate relationships between observed (measured) variables and latent (unobserved) constructs. It is commonly used across various fields, including psychology, social sciences, and education, to model theoretical frameworks and validate hypotheses.</p>
<p>SEM is flexible and can handle complex models, such as those involving mediation, moderation, or hierarchical structures. Unlike traditional regression models, SEM allows for simultaneous analysis of many response and predictor variables and thus useful for testing comprehensive, theory-driven questions.</p>
<p>There are many open-source packages for SEM, both in and outside of R, such as lavaan, OpenMX, and sem. In this tutorial, we will use the <strong>lavaan</strong> package because its widely used for SEM in R. The <strong>lavaan</strong> package is user-friendly and the syntax mirrors the theoretical models researchers aim to test.</p>
<p>Here, we will consider models in which all variables are observed, as well as models with latent variables. The first is sometimes called ‘path analysis’, whereas the latter is sometimes called a ‘measurement model.’</p>
<section id="using-lavaan-package" class="level3">
<h3 class="anchored" data-anchor-id="using-lavaan-package">Using Lavaan package</h3>
<p>Like I said earlier, SEM is essentially an advanced extension of regression analysis that enables us to model multiple predictors and responses. SEM can also incorporate latent variables (<em>unmeasured observations but inferred from other observed variables</em>). The term “structural equations” reflects the use of multiple equations to describe the relationships among variables, often involving several dependent and independent variables within a covariance structure.</p>
<p>let’s begin with a simple illustration of how SEM can replicate a basic single-predictor, single-outcome regression model using a path diagram. For this demonstration, we can use the Boston housing dataset from the 1970 census (of course you can use other data), which includes variables like crime rates, pollution levels, and the age of buildings. This dataset is ideal for regression analysis because it features many interrelated predictors.</p>
<p>We will fit the same regression models (using the <strong>lavaan</strong> package), similar to how we do that via the <code>lm()</code> function in R. The syntax is straightforward- so it should be relatively easy before moving into more complex SEM models.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="co">#load the required libraries</span></span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a>pacman<span class="sc">::</span><span class="fu">p_load</span>(dplyr, ggplot2,magrittr,interactions,Hmisc,lavaan,mlbench,mediation,semPlot)</span>
<span id="cb122-3"><a href="#cb122-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-4"><a href="#cb122-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-5"><a href="#cb122-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the dataset</span></span>
<span id="cb122-6"><a href="#cb122-6" aria-hidden="true" tabindex="-1"></a><span class="co">#from the MASS or mlbench pkg</span></span>
<span id="cb122-7"><a href="#cb122-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-8"><a href="#cb122-8" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(BostonHousing2)</span>
<span id="cb122-9"><a href="#cb122-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-10"><a href="#cb122-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Select and transform relevant variables</span></span>
<span id="cb122-11"><a href="#cb122-11" aria-hidden="true" tabindex="-1"></a>df_boston <span class="ot">&lt;-</span> BostonHousing2 <span class="sc">%&gt;%</span></span>
<span id="cb122-12"><a href="#cb122-12" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(</span>
<span id="cb122-13"><a href="#cb122-13" aria-hidden="true" tabindex="-1"></a>    cmedv,  <span class="co"># Median value of home in 1000s</span></span>
<span id="cb122-14"><a href="#cb122-14" aria-hidden="true" tabindex="-1"></a>    crim,   <span class="co"># Per capita crime by town</span></span>
<span id="cb122-15"><a href="#cb122-15" aria-hidden="true" tabindex="-1"></a>    nox,    <span class="co"># Nitric oxide concentration</span></span>
<span id="cb122-16"><a href="#cb122-16" aria-hidden="true" tabindex="-1"></a>    lstat,  <span class="co"># Proportion of lower status population</span></span>
<span id="cb122-17"><a href="#cb122-17" aria-hidden="true" tabindex="-1"></a>    rad     <span class="co"># Proximity to radial highways</span></span>
<span id="cb122-18"><a href="#cb122-18" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb122-19"><a href="#cb122-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">log_crim =</span> <span class="fu">log2</span>(crim))</span>
<span id="cb122-20"><a href="#cb122-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-21"><a href="#cb122-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the SEM model</span></span>
<span id="cb122-22"><a href="#cb122-22" aria-hidden="true" tabindex="-1"></a>lav_md <span class="ot">&lt;-</span> <span class="st">'cmedv ~ log_crim'</span></span>
<span id="cb122-23"><a href="#cb122-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-24"><a href="#cb122-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model using lavaan</span></span>
<span id="cb122-25"><a href="#cb122-25" aria-hidden="true" tabindex="-1"></a>mod_lav <span class="ot">&lt;-</span> <span class="fu">sem</span>(lav_md, <span class="at">data =</span> df_boston)</span>
<span id="cb122-26"><a href="#cb122-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-27"><a href="#cb122-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Summarize the results</span></span>
<span id="cb122-28"><a href="#cb122-28" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_lav)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-19 ended normally after 1 iteration

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                         2

  Number of observations                           506

Model Test User Model:
                                                      
  Test statistic                                 0.000
  Degrees of freedom                                 0

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Regressions:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  cmedv ~                                             
    log_crim         -1.346    0.116  -11.567    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .cmedv            66.549    4.184   15.906    0.000</code></pre>
</div>
</div>
<p>We can also compare that with the “lm” function</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(cmedv <span class="sc">~</span> log_crim, df_boston))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = cmedv ~ log_crim, data = df_boston)

Residuals:
    Min      1Q  Median      3Q     Max 
-17.308  -5.167  -2.476   2.659  33.304 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  21.0131     0.3864   54.39   &lt;2e-16 ***
log_crim     -1.3462     0.1166  -11.54   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 8.174 on 504 degrees of freedom
Multiple R-squared:  0.2091,    Adjusted R-squared:  0.2076 
F-statistic: 133.3 on 1 and 504 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>The regression coefficient is quite similar to the result from lavaan! However, you may notice that the <strong>lavaan</strong> output does not include an intercept. This difference is a key feature of basic SEM: it primarily emphasizes the covariance structure of the data rather than the mean structure. While it’s possible to incorporate means into SEM analysis, this is usually done only when it aligns with specific research questions. For instance, one might explore whether there are mean differences in a latent depression factor between males and females.</p>
</section>
<section id="including-the-mean-structure" class="level3">
<h3 class="anchored" data-anchor-id="including-the-mean-structure">Including the Mean Structure</h3>
<p>To include the mean (intercept) in the model, we can instruct <strong>lavaan</strong> to account for it by setting <code>meanstructure = TRUE</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a>mod_lav_intercept <span class="ot">&lt;-</span> <span class="fu">sem</span>(lav_md, <span class="at">data=</span>df_boston, <span class="at">meanstructure=</span><span class="cn">TRUE</span>)</span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_lav_intercept)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-19 ended normally after 1 iteration

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                         3

  Number of observations                           506

Model Test User Model:
                                                      
  Test statistic                                 0.000
  Degrees of freedom                                 0

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Regressions:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  cmedv ~                                             
    log_crim         -1.346    0.116  -11.567    0.000

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .cmedv            21.013    0.386   54.494    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .cmedv            66.549    4.184   15.906    0.000</code></pre>
</div>
</div>
</section>
<section id="examining-model-parameters" class="level3">
<h3 class="anchored" data-anchor-id="examining-model-parameters">Examining Model Parameters</h3>
<p>It’s also good to check the ‘parameter’ table in <strong>lavaan</strong>. This table gives important overview of the model parameters, and gives us idea of which ones are free (i.e., need to be estimated) and which were explicitly specified by you in the model syntax.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="fu">parTable</span>(mod_lav)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  id      lhs op      rhs user block group free ustart exo label plabel  start
1  1    cmedv  ~ log_crim    1     1     1    1     NA   0         .p1. -1.346
2  2    cmedv ~~    cmedv    0     1     1    2     NA   0         .p2. 66.549
3  3 log_crim ~~ log_crim    0     1     1    0     NA   1         .p3.  9.710
     est    se
1 -1.346 0.116
2 66.549 4.184
3  9.710 0.000</code></pre>
</div>
</div>
<p>From the table above, ‘user’ column represent parameters that you have explicitly defined in the model syntax, while non-zero values in the ‘free’ column indicate parameters that the model estimates freely.</p>
<p>Additionally, <strong>lavaan</strong> allows us to obtain standardized estimates. Standardization in SEM can be a bit complicated, as you can choose to standardize based on the latent variables only (<code>std.lv</code>) or on both observed and latent variables (<code>std.all</code>). The latter option, <code>std.all</code>, is the most commonly reported in SEM research publications.</p>
</section>
<section id="standardized-estimates" class="level3">
<h3 class="anchored" data-anchor-id="standardized-estimates">Standardized estimates</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb130"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="fu">standardizedSolution</span>(mod_lav, <span class="at">type=</span><span class="st">"std.all"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       lhs op      rhs est.std    se       z pvalue ci.lower ci.upper
1    cmedv  ~ log_crim  -0.457 0.033 -13.745      0   -0.523   -0.392
2    cmedv ~~    cmedv   0.791 0.030  25.991      0    0.731    0.851
3 log_crim ~~ log_crim   1.000 0.000      NA     NA    1.000    1.000</code></pre>
</div>
</div>
</section>
<section id="path-analysis-with-housing-data" class="level2">
<h2 class="anchored" data-anchor-id="path-analysis-with-housing-data">Path Analysis with Housing Data</h2>
<p>Now, let’s explore another scenario. Suppose we hypothesize that nitric oxide levels (<code>nox</code>) also influence home prices alongside crime rates- more like adding predictors in a standard multiple regression model.</p>
<p>Also, we might hypothesize that the proximity of a home to major highways (<code>rad</code>) affects nitric oxide concentration, which in turn impacts home prices.</p>
<p>In R, we can model the hypothesis like:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb132"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a>lav_m2 <span class="ot">&lt;-</span> <span class="st">'</span></span>
<span id="cb132-2"><a href="#cb132-2" aria-hidden="true" tabindex="-1"></a><span class="st">cmedv ~ log_crim + nox #crime and nox predict lower home prices</span></span>
<span id="cb132-3"><a href="#cb132-3" aria-hidden="true" tabindex="-1"></a><span class="st">nox ~ rad #proximity to highways predicts nox</span></span>
<span id="cb132-4"><a href="#cb132-4" aria-hidden="true" tabindex="-1"></a><span class="st">'</span></span>
<span id="cb132-5"><a href="#cb132-5" aria-hidden="true" tabindex="-1"></a>mod_lav2 <span class="ot">&lt;-</span> <span class="fu">sem</span>(lav_m2, <span class="at">data=</span>df_boston)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: lavaan-&gt;lav_data_full():  
   some observed variances are (at least) a factor 1000 times larger than 
   others; use varTable(fit) to investigate</code></pre>
</div>
</div>
<p>We can then view the model like:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb134"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a>semPlot<span class="sc">::</span><span class="fu">semPaths</span>(mod_lav2, <span class="at">what=</span><span class="st">'std'</span>, <span class="at">nCharNodes=</span><span class="dv">6</span>, <span class="at">sizeMan=</span><span class="dv">10</span>,</span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">edge.label.cex=</span><span class="fl">1.25</span>, <span class="at">curvePivot =</span> <span class="cn">TRUE</span>, <span class="at">fade=</span><span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-75-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><em>Note here, we used the handy semPaths function from semPlot.</em></p>
<p>To view just the model output like a normal regression text</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_lav2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-19 ended normally after 1 iteration

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                         5

  Number of observations                           506

Model Test User Model:
                                                      
  Test statistic                               274.360
  Degrees of freedom                                 2
  P-value (Chi-square)                           0.000

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Regressions:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  cmedv ~                                             
    log_crim         -0.925    0.135   -6.831    0.000
    nox             -14.391    3.643   -3.950    0.000
  nox ~                                               
    rad               0.008    0.000   17.382    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .cmedv            65.499    4.118   15.906    0.000
   .nox               0.008    0.001   15.906    0.000</code></pre>
</div>
</div>
<p><strong>Observations</strong></p>
<p>Here are a few important points to consider:</p>
<ol type="1">
<li><p>A warning indicates that “some observed variances are (at least) a factor 1000 times larger than others.” This issue, known as ill-conditioning, suggests substantial differences in the scale of variables.</p></li>
<li><p>The hypotheses appear to be well-supported by the model.</p></li>
<li><p>The model’s chi-square test is highly significant, indicating a poor overall fit for the model.</p></li>
</ol>
<section id="ill-conditioning" class="level3">
<h3 class="anchored" data-anchor-id="ill-conditioning">Ill-Conditioning</h3>
<p>When the variances of variables in a model differ significantly—often by several orders of magnitude—it can create challenges for parameter estimation. Considering the earlier warning, we can investigate this further.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a><span class="fu">varTable</span>(mod_lav2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      name idx nobs    type exo user   mean    var nlev lnam
1    cmedv   1  506 numeric   0    0 22.529 84.312    0     
2      nox   3  506 numeric   0    0  0.555  0.013    0     
3 log_crim   6  506 numeric   1    0 -1.126  9.729    0     
4      rad   5  506 numeric   1    0  9.549 75.816    0     </code></pre>
</div>
</div>
<p>It seems that the scale of <code>nox</code> is significantly smaller than the other predictors, likely because it’s measured in parts per 10 million. To address this, we can rescale the variable by multiplying it by a constant. As you probably know, this adjustment doesn’t affect the model’s fit or interpretation, but you just have to keep track of the new units. If needed, the original units can be restored by dividing the parameter estimate by the same constant used for rescaling.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>df_boston <span class="ot">&lt;-</span> df_boston <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">nox =</span> nox<span class="sc">*</span><span class="dv">100</span>) <span class="co">#parts per 100,000 not 10 million</span></span>
<span id="cb139-2"><a href="#cb139-2" aria-hidden="true" tabindex="-1"></a>mod_lav2 <span class="ot">&lt;-</span> <span class="fu">sem</span>(lav_m2, <span class="at">data=</span>df_boston)</span>
<span id="cb139-3"><a href="#cb139-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_lav2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-19 ended normally after 1 iteration

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                         5

  Number of observations                           506

Model Test User Model:
                                                      
  Test statistic                               274.360
  Degrees of freedom                                 2
  P-value (Chi-square)                           0.000

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Regressions:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  cmedv ~                                             
    log_crim         -0.925    0.135   -6.831    0.000
    nox              -0.144    0.036   -3.950    0.000
  nox ~                                               
    rad               0.814    0.047   17.382    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .cmedv            65.499    4.118   15.906    0.000
   .nox              83.910    5.275   15.906    0.000</code></pre>
</div>
</div>
</section>
<section id="evaluating-model-fit" class="level3">
<h3 class="anchored" data-anchor-id="evaluating-model-fit">Evaluating Model Fit</h3>
<p>To obtain a more comprehensive set of global fit indices in the <strong>lavaan</strong> summary output, you can enable this by setting <code>fit.measures = TRUE</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_lav2, <span class="at">fit.measures=</span><span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-19 ended normally after 1 iteration

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                         5

  Number of observations                           506

Model Test User Model:
                                                      
  Test statistic                               274.360
  Degrees of freedom                                 2
  P-value (Chi-square)                           0.000

Model Test Baseline Model:

  Test statistic                               638.018
  Degrees of freedom                                 5
  P-value                                        0.000

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.570
  Tucker-Lewis Index (TLI)                      -0.076

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)              -3614.747
  Loglikelihood unrestricted model (H1)      -3477.566
                                                      
  Akaike (AIC)                                7239.493
  Bayesian (BIC)                              7260.626
  Sample-size adjusted Bayesian (SABIC)       7244.755

Root Mean Square Error of Approximation:

  RMSEA                                          0.519
  90 Percent confidence interval - lower         0.468
  90 Percent confidence interval - upper         0.571
  P-value H_0: RMSEA &lt;= 0.050                    0.000
  P-value H_0: RMSEA &gt;= 0.080                    1.000

Standardized Root Mean Square Residual:

  SRMR                                           0.090

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Regressions:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  cmedv ~                                             
    log_crim         -0.925    0.135   -6.831    0.000
    nox              -0.144    0.036   -3.950    0.000
  nox ~                                               
    rad               0.814    0.047   17.382    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .cmedv            65.499    4.118   15.906    0.000
   .nox              83.910    5.275   15.906    0.000</code></pre>
</div>
</div>
<p>Also, we can get the fit measures (including additional statistics) using fitmeasures():</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb143"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fitmeasures</span>(mod_lav2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                 npar                  fmin                 chisq 
                5.000                 0.271               274.360 
                   df                pvalue        baseline.chisq 
                2.000                 0.000               638.018 
          baseline.df       baseline.pvalue                   cfi 
                5.000                 0.000                 0.570 
                  tli                  nnfi                   rfi 
               -0.076                -0.076                 1.000 
                  nfi                  pnfi                   ifi 
                0.570                 0.228                 0.572 
                  rni                  logl     unrestricted.logl 
                0.570             -3614.747             -3477.566 
                  aic                   bic                ntotal 
             7239.493              7260.626               506.000 
                 bic2                 rmsea        rmsea.ci.lower 
             7244.755                 0.519                 0.468 
       rmsea.ci.upper        rmsea.ci.level          rmsea.pvalue 
                0.571                 0.900                 0.000 
       rmsea.close.h0 rmsea.notclose.pvalue     rmsea.notclose.h0 
                0.050                 1.000                 0.080 
                  rmr            rmr_nomean                  srmr 
                4.249                 4.249                 0.090 
         srmr_bentler   srmr_bentler_nomean                  crmr 
                0.090                 0.090                 0.115 
          crmr_nomean            srmr_mplus     srmr_mplus_nomean 
                0.115                 0.089                 0.089 
                cn_05                 cn_01                   gfi 
               12.050                17.987                 0.748 
                 agfi                  pgfi                   mfi 
               -0.259                 0.150                 0.764 
                 ecvi 
                0.562 </code></pre>
</div>
</div>
<p>From the table above, we can see the results are quite poor: the CFI falls well below the acceptable threshold of 0.95 (and even 0.9), while the RMSEA exceeds the 0.08 cutoff typically considered to indicate an adequate fit.</p>
</section>
<section id="model-diagnostics" class="level3">
<h3 class="anchored" data-anchor-id="model-diagnostics">Model Diagnostics</h3>
<p>Let’s examine model fit closely. One way to do this is by comparing the observed covariance matrix to the covariance matrix implied by the model.</p>
<p>In SEM, the primary goal is to assess whether a theoretically derived model provides a reasonable approximation of the relationships in the data. Specifically, the aim is to determine how well a simplified model, built from measurement and/or structural components, can replicate the observed covariance matrix.</p>
<p>Formally, the objective is to develop a model where the model-implied covariance matrix closely matches the sample (observed) covariance matrix:</p>
<p>[ S_{XX} () ]</p>
<p>Using <strong>lavaan</strong>, we can extract these matrices to further investigate potential areas of model misfit.</p>
<p>First, let’s examine the model-implied covariance matrix:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb145"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fitted</span>(mod_lav2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$cov
           cmedv     nox  lg_crm     rad
cmedv     81.585                        
nox      -36.689 134.011                
log_crim -11.687  18.823   9.710        
rad      -30.248  61.571  23.132  75.667</code></pre>
</div>
</div>
<p>It might be more intuitive to interpret the results in terms of correlations (standardized units). In other words, what are the model-implied correlations among the variables? The <strong>inspect</strong> function in <strong>lavaan</strong> allows us to access various details about the model, including these correlations:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb147"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(mod_lav2, <span class="at">what=</span><span class="st">"cor.all"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          cmedv    nox lg_crm    rad
cmedv     1.000                     
nox      -0.351  1.000              
log_crim -0.415  0.522  1.000       
rad      -0.385  0.611  0.853  1.000</code></pre>
</div>
</div>
<p>Can we compare this to the observed correlations?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lavCor</span>(mod_lav2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          cmedv    nox lg_crm    rad
cmedv     1.000                     
nox      -0.429  1.000              
log_crim -0.457  0.789  1.000       
rad      -0.385  0.611  0.853  1.000</code></pre>
</div>
</div>
<p>Examining the (mis)fit in bivariate relationships can be useful By working with residuals in correlational units, we have more perspective compared to unstandardized covariances. These residuals represent the difference between the observed and model-implied matrices calculated earlier.</p>
<ul>
<li><p><strong>Large positive residuals</strong>: Indicate that the model underestimates the correlation between variables.</p></li>
<li><p><strong>Large negative residuals</strong>: Suggest that the model overestimates the correlation.</p></li>
<li><p>Typically, residual values with magnitudes greater than |r &gt; 0.1| warrant further investigation.</p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb151"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a><span class="fu">resid</span>(mod_lav2, <span class="st">"cor"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$type
[1] "cor.bollen"

$cov
          cmedv    nox lg_crm    rad
cmedv     0.000                     
nox      -0.078  0.000              
log_crim -0.042  0.267  0.000       
rad       0.000  0.000  0.000  0.000</code></pre>
</div>
</div>
<p>The model substantially underestimates the relationship between <code>nox</code> and <code>log_crim</code>.</p>
</section>
<section id="modification-indices" class="level3">
<h3 class="anchored" data-anchor-id="modification-indices">Modification Indices</h3>
<p>To address the misfit, we can examine the modification indices to determine if freeing specific paths—such as the relationship between <code>nox</code> and <code>log_crim</code>—might improve the model.</p>
<p>Here’s the code to inspect the modification indices:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb153"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Display modification indices greater than 20</span></span>
<span id="cb153-2"><a href="#cb153-2" aria-hidden="true" tabindex="-1"></a><span class="fu">modificationindices</span>(mod_lav2, <span class="at">minimum.value =</span> <span class="dv">20</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        lhs op      rhs      mi    epc sepc.lv sepc.all sepc.nox
11      nox  ~    cmedv  38.495 -0.748  -0.748   -0.584   -0.584
12      nox  ~ log_crim 211.735  3.648   3.648    0.982    0.315
14 log_crim  ~      nox  82.828  0.045   0.045    0.167    0.167
17      rad  ~      nox  80.244 -0.142  -0.142   -0.189   -0.189</code></pre>
</div>
</div>
<p>From the table above, the results indicate that allowing <code>log_crim</code> to predict <code>nox</code> would greatly improve the model fit. However, it’s essential to evaluate whether this adjustment aligns with the theoretical framework, as theoretical validity often outweighs statistical considerations.</p>
<p>For the sake of this tutorial, we’ll just proceed by freeing this path to estimate it directly.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Adding a path to the existing model</span></span>
<span id="cb155-2"><a href="#cb155-2" aria-hidden="true" tabindex="-1"></a>mod_lav3 <span class="ot">&lt;-</span> <span class="fu">update</span>(mod_lav2, <span class="at">add =</span> <span class="st">"nox ~ log_crim"</span>)</span>
<span id="cb155-3"><a href="#cb155-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-4"><a href="#cb155-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Summarizing the updated model with fit measures</span></span>
<span id="cb155-5"><a href="#cb155-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_lav3, <span class="at">fit.measures =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-19 ended normally after 1 iteration

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                         6

  Number of observations                           506

Model Test User Model:
                                                      
  Test statistic                                 0.080
  Degrees of freedom                                 1
  P-value (Chi-square)                           0.777

Model Test Baseline Model:

  Test statistic                               638.018
  Degrees of freedom                                 5
  P-value                                        0.000

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    1.000
  Tucker-Lewis Index (TLI)                       1.007

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)              -3477.606
  Loglikelihood unrestricted model (H1)      -3477.566
                                                      
  Akaike (AIC)                                6967.213
  Bayesian (BIC)                              6992.572
  Sample-size adjusted Bayesian (SABIC)       6973.527

Root Mean Square Error of Approximation:

  RMSEA                                          0.000
  90 Percent confidence interval - lower         0.000
  90 Percent confidence interval - upper         0.078
  P-value H_0: RMSEA &lt;= 0.050                    0.880
  P-value H_0: RMSEA &gt;= 0.080                    0.046

Standardized Root Mean Square Residual:

  SRMR                                           0.002

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Regressions:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  cmedv ~                                             
    log_crim         -0.925    0.188   -4.924    0.000
    nox              -0.144    0.051   -2.847    0.004
  nox ~                                               
    rad              -0.302    0.068   -4.403    0.000
    log_crim          3.648    0.191   19.081    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .cmedv            65.499    4.118   15.906    0.000
   .nox              48.798    3.068   15.906    0.000</code></pre>
</div>
</div>
<p>The updated model shows a significant improvement in fit. We can see a strong positive association between crime and <code>nox</code> levels that was previously overlooked. This suggests that the relationship between crime and home prices is partially mediated by crime’s influence on pollution levels.</p>
<p>In contrast, the proximity of homes to highways seems to affect home prices entirely through its impact on pollution levels. This conclusion is supported by the lack of a significant modification index for a direct path from highway proximity to home prices.</p>
<p>To visualize the updated model, including standardized estimates, we can use the following code:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb157"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a>semPlot<span class="sc">::</span><span class="fu">semPaths</span>(mod_lav3, </span>
<span id="cb157-2"><a href="#cb157-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">what =</span> <span class="st">'std'</span>, </span>
<span id="cb157-3"><a href="#cb157-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">nCharNodes =</span> <span class="dv">6</span>, </span>
<span id="cb157-4"><a href="#cb157-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">sizeMan =</span> <span class="dv">10</span>,</span>
<span id="cb157-5"><a href="#cb157-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">edge.label.cex =</span> <span class="fl">1.25</span>, </span>
<span id="cb157-6"><a href="#cb157-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">curvePivot =</span> <span class="cn">TRUE</span>, </span>
<span id="cb157-7"><a href="#cb157-7" aria-hidden="true" tabindex="-1"></a>         <span class="at">fade =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-87-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="testing-mediation-effects" class="level3">
<h3 class="anchored" data-anchor-id="testing-mediation-effects">Testing Mediation Effects</h3>
<p>When exploring mediation within an SEM framework, we can explicitly test indirect effects and use appropriate significance tests to ensure reliable p-values. Ideally, mediation is tested through the product of the paths that define the mediational relationship.</p>
<p>In this case, we have two mediation chains:</p>
<ol type="1">
<li><code>rad → nox → cmedv</code><br>
</li>
<li><code>log_crim → nox → cmedv</code></li>
</ol>
<p>To test these indirect effects, we can define new parameters in the model as the product of the individual paths. This is achieved using the <code>:=</code> operator, which specifies the defined parameters without introducing additional free parameters. To identify which paths to multiply, we use parameter labels (<code>a1</code>, <code>a2</code>, <code>b1</code>) to indicate the respective paths:</p>
<ul>
<li><code>a1</code> and <code>a2</code> represent the paths from predictors (<code>rad</code> and <code>log_crim</code>) to the mediator (<code>nox</code>).</li>
<li><code>b1</code> represents the path from the mediator (<code>nox</code>) to the outcome (<code>cmedv</code>).</li>
</ul>
<p>Here’s the updated model:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb158"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a>m_update <span class="ot">&lt;-</span> <span class="st">'</span></span>
<span id="cb158-2"><a href="#cb158-2" aria-hidden="true" tabindex="-1"></a><span class="st">cmedv ~ log_crim + b1*nox    # crime and nox predict lower home prices</span></span>
<span id="cb158-3"><a href="#cb158-3" aria-hidden="true" tabindex="-1"></a><span class="st">nox ~ a1*rad + a2*log_crim   # proximity to highways predicts nox</span></span>
<span id="cb158-4"><a href="#cb158-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb158-5"><a href="#cb158-5" aria-hidden="true" tabindex="-1"></a><span class="st">i_1 := a1*b1                 # indirect effect of rad -&gt; nox -&gt; cmedv</span></span>
<span id="cb158-6"><a href="#cb158-6" aria-hidden="true" tabindex="-1"></a><span class="st">i_2 := a2*b1                 # indirect effect of log_crim -&gt; nox -&gt; cmedv</span></span>
<span id="cb158-7"><a href="#cb158-7" aria-hidden="true" tabindex="-1"></a><span class="st">'</span></span>
<span id="cb158-8"><a href="#cb158-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb158-9"><a href="#cb158-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the updated model</span></span>
<span id="cb158-10"><a href="#cb158-10" aria-hidden="true" tabindex="-1"></a>mod_lav4 <span class="ot">&lt;-</span> <span class="fu">sem</span>(m_update, df_boston)</span>
<span id="cb158-11"><a href="#cb158-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb158-12"><a href="#cb158-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Summarize the results</span></span>
<span id="cb158-13"><a href="#cb158-13" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_lav4)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-19 ended normally after 1 iteration

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                         6

  Number of observations                           506

Model Test User Model:
                                                      
  Test statistic                                 0.080
  Degrees of freedom                                 1
  P-value (Chi-square)                           0.777

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Regressions:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  cmedv ~                                             
    log_crim         -0.925    0.188   -4.924    0.000
    nox       (b1)   -0.144    0.051   -2.847    0.004
  nox ~                                               
    rad       (a1)   -0.302    0.068   -4.403    0.000
    log_crim  (a2)    3.648    0.191   19.081    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .cmedv            65.499    4.118   15.906    0.000
   .nox              48.798    3.068   15.906    0.000

Defined Parameters:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
    i_1               0.043    0.018    2.391    0.017
    i_2              -0.525    0.186   -2.816    0.005</code></pre>
</div>
</div>
<p>Just to recap, 1. The <code>:=</code> operator allows us to calculate indirect effects as a function of existing parameters without changing the number of free parameters. 2. <code>i_1</code> and <code>i_2</code> capture the mediational effects for the two specified pathways. 3. The model output will include estimates and significance tests for the indirect effects, to confirm whether mediation is present.</p>
<p>While the results looks good, it’s worth noting that this approach has limitations. Specifically, if the sampling distribution of the product of indirect paths is not normal, it can lead to inaccurate results. In this case, Bootstrapping is another good alternative to address this, as it doesn’t rely on strict assumptions about the distribution of the indirect effect. By resampling the data multiple times, we can estimate the standard errors of the parameters in a more reliable way. In <strong>lavaan</strong>, this can be implemented using the <code>se = "bootstrap"</code> argument.</p>
<p>By default, <strong>lavaan</strong> uses 1000 bootstrap samples, but you can adjust this number with the <code>bootstrap</code> argument.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb160"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb160-1"><a href="#cb160-1" aria-hidden="true" tabindex="-1"></a>mod_lav4_boot <span class="ot">&lt;-</span> <span class="fu">sem</span>(m_update, df_boston, <span class="at">se =</span> <span class="st">"bootstrap"</span>)</span>
<span id="cb160-2"><a href="#cb160-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb160-3"><a href="#cb160-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Summarize the results with bootstrapped standard errors</span></span>
<span id="cb160-4"><a href="#cb160-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_lav4_boot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-19 ended normally after 1 iteration

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                         6

  Number of observations                           506

Model Test User Model:
                                                      
  Test statistic                                 0.080
  Degrees of freedom                                 1
  P-value (Chi-square)                           0.777

Parameter Estimates:

  Standard errors                            Bootstrap
  Number of requested bootstrap draws             1000
  Number of successful bootstrap draws            1000

Regressions:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  cmedv ~                                             
    log_crim         -0.925    0.168   -5.517    0.000
    nox       (b1)   -0.144    0.036   -3.987    0.000
  nox ~                                               
    rad       (a1)   -0.302    0.098   -3.078    0.002
    log_crim  (a2)    3.648    0.269   13.586    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .cmedv            65.499    7.052    9.288    0.000
   .nox              48.798    3.910   12.479    0.000

Defined Parameters:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
    i_1               0.043    0.018    2.429    0.015
    i_2              -0.525    0.135   -3.898    0.000</code></pre>
</div>
</div>
</section>
<section id="latent-variable-models-in-sem" class="level3">
<h3 class="anchored" data-anchor-id="latent-variable-models-in-sem">Latent Variable Models in SEM</h3>
<p>What if we want to test models involving latent variables? In cases like these, we typically use a <em>reflective latent variable</em> model. This type of model assumes that a latent construct is inferred from multiple observed indicators (usually three or more). These latent constructs are often referred to as “factors” or “latent traits.” Within SEM, confirmatory factor analysis (CFA) is the most common method for testing such models.</p>
<p>In <strong>lavaan</strong>, reflective latent variable models are defined using the <code>=~</code> operator, which indicates that a latent variable is “measured by” its observed indicators.</p>
<p>A classic example of this approach is the Holzinger-Swineford dataset, frequently used in SEM tutorials and research. This dataset includes scores from mental ability tests administered to seventh and eighth-grade students from two schools (Pasteur and Grant-White). While the original dataset contained 26 variables, a simplified version focuses on 9 observed variables (x1 to x9), used to measure three latent traits of intelligence: visual ability, textual ability, and processing speed.</p>
<p>The CFA model for these 9 variables proposes the following structure:</p>
<ol type="1">
<li>A <strong>visual factor</strong> measured by <code>x1</code>, <code>x2</code>, and <code>x3</code>.<br>
</li>
<li>A <strong>textual factor</strong> measured by <code>x4</code>, <code>x5</code>, and <code>x6</code>.<br>
</li>
<li>A <strong>speed factor</strong> measured by <code>x7</code>, <code>x8</code>, and <code>x9</code>.</li>
</ol>
<p><strong>Defining a Factor Model</strong></p>
<p>For the Holzinger-Swineford dataset, the model can be defined as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb162"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb162-1"><a href="#cb162-1" aria-hidden="true" tabindex="-1"></a>visual <span class="ot">=</span><span class="er">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3</span>
<span id="cb162-2"><a href="#cb162-2" aria-hidden="true" tabindex="-1"></a>textual <span class="ot">=</span><span class="er">~</span> x4 <span class="sc">+</span> x5 <span class="sc">+</span> x6</span>
<span id="cb162-3"><a href="#cb162-3" aria-hidden="true" tabindex="-1"></a>speed <span class="ot">=</span><span class="er">~</span> x7 <span class="sc">+</span> x8 <span class="sc">+</span> x9</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here, the model consists of three latent variables, each measured by three observed indicators. The general structure for defining a latent variable is:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb163"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb163-1"><a href="#cb163-1" aria-hidden="true" tabindex="-1"></a>latent_variable <span class="ot">=</span><span class="er">~</span> indicator1 <span class="sc">+</span> indicator2 <span class="sc">+</span> indicator3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This syntax specifies that each latent construct (e.g., <code>visual</code>, <code>textual</code>, <code>speed</code>) is inferred from the corresponding observed variables (<code>x1</code>, <code>x2</code>, <code>x3</code>, etc.). This makes it easy to model reflective latent variables in <strong>lavaan</strong>.</p>
<p><strong>Understanding Typical CFA Output</strong></p>
<p>In CFA models, the first indicator of each latent variable is typically assigned a fixed loading of 1. This approach, known as <em>unit loading identification</em>, establishes the scale for the underlying factor.</p>
<p>To examine the results of a fitted model, including fit measures, we can use the following command:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb164"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="st">'</span></span>
<span id="cb164-2"><a href="#cb164-2" aria-hidden="true" tabindex="-1"></a><span class="st">    visual =~ x1 + x2 + x3</span></span>
<span id="cb164-3"><a href="#cb164-3" aria-hidden="true" tabindex="-1"></a><span class="st">    textual =~ x4 + x5 + x6</span></span>
<span id="cb164-4"><a href="#cb164-4" aria-hidden="true" tabindex="-1"></a><span class="st">    speed =~ x7 + x8 + x9</span></span>
<span id="cb164-5"><a href="#cb164-5" aria-hidden="true" tabindex="-1"></a><span class="st">'</span></span>
<span id="cb164-6"><a href="#cb164-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb164-7"><a href="#cb164-7" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">cfa</span>(model, <span class="at">data =</span> HolzingerSwineford1939)</span>
<span id="cb164-8"><a href="#cb164-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb164-9"><a href="#cb164-9" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit, <span class="at">fit.measures =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-19 ended normally after 35 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        21

  Number of observations                           301

Model Test User Model:
                                                      
  Test statistic                                85.306
  Degrees of freedom                                24
  P-value (Chi-square)                           0.000

Model Test Baseline Model:

  Test statistic                               918.852
  Degrees of freedom                                36
  P-value                                        0.000

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.931
  Tucker-Lewis Index (TLI)                       0.896

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)              -3737.745
  Loglikelihood unrestricted model (H1)      -3695.092
                                                      
  Akaike (AIC)                                7517.490
  Bayesian (BIC)                              7595.339
  Sample-size adjusted Bayesian (SABIC)       7528.739

Root Mean Square Error of Approximation:

  RMSEA                                          0.092
  90 Percent confidence interval - lower         0.071
  90 Percent confidence interval - upper         0.114
  P-value H_0: RMSEA &lt;= 0.050                    0.001
  P-value H_0: RMSEA &gt;= 0.080                    0.840

Standardized Root Mean Square Residual:

  SRMR                                           0.065

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual =~                                           
    x1                1.000                           
    x2                0.554    0.100    5.554    0.000
    x3                0.729    0.109    6.685    0.000
  textual =~                                          
    x4                1.000                           
    x5                1.113    0.065   17.014    0.000
    x6                0.926    0.055   16.703    0.000
  speed =~                                            
    x7                1.000                           
    x8                1.180    0.165    7.152    0.000
    x9                1.082    0.151    7.155    0.000

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual ~~                                           
    textual           0.408    0.074    5.552    0.000
    speed             0.262    0.056    4.660    0.000
  textual ~~                                          
    speed             0.173    0.049    3.518    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                0.549    0.114    4.833    0.000
   .x2                1.134    0.102   11.146    0.000
   .x3                0.844    0.091    9.317    0.000
   .x4                0.371    0.048    7.779    0.000
   .x5                0.446    0.058    7.642    0.000
   .x6                0.356    0.043    8.277    0.000
   .x7                0.799    0.081    9.823    0.000
   .x8                0.488    0.074    6.573    0.000
   .x9                0.566    0.071    8.003    0.000
    visual            0.809    0.145    5.564    0.000
    textual           0.979    0.112    8.737    0.000
    speed             0.384    0.086    4.451    0.000</code></pre>
</div>
</div>
<p>Now we have a detailed summary of the model’s parameter estimates and global fit indices and can assess the adequacy of the factor structure.</p>
<p><strong>Modification Indices for CFA</strong></p>
<p>To identify potential improvements to the CFA model, we can examine the modification indices. These indices suggest changes—such as freeing specific parameters—that could enhance the model fit.</p>
<p>The following command displays modification indices greater than a specified threshold (in this case, 10):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb166"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb166-1"><a href="#cb166-1" aria-hidden="true" tabindex="-1"></a><span class="fu">modificationIndices</span>(fit, <span class="at">minimum.value =</span> <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      lhs op rhs     mi    epc sepc.lv sepc.all sepc.nox
28 visual =~  x7 18.631 -0.422  -0.380   -0.349   -0.349
30 visual =~  x9 36.411  0.577   0.519    0.515    0.515
76     x7 ~~  x8 34.145  0.536   0.536    0.859    0.859
78     x8 ~~  x9 14.946 -0.423  -0.423   -0.805   -0.805</code></pre>
</div>
</div>
<p>The table shows that <code>x9</code> might load onto the visual factor, or that <code>x7</code> and <code>x9</code> could share a unique residual correlation. While this poses theoretical concerns, for this tutorial, let’s just test an adjusted model. In <strong>lavaan</strong>, the <code>~~</code> operator is used to define residual variances or covariances within the model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb168"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb168-1"><a href="#cb168-1" aria-hidden="true" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="st">' visual  =~ x1 + x2 + x3</span></span>
<span id="cb168-2"><a href="#cb168-2" aria-hidden="true" tabindex="-1"></a><span class="st">              textual =~ x4 + x5 + x6</span></span>
<span id="cb168-3"><a href="#cb168-3" aria-hidden="true" tabindex="-1"></a><span class="st">              speed   =~ x7 + x8 + x9 </span></span>
<span id="cb168-4"><a href="#cb168-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb168-5"><a href="#cb168-5" aria-hidden="true" tabindex="-1"></a><span class="st">x7 ~~ x9 #this specifies a variance or covariance parameter</span></span>
<span id="cb168-6"><a href="#cb168-6" aria-hidden="true" tabindex="-1"></a><span class="st">'</span></span>
<span id="cb168-7"><a href="#cb168-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb168-8"><a href="#cb168-8" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">cfa</span>(model2, <span class="at">data=</span>HolzingerSwineford1939)</span>
<span id="cb168-9"><a href="#cb168-9" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit2, <span class="at">fit.measures=</span><span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-19 ended normally after 38 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        22

  Number of observations                           301

Model Test User Model:
                                                      
  Test statistic                                79.803
  Degrees of freedom                                23
  P-value (Chi-square)                           0.000

Model Test Baseline Model:

  Test statistic                               918.852
  Degrees of freedom                                36
  P-value                                        0.000

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.936
  Tucker-Lewis Index (TLI)                       0.899

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)              -3734.994
  Loglikelihood unrestricted model (H1)      -3695.092
                                                      
  Akaike (AIC)                                7513.987
  Bayesian (BIC)                              7595.544
  Sample-size adjusted Bayesian (SABIC)       7525.772

Root Mean Square Error of Approximation:

  RMSEA                                          0.091
  90 Percent confidence interval - lower         0.069
  90 Percent confidence interval - upper         0.113
  P-value H_0: RMSEA &lt;= 0.050                    0.001
  P-value H_0: RMSEA &gt;= 0.080                    0.804

Standardized Root Mean Square Residual:

  SRMR                                           0.062

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual =~                                           
    x1                1.000                           
    x2                0.554    0.099    5.574    0.000
    x3                0.735    0.109    6.766    0.000
  textual =~                                          
    x4                1.000                           
    x5                1.112    0.065   17.030    0.000
    x6                0.925    0.055   16.707    0.000
  speed =~                                            
    x7                1.000                           
    x8                0.865    0.186    4.664    0.000
    x9                1.140    0.157    7.278    0.000

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
 .x7 ~~                                               
   .x9               -0.216    0.113   -1.920    0.055
  visual ~~                                           
    textual           0.407    0.073    5.543    0.000
    speed             0.293    0.060    4.902    0.000
  textual ~~                                          
    speed             0.201    0.053    3.821    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                0.553    0.112    4.944    0.000
   .x2                1.135    0.102   11.163    0.000
   .x3                0.840    0.090    9.310    0.000
   .x4                0.370    0.048    7.757    0.000
   .x5                0.447    0.058    7.651    0.000
   .x6                0.357    0.043    8.301    0.000
   .x7                0.666    0.129    5.180    0.000
   .x8                0.635    0.087    7.275    0.000
   .x9                0.343    0.134    2.560    0.010
    visual            0.805    0.144    5.593    0.000
    textual           0.981    0.112    8.748    0.000
    speed             0.517    0.141    3.662    0.000</code></pre>
</div>
</div>
<p>The updated model still doesn’t fit much well. We can revisit the modification indices to explore additional adjustments:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb170"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb170-1"><a href="#cb170-1" aria-hidden="true" tabindex="-1"></a><span class="fu">modificationIndices</span>(fit2, <span class="at">minimum.value =</span> <span class="dv">20</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      lhs op rhs     mi    epc sepc.lv sepc.all sepc.nox
29 visual =~  x7 32.723 -0.662  -0.594   -0.546   -0.546
31 visual =~  x9 30.121  0.715   0.641    0.637    0.637
77     x7 ~~  x8 27.153  0.559   0.559    0.859    0.859
78     x8 ~~  x9 27.153 -0.637  -0.637   -1.366   -1.366</code></pre>
</div>
</div>
<p>This open new possibilities for model fine-tuning. At this point, you may want to revisit your theoretical framework or predictions to guide decisions about the latent structure. Model building and comparison are complex tasks and extend beyond the scope of this tutorial. However, we can evaluate the global fit differences between models.</p>
<p>Since the models are nested (e.g., the residual covariance <code>x7 ~~ x9</code> is fixed to 0 in the simpler model), we can use a likelihood ratio test (LRT), also referred to as a model chi-square difference test, to compare them:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb172"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb172-1"><a href="#cb172-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(fit, fit2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Chi-Squared Difference Test

     Df    AIC    BIC  Chisq Chisq diff  RMSEA Df diff Pr(&gt;Chisq)  
fit2 23 7514.0 7595.5 79.803                                       
fit  24 7517.5 7595.3 85.305     5.5024 0.1223       1    0.01899 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>The <code>anova</code> function performs this comparison, with the LRT degrees of freedom equal to the difference in the number of free parameters between the models (1 in this case). This test evaluates whether the additional parameter in the more complex model significantly improves model fit.</p>
</section>
<section id="structural-model" class="level3">
<h3 class="anchored" data-anchor-id="structural-model">Structural Model</h3>
<p>In the previous example, the CFA focused solely on the measurement model—a three-factor model capturing the relationships among the observed variables and their latent constructs, with correlations among the factors. But what if we want to explore how an external variable, such as grade level, predicts the latent intelligence factors (visual, textual, and speed)?</p>
<p>To do this, we extend the model to include structural paths from <code>grade</code> to each of the latent variables:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb174"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb174-1"><a href="#cb174-1" aria-hidden="true" tabindex="-1"></a>model3 <span class="ot">&lt;-</span> <span class="st">'</span></span>
<span id="cb174-2"><a href="#cb174-2" aria-hidden="true" tabindex="-1"></a><span class="st">  visual  =~ x1 + x2 + x3</span></span>
<span id="cb174-3"><a href="#cb174-3" aria-hidden="true" tabindex="-1"></a><span class="st">  textual =~ x4 + x5 + x6</span></span>
<span id="cb174-4"><a href="#cb174-4" aria-hidden="true" tabindex="-1"></a><span class="st">  speed   =~ x7 + x8 + x9</span></span>
<span id="cb174-5"><a href="#cb174-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-6"><a href="#cb174-6" aria-hidden="true" tabindex="-1"></a><span class="st">  # Structural paths</span></span>
<span id="cb174-7"><a href="#cb174-7" aria-hidden="true" tabindex="-1"></a><span class="st">  visual ~ grade</span></span>
<span id="cb174-8"><a href="#cb174-8" aria-hidden="true" tabindex="-1"></a><span class="st">  textual ~ grade</span></span>
<span id="cb174-9"><a href="#cb174-9" aria-hidden="true" tabindex="-1"></a><span class="st">  speed ~ grade</span></span>
<span id="cb174-10"><a href="#cb174-10" aria-hidden="true" tabindex="-1"></a><span class="st">'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We then fit the model and summarize the results:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb175"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a>fit_structural <span class="ot">&lt;-</span> <span class="fu">cfa</span>(model3, <span class="at">data =</span> HolzingerSwineford1939)</span>
<span id="cb175-2"><a href="#cb175-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb175-3"><a href="#cb175-3" aria-hidden="true" tabindex="-1"></a><span class="co"># View the summary, including fit measures</span></span>
<span id="cb175-4"><a href="#cb175-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit_structural, <span class="at">fit.measures =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-19 ended normally after 36 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        24

                                                  Used       Total
  Number of observations                           300         301

Model Test User Model:
                                                      
  Test statistic                                99.363
  Degrees of freedom                                30
  P-value (Chi-square)                           0.000

Model Test Baseline Model:

  Test statistic                               979.033
  Degrees of freedom                                45
  P-value                                        0.000

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.926
  Tucker-Lewis Index (TLI)                       0.889

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)              -3702.602
  Loglikelihood unrestricted model (H1)      -3652.920
                                                      
  Akaike (AIC)                                7453.203
  Bayesian (BIC)                              7542.094
  Sample-size adjusted Bayesian (SABIC)       7465.980

Root Mean Square Error of Approximation:

  RMSEA                                          0.088
  90 Percent confidence interval - lower         0.069
  90 Percent confidence interval - upper         0.107
  P-value H_0: RMSEA &lt;= 0.050                    0.001
  P-value H_0: RMSEA &gt;= 0.080                    0.764

Standardized Root Mean Square Residual:

  SRMR                                           0.064

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual =~                                           
    x1                1.000                           
    x2                0.554    0.100    5.547    0.000
    x3                0.726    0.109    6.634    0.000
  textual =~                                          
    x4                1.000                           
    x5                1.108    0.065   17.008    0.000
    x6                0.921    0.055   16.670    0.000
  speed =~                                            
    x7                1.000                           
    x8                1.118    0.143    7.831    0.000
    x9                0.947    0.126    7.534    0.000

Regressions:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual ~                                            
    grade             0.428    0.125    3.428    0.001
  textual ~                                           
    grade             0.422    0.120    3.501    0.000
  speed ~                                             
    grade             0.571    0.099    5.795    0.000

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
 .visual ~~                                           
   .textual           0.367    0.070    5.230    0.000
   .speed             0.203    0.051    3.987    0.000
 .textual ~~                                          
   .speed             0.119    0.046    2.595    0.009

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                0.545    0.115    4.734    0.000
   .x2                1.135    0.102   11.112    0.000
   .x3                0.845    0.091    9.286    0.000
   .x4                0.368    0.048    7.697    0.000
   .x5                0.448    0.058    7.666    0.000
   .x6                0.360    0.043    8.330    0.000
   .x7                0.743    0.079    9.440    0.000
   .x8                0.463    0.069    6.695    0.000
   .x9                0.620    0.067    9.213    0.000
   .visual            0.771    0.142    5.431    0.000
   .textual           0.942    0.108    8.718    0.000
   .speed             0.363    0.076    4.799    0.000</code></pre>
</div>
</div>
<p>To visualize the structural model, including the new paths, we use the <code>semPaths</code> function:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb177"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a>semPlot<span class="sc">::</span><span class="fu">semPaths</span>(fit_structural)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-99-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>We can now see the extension of CFA by adding structural paths. This enable us to evaluate how <code>grade</code> influences each of the latent intelligence factors while maintaining the integrity of the measurement model.</p>
<p>As expected, students in higher grades tend to achieve higher scores on the latent intelligence factors.</p>
</section>
<section id="choosing-estimators" class="level3">
<h3 class="anchored" data-anchor-id="choosing-estimators">Choosing Estimators</h3>
<p><strong>lavaan</strong> provides several algorithms for parameter estimation, depending on the nature of your data:</p>
<ul>
<li><strong>ML (Maximum Likelihood)</strong>: The default for continuous data.</li>
<li><strong>WLS (Weighted Least Squares)</strong>: The default for data that includes categorical variables.</li>
</ul>
<p>Robust variants of these estimators, such as <strong>MLR</strong> and <strong>WLSMV</strong>, adjust the model to handle non-normality and other complexities like clustering. These adjustments are particularly useful because they improve the accuracy of global chi-square tests, standard errors, and significance tests. For most scenarios: - <strong>MLR</strong> is a popular choice for continuous data. - <strong>WLSMV</strong> is commonly used for categorical data.</p>
<p>We can specify the estimator in <strong>lavaan</strong> using the <code>estimator</code> argument:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb178"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb178-1"><a href="#cb178-1" aria-hidden="true" tabindex="-1"></a>model4 <span class="ot">&lt;-</span> <span class="st">'</span></span>
<span id="cb178-2"><a href="#cb178-2" aria-hidden="true" tabindex="-1"></a><span class="st">  visual  =~ x1 + x2 + x3</span></span>
<span id="cb178-3"><a href="#cb178-3" aria-hidden="true" tabindex="-1"></a><span class="st">  textual =~ x4 + x5 + x6</span></span>
<span id="cb178-4"><a href="#cb178-4" aria-hidden="true" tabindex="-1"></a><span class="st">  speed   =~ x7 + x8 + x9 </span></span>
<span id="cb178-5"><a href="#cb178-5" aria-hidden="true" tabindex="-1"></a><span class="st">'</span></span>
<span id="cb178-6"><a href="#cb178-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-7"><a href="#cb178-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model using the MLR estimator</span></span>
<span id="cb178-8"><a href="#cb178-8" aria-hidden="true" tabindex="-1"></a>fit_mlr <span class="ot">&lt;-</span> <span class="fu">cfa</span>(model4, HolzingerSwineford1939, <span class="at">estimator =</span> <span class="st">"MLR"</span>)</span>
<span id="cb178-9"><a href="#cb178-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-10"><a href="#cb178-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Summarize the model with robust fit measures</span></span>
<span id="cb178-11"><a href="#cb178-11" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit_mlr, <span class="at">fit.measures =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-19 ended normally after 35 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        21

  Number of observations                           301

Model Test User Model:
                                              Standard      Scaled
  Test Statistic                                85.306      87.132
  Degrees of freedom                                24          24
  P-value (Chi-square)                           0.000       0.000
  Scaling correction factor                                  0.979
    Yuan-Bentler correction (Mplus variant)                       

Model Test Baseline Model:

  Test statistic                               918.852     880.082
  Degrees of freedom                                36          36
  P-value                                        0.000       0.000
  Scaling correction factor                                  1.044

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.931       0.925
  Tucker-Lewis Index (TLI)                       0.896       0.888
                                                                  
  Robust Comparative Fit Index (CFI)                         0.930
  Robust Tucker-Lewis Index (TLI)                            0.895

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)              -3737.745   -3737.745
  Scaling correction factor                                  1.133
      for the MLR correction                                      
  Loglikelihood unrestricted model (H1)      -3695.092   -3695.092
  Scaling correction factor                                  1.051
      for the MLR correction                                      
                                                                  
  Akaike (AIC)                                7517.490    7517.490
  Bayesian (BIC)                              7595.339    7595.339
  Sample-size adjusted Bayesian (SABIC)       7528.739    7528.739

Root Mean Square Error of Approximation:

  RMSEA                                          0.092       0.093
  90 Percent confidence interval - lower         0.071       0.073
  90 Percent confidence interval - upper         0.114       0.115
  P-value H_0: RMSEA &lt;= 0.050                    0.001       0.001
  P-value H_0: RMSEA &gt;= 0.080                    0.840       0.862
                                                                  
  Robust RMSEA                                               0.092
  90 Percent confidence interval - lower                     0.072
  90 Percent confidence interval - upper                     0.114
  P-value H_0: Robust RMSEA &lt;= 0.050                         0.001
  P-value H_0: Robust RMSEA &gt;= 0.080                         0.849

Standardized Root Mean Square Residual:

  SRMR                                           0.065       0.065

Parameter Estimates:

  Standard errors                             Sandwich
  Information bread                           Observed
  Observed information based on                Hessian

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual =~                                           
    x1                1.000                           
    x2                0.554    0.132    4.191    0.000
    x3                0.729    0.141    5.170    0.000
  textual =~                                          
    x4                1.000                           
    x5                1.113    0.066   16.946    0.000
    x6                0.926    0.061   15.089    0.000
  speed =~                                            
    x7                1.000                           
    x8                1.180    0.130    9.046    0.000
    x9                1.082    0.266    4.060    0.000

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual ~~                                           
    textual           0.408    0.099    4.110    0.000
    speed             0.262    0.060    4.366    0.000
  textual ~~                                          
    speed             0.173    0.056    3.081    0.002

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                0.549    0.156    3.509    0.000
   .x2                1.134    0.112   10.135    0.000
   .x3                0.844    0.100    8.419    0.000
   .x4                0.371    0.050    7.382    0.000
   .x5                0.446    0.057    7.870    0.000
   .x6                0.356    0.047    7.658    0.000
   .x7                0.799    0.097    8.222    0.000
   .x8                0.488    0.120    4.080    0.000
   .x9                0.566    0.119    4.768    0.000
    visual            0.809    0.180    4.486    0.000
    textual           0.979    0.121    8.075    0.000
    speed             0.384    0.107    3.596    0.000</code></pre>
</div>
</div>
<p>The output now includes a column of <strong>robust global fit indices</strong>- that provides more reliable assessments under non-normal conditions. Also, the standard errors are computed using a Huber-White sandwich estimator that are resistant to issues like non-normality and clustering.</p>
</section>
<section id="handling-missing-data-in-sem" class="level3">
<h3 class="anchored" data-anchor-id="handling-missing-data-in-sem">Handling Missing Data in SEM</h3>
<p>By default, <strong>lavaan</strong> performs listwise deletion for missing data, meaning that any individual with missing values is excluded from the analysis. This approach can lead to significant data loss and potentially biased results.</p>
<p>An alternative approach is to use <strong>Full-Information Maximum Likelihood (FIML)</strong>, which assumes data are <em>missing at random</em> (MAR). Under MAR, missingness on a variable can be related to other observed variables but not to the variable itself. FIML leverages all available data to estimate parameters without discarding cases, making it a preferred approach for handling missingness in SEM.</p>
<p>In <strong>lavaan</strong>, we can enable FIML by adding <code>missing = "ml"</code> or <code>fiml</code> to your model specification. You can type <code>?lavOptions</code> in R to see the list of all available options.</p>
<p>Let’s fit the model with the default</p>
<p><strong>Listwise Deletion (Default Behavior)</strong>:</p>
<p>But before then, we can quickly generate some missing data for the HolzingerSwineford1939</p>
<p>The missing values for <code>x5</code> are dependent on <code>x1</code>, with the lowest 20% of <code>x1</code> having missing <code>x5</code> values.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb180"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb180-1"><a href="#cb180-1" aria-hidden="true" tabindex="-1"></a>data_miss <span class="ot">&lt;-</span> lavaan<span class="sc">::</span>HolzingerSwineford1939</span>
<span id="cb180-2"><a href="#cb180-2" aria-hidden="true" tabindex="-1"></a>data_miss<span class="sc">$</span>x5 <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(data_miss<span class="sc">$</span>x1 <span class="sc">&lt;=</span> <span class="fu">quantile</span>(data_miss<span class="sc">$</span>x1, .<span class="dv">2</span>), </span>
<span id="cb180-3"><a href="#cb180-3" aria-hidden="true" tabindex="-1"></a>                       <span class="cn">NA</span>, data_miss<span class="sc">$</span>x5)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Also, the missing values for <code>x9</code> are associated with <code>age</code>, where the youngest 10% of the age group have missing values for <code>x9</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb181"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb181-1"><a href="#cb181-1" aria-hidden="true" tabindex="-1"></a>data_miss<span class="sc">$</span>age <span class="ot">&lt;-</span> data_miss<span class="sc">$</span>ageyr <span class="sc">+</span> data_miss<span class="sc">$</span>agemo<span class="sc">/</span><span class="dv">12</span></span>
<span id="cb181-2"><a href="#cb181-2" aria-hidden="true" tabindex="-1"></a>data_miss<span class="sc">$</span>x9 <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(data_miss<span class="sc">$</span>age <span class="sc">&lt;=</span> <span class="fu">quantile</span>(data_miss<span class="sc">$</span>age, .<span class="dv">1</span>), </span>
<span id="cb181-3"><a href="#cb181-3" aria-hidden="true" tabindex="-1"></a>                       <span class="cn">NA</span>, data_miss<span class="sc">$</span>x9)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can also check the missing data indicators (missing: true, complete: false)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb182"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb182-1"><a href="#cb182-1" aria-hidden="true" tabindex="-1"></a>na.eval <span class="ot">=</span> <span class="fu">is.na</span>(data_miss)</span>
<span id="cb182-2"><a href="#cb182-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(na.eval[,<span class="dv">7</span><span class="sc">:</span><span class="dv">15</span>], <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        x1    x2    x3    x4    x5    x6    x7    x8    x9
[1,] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE
[2,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
[3,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE</code></pre>
</div>
</div>
<p>Count the missing value for each variable</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb184"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb184-1"><a href="#cb184-1" aria-hidden="true" tabindex="-1"></a><span class="fu">colSums</span>(na.eval)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    id    sex  ageyr  agemo school  grade     x1     x2     x3     x4     x5 
     0      0      0      0      0      1      0      0      0      0     65 
    x6     x7     x8     x9    age 
     0      0      0     33      0 </code></pre>
</div>
</div>
<p>As we can see, we have 65 missing values on x5 and 33 on x9</p>
<p>Now we can fit the model</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb186"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb186-1"><a href="#cb186-1" aria-hidden="true" tabindex="-1"></a>fit.listwise <span class="ot">&lt;-</span> lavaan<span class="sc">::</span><span class="fu">sem</span>(model4, </span>
<span id="cb186-2"><a href="#cb186-2" aria-hidden="true" tabindex="-1"></a>                    <span class="at">data =</span> data_miss, </span>
<span id="cb186-3"><a href="#cb186-3" aria-hidden="true" tabindex="-1"></a>                    <span class="at">fixed.x =</span> <span class="cn">FALSE</span>)</span>
<span id="cb186-4"><a href="#cb186-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb186-5"><a href="#cb186-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit.listwise, <span class="at">fit.measures =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-19 ended normally after 35 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        21

                                                  Used       Total
  Number of observations                           209         301

Model Test User Model:
                                                      
  Test statistic                                57.615
  Degrees of freedom                                24
  P-value (Chi-square)                           0.000

Model Test Baseline Model:

  Test statistic                               602.992
  Degrees of freedom                                36
  P-value                                        0.000

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.941
  Tucker-Lewis Index (TLI)                       0.911

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)              -2531.199
  Loglikelihood unrestricted model (H1)      -2502.391
                                                      
  Akaike (AIC)                                5104.397
  Bayesian (BIC)                              5174.586
  Sample-size adjusted Bayesian (SABIC)       5108.047

Root Mean Square Error of Approximation:

  RMSEA                                          0.082
  90 Percent confidence interval - lower         0.055
  90 Percent confidence interval - upper         0.109
  P-value H_0: RMSEA &lt;= 0.050                    0.028
  P-value H_0: RMSEA &gt;= 0.080                    0.572

Standardized Root Mean Square Residual:

  SRMR                                           0.068

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual =~                                           
    x1                1.000                           
    x2                0.616    0.176    3.501    0.000
    x3                0.728    0.188    3.870    0.000
  textual =~                                          
    x4                1.000                           
    x5                1.170    0.081   14.521    0.000
    x6                0.955    0.068   14.114    0.000
  speed =~                                            
    x7                1.000                           
    x8                1.063    0.191    5.582    0.000
    x9                0.853    0.153    5.586    0.000

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual ~~                                           
    textual           0.308    0.065    4.700    0.000
    speed             0.149    0.050    2.983    0.003
  textual ~~                                          
    speed             0.169    0.062    2.715    0.007

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                0.277    0.103    2.685    0.007
   .x2                1.151    0.122    9.420    0.000
   .x3                1.018    0.115    8.816    0.000
   .x4                0.438    0.059    7.378    0.000
   .x5                0.369    0.066    5.573    0.000
   .x6                0.327    0.049    6.663    0.000
   .x7                0.716    0.101    7.079    0.000
   .x8                0.518    0.095    5.427    0.000
   .x9                0.590    0.079    7.492    0.000
    visual            0.448    0.119    3.759    0.000
    textual           0.960    0.136    7.049    0.000
    speed             0.441    0.115    3.831    0.000</code></pre>
</div>
</div>
<p>Looking at the output. The used observations = 209 as compared to total obs of 301. So, there’s reduction in sample size due to listwise deletion.</p>
<p>Now, let’s see what happens when we use <strong>Full-Information Maximum Likelihood (FIML):</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb188"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb188-1"><a href="#cb188-1" aria-hidden="true" tabindex="-1"></a>fit.fiml <span class="ot">&lt;-</span> lavaan<span class="sc">::</span><span class="fu">sem</span>(model4, </span>
<span id="cb188-2"><a href="#cb188-2" aria-hidden="true" tabindex="-1"></a>                <span class="at">data =</span> data_miss, </span>
<span id="cb188-3"><a href="#cb188-3" aria-hidden="true" tabindex="-1"></a>                <span class="at">missing =</span> <span class="st">'fiml'</span>,</span>
<span id="cb188-4"><a href="#cb188-4" aria-hidden="true" tabindex="-1"></a>                <span class="at">fixed.x =</span> <span class="cn">FALSE</span>)</span>
<span id="cb188-5"><a href="#cb188-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb188-6"><a href="#cb188-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit.fiml, <span class="at">fit.measures =</span> <span class="cn">TRUE</span>)   </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-19 ended normally after 52 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        30

  Number of observations                           301
  Number of missing patterns                         4

Model Test User Model:
                                                      
  Test statistic                                71.947
  Degrees of freedom                                24
  P-value (Chi-square)                           0.000

Model Test Baseline Model:

  Test statistic                               842.783
  Degrees of freedom                                36
  P-value                                        0.000

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.941
  Tucker-Lewis Index (TLI)                       0.911
                                                      
  Robust Comparative Fit Index (CFI)             0.939
  Robust Tucker-Lewis Index (TLI)                0.908

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)              -3609.653
  Loglikelihood unrestricted model (H1)      -3573.679
                                                      
  Akaike (AIC)                                7279.306
  Bayesian (BIC)                              7390.519
  Sample-size adjusted Bayesian (SABIC)       7295.376

Root Mean Square Error of Approximation:

  RMSEA                                          0.081
  90 Percent confidence interval - lower         0.060
  90 Percent confidence interval - upper         0.103
  P-value H_0: RMSEA &lt;= 0.050                    0.009
  P-value H_0: RMSEA &gt;= 0.080                    0.568
                                                      
  Robust RMSEA                                   0.086
  90 Percent confidence interval - lower         0.063
  90 Percent confidence interval - upper         0.110
  P-value H_0: Robust RMSEA &lt;= 0.050             0.006
  P-value H_0: Robust RMSEA &gt;= 0.080             0.693

Standardized Root Mean Square Residual:

  SRMR                                           0.060

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Observed
  Observed information based on                Hessian

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual =~                                           
    x1                1.000                           
    x2                0.549    0.110    5.001    0.000
    x3                0.720    0.117    6.166    0.000
  textual =~                                          
    x4                1.000                           
    x5                1.146    0.071   16.114    0.000
    x6                0.949    0.058   16.259    0.000
  speed =~                                            
    x7                1.000                           
    x8                1.175    0.154    7.632    0.000
    x9                0.982    0.160    6.143    0.000

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual ~~                                           
    textual           0.420    0.080    5.256    0.000
    speed             0.248    0.056    4.416    0.000
  textual ~~                                          
    speed             0.161    0.050    3.201    0.001

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                4.936    0.067   73.473    0.000
   .x2                6.088    0.068   89.855    0.000
   .x3                2.250    0.065   34.579    0.000
   .x4                3.061    0.067   45.694    0.000
   .x5                4.316    0.078   55.567    0.000
   .x6                2.186    0.063   34.667    0.000
   .x7                4.186    0.063   66.766    0.000
   .x8                5.527    0.058   94.854    0.000
   .x9                5.381    0.061   88.408    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                0.540    0.121    4.458    0.000
   .x2                1.135    0.105   10.845    0.000
   .x3                0.851    0.095    8.948    0.000
   .x4                0.397    0.050    8.015    0.000
   .x5                0.378    0.060    6.301    0.000
   .x6                0.337    0.044    7.696    0.000
   .x7                0.773    0.083    9.363    0.000
   .x8                0.455    0.086    5.278    0.000
   .x9                0.624    0.085    7.358    0.000
    visual            0.819    0.152    5.391    0.000
    textual           0.953    0.112    8.533    0.000
    speed             0.410    0.090    4.539    0.000</code></pre>
</div>
</div>
<p>Now, you can look at the number of obs and the missing patterns- you can see the difference with the default behavior?</p>
<p>Essentially, FIML uses all available data, resulting in no loss of sample size and a more complete analysis.</p>
<p>Note that FIML is available only for maximum likelihood (ML)-based estimators. For the WLS family of estimators (e.g., WLS or WLSMV), which are not ML estimators, FIML is not supported. Instead, you can use <code>missing = "pairwise"</code>, which bases estimates on pairwise available data. However, this approach is generally less robust and may lead to less accurate parameter estimates. So, my suggestion is that for models with missing data, using FIML (<code>missing = "ml" or "fiml"</code>) is typically the most reliable method in <strong>lavaan</strong> when the data meet the MAR assumption. While listwise deletion is the default, it should be avoided when possible due to its tendency to discard valuable data and introduce bias.</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>