[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to EDUC 6003 Advanced Statistics. This website will be used for all the tutorials of this course. We will be using R/RStudio throughout the semester. However, anyone interested in using Python should feel free to do so (and I‚Äôm happy to chat about that). If you‚Äôre very new to R for statistical analysis and would like a quick intro, please refer to this website R Workshop for Statistical Analysis.\nIn fact, this website was built entirely using R!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "This tutorial will serve as a Guide to Enhanced Reliability Estimation with R\n\n\nReliability refers to the consistency and precision of measurement instruments. In psychological testing, it assesses the extent to which a test produces stable and consistent results.\n\n\nMeasurement Precision: Ensures that the scores accurately reflect the true attributes being measured.\nResearch Validity: High reliability is a prerequisite for valid conclusions and replicable research findings.\nError Reduction: Minimizes the impact of random errors, enhancing the clarity of observed relationships between constructs.\n\n\n\nInternal Consistency: Degree to which items within a test measure the same construct.\nTest-Retest Reliability: Consistency of scores over time.\nInter-Rater Reliability: Agreement between different raters or observers.\n\n\n\n\n\nClassical Test Theory Overview: CTT posits that each observed score is composed of a true score and an error score:\n\\[ X = T + E \\]\nwhere:\nùëã= Observed score ùëá= True score ùê∏= Error score\n\n\nThis is a widely used measure of internal consistency reliability within CTT. It estimates the extent to which items on a test measure the same underlying construct.\n\\[\n\\alpha = \\frac{N}{N-1} \\left(1 - \\frac{\\sum \\sigma^2_{E}}{\\sigma^2_{X}}\\right)\n\\]\nWhere:\n\\(\\alpha\\) = Cronbach‚Äôs Alpha\nùëÅ = Number of items in the test\n\\(\\sigma^2_{E}\\) = Variance of the error scores\n\\(\\sigma^2_{X}\\) = Variance of the observed total scores\n\n\nUnidimensionality: All items measure a single construct.\nTau Equivalence: Each item has the same true score variance.\nIndependence of Errors: Error terms are uncorrelated across items.\n\n\n\nSensitivity to Tau Equivalence: Violations can lead to underestimation or overestimation of reliability.\nAssumes Unidimensionality: Not suitable for multidimensional scales without adjustments.\nIgnores Factor Structure: Does not account for the underlying factor model of the test.\n\n\n\n\nCoefficient Omega is a more robust alternative to Cronbach‚Äôs Alpha, especially when the assumption of tau-equivalence (equal factor loadings) is violated. Omega takes into account the factor structure of the test, making it suitable for both unidimensional and multidimensional scales.\n\n\nOmega Total (œâ‚Çú): Accounts for all common factors, both general and specific.\nOmega Hierarchical (œâ‚Çï): Represents the proportion of variance attributable to a general factor alone.\nOmega Total is given by:\n\\[\n\\omega_t = \\frac{\\sum_{i=1}^{k} \\lambda_i}{\\sum_{i=1}^{k} \\lambda_i + \\sum_{i=1}^{k} \\theta_i}\n\\]\nWhere:\n\\(\\omega_t\\) = Omega Total\n\\(\\lambda_i\\) = Factor loading for item\n\\(\\theta_i\\) = Unique variance (error variance) for item\n\\(k\\) = Total number of items\nFor a hierarchical model, Omega Hierarchical is:\n\\[\n\\omega_h = \\frac{\\lambda_g^2}{\\lambda_g^2 + \\sum_{i=1}^{k} \\theta_i}\n\\]\nwhere:\n\\(\\omega_h\\) = Omega Hierarchical\n\\(\\lambda_g\\) = Factor loading of the general factor\n\\(\\theta_i\\) = Unique variance for item \\(i\\)\n\n\n\nFactor Structure Incorporation: Utilizes confirmatory factor analysis (CFA) to model the underlying structure.\nLess Sensitive to Tau Equivalence Violations: Provides more accurate reliability estimates when tau equivalence is not met.\nApplicability to Multidimensional Scales: Suitable for tests measuring multiple constructs.\n\n\n\n\n\nHere, I will walk through the step-by-step process of calculating Cronbach‚Äôs Alpha and Coefficient Omega using R.\nLoad the necessary packages.\n\npacman::p_load(psych,lavaan,semTools,tidyverse,semTools,psych,tidyverse,lavaan,rio,parameters,\n               nFactors,EGAnet,PCDimension)\n\n\n\n\nThe Big Five Inventory (BFI) is a widely used dataset in personality psychology, measuring the five major dimensions of personality. We‚Äôll focus on the Openness trait for this tutorial.\n\n# Make sure you've loaded the psych package\n\n\n# Load the BFI dataset\ndata(bfi)\n\n# load data file\nbfi &lt;- bfi\nnames(bfi)\n\n [1] \"A1\"        \"A2\"        \"A3\"        \"A4\"        \"A5\"        \"C1\"       \n [7] \"C2\"        \"C3\"        \"C4\"        \"C5\"        \"E1\"        \"E2\"       \n[13] \"E3\"        \"E4\"        \"E5\"        \"N1\"        \"N2\"        \"N3\"       \n[19] \"N4\"        \"N5\"        \"O1\"        \"O2\"        \"O3\"        \"O4\"       \n[25] \"O5\"        \"gender\"    \"education\" \"age\"      \n\n# View the structure of the dataset\n#str(bfi)\n\nThe dataset contains 2,800 participants with various demographic and personality-related variables. A1 to A5 correspond to items measuring the Openness trait.\n\n\nFor this tutorial, we‚Äôll focus on five items measuring the Openness trait. These items are typically labeled as A1 to A5 in the BFI dataset.\n\n\n\n# Select columns that contain \"O\" in their names and remove rows with NA values\noppeness &lt;- bfi %&gt;%\n  select(matches(\"^O\")) %&gt;%\n  drop_na()\n\nhead(oppeness)\n\n  O1 O2 O3 O4 O5\n1  3  6  3  4  3\n2  4  2  4  3  3\n3  4  2  5  5  2\n4  3  3  4  3  5\n5  3  3  4  3  3\n6  4  3  5  6  1\n\n\nEach A variable represents a Likert-type item measuring Openness. Responses range from 1 to 6, treated as continuous variables for analysis.\n\n\n\n\nBefore we continue, let‚Äôs check any missing data.\n\n# Check for missing values\nsum(is.na(oppeness))\n\n[1] 0\n\n\nIn this dataset, there are no missing values in the Openness items. If missing values were present, then we need to address that.\n\n\n\n\nRecall that Cronbach‚Äôs Alpha (Œ±) is a measure of internal consistency that measures how closely related a set of items are as a group.\n\n\n\n# Calculate Cronbach's Alpha using the psych package\n#alpha_result &lt;- psych::alpha(oppeness)\n\n# Print the result\n#print(alpha_result)\n\nBecause some items were negatively correlated with the first principal component, we probably should reverse them.\n\n# Reversing item O2 and O5\n\nq &lt;- c(\"O2\",\"O5\")\nreverse &lt;- function(x){\n  x.reversed &lt;- 7 +0 - x\n}\n\noppeness[, c(\"O2R\", \"O5R\")] &lt;- reverse(oppeness[,c(\"O2\",\"O5\")])\n\n# compare original and reversed responses\noppeness[1:6,]\n\n  O1 O2 O3 O4 O5 O2R O5R\n1  3  6  3  4  3   1   4\n2  4  2  4  3  3   5   4\n3  4  2  5  5  2   5   5\n4  3  3  4  3  5   4   2\n5  3  3  4  3  3   4   4\n6  4  3  5  6  1   4   6\n\n\nNow, we can compute the alpha\n\n# compute alpha coefficient \n\nalpha_result &lt;- psych::alpha(oppeness[, -c(2,5)])\n\n# Print the result\nprint(alpha_result)\n\n\nReliability analysis   \nCall: psych::alpha(x = oppeness[, -c(2, 5)])\n\n  raw_alpha std.alpha G6(smc) average_r S/N   ase mean   sd median_r\n       0.6      0.61    0.57      0.24 1.6 0.012  4.6 0.81     0.23\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.58   0.6  0.63\nDuhachek  0.58   0.6  0.63\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nO1       0.54      0.54    0.48      0.23 1.2    0.014 0.0087  0.23\nO3       0.50      0.50    0.44      0.20 1.0    0.015 0.0065  0.20\nO4       0.61      0.62    0.56      0.29 1.7    0.012 0.0040  0.29\nO2R      0.57      0.57    0.51      0.25 1.3    0.014 0.0077  0.21\nO5R      0.52      0.53    0.48      0.22 1.1    0.015 0.0109  0.21\n\n Item statistics \n       n raw.r std.r r.cor r.drop mean  sd\nO1  2726  0.61  0.65  0.51   0.39  4.8 1.1\nO3  2726  0.68  0.69  0.59   0.45  4.4 1.2\nO4  2726  0.50  0.52  0.29   0.22  4.9 1.2\nO2R 2726  0.66  0.60  0.44   0.34  4.3 1.6\nO5R 2726  0.67  0.66  0.52   0.42  4.5 1.3\n\nNon missing response frequency for each item\n       1    2    3    4    5    6 miss\nO1  0.01 0.04 0.08 0.22 0.33 0.33    0\nO3  0.03 0.05 0.10 0.28 0.34 0.20    0\nO4  0.02 0.05 0.06 0.17 0.32 0.39    0\nO2R 0.06 0.10 0.15 0.14 0.26 0.29    0\nO5R 0.02 0.07 0.13 0.19 0.32 0.27    0\n\n\nExplanation:\nraw_alpha: The Cronbach‚Äôs Alpha coefficient.\nstd.alpha: Standardized alpha, similar to raw_alpha.\nG6(smc): Generalizability theory estimate with squared multiple correlations.\naverage_r: Average inter-item correlation.\nS/N: Signal-to-noise ratio.\nase: Asymptotic standard error.\nConfidence Intervals: Lower and upper bounds for alpha.\nAs we can see, the Cronbach‚Äôs Alpha for the Openness items is 0.6, indicating strong internal consistency. The average inter-item correlation is 0.24, moderate and within psychological scales.\n\n\n\n\nConfirmatory Factor Analysis (CFA) is used to verify the factor structure of a set of observed variables. In our case, we assume a unidimensional structure.\n\n\nLet‚Äôs specify a one-factor model where all items load on a single latent factor.\n\n# Specify model\nmod1f &lt;- \"\nopenness =~ O1 + O2R + O3 + O4 + O5R\n\"\n\n\n\n\nFit the Model Using lavaan:\n\n#pacman::p_load(lavaan)\n# Estimate model\nfit.one.f &lt;- cfa(mod1f, data=oppeness, std.lv=T, missing='direct', \n             estimator='MLR')\n\n# The results can be viewed using the summary\n\nsummary(fit.one.f, fit.measures=T, standardized=T)\n\nlavaan 0.6-19 ended normally after 22 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        15\n\n  Number of observations                          2726\n  Number of missing patterns                         1\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                80.583      67.248\n  Degrees of freedom                                 5           5\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  1.198\n    Yuan-Bentler correction (Mplus variant)                       \n\nModel Test Baseline Model:\n\n  Test statistic                              1375.389    1049.226\n  Degrees of freedom                                10          10\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.311\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.945       0.940\n  Tucker-Lewis Index (TLI)                       0.889       0.880\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.946\n  Robust Tucker-Lewis Index (TLI)                            0.891\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -22078.661  -22078.661\n  Scaling correction factor                                  1.167\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)     -22038.369  -22038.369\n  Scaling correction factor                                  1.174\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                               44187.322   44187.322\n  Bayesian (BIC)                             44275.980   44275.980\n  Sample-size adjusted Bayesian (SABIC)      44228.321   44228.321\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.074       0.068\n  90 Percent confidence interval - lower         0.061       0.055\n  90 Percent confidence interval - upper         0.089       0.081\n  P-value H_0: RMSEA &lt;= 0.050                    0.002       0.012\n  P-value H_0: RMSEA &gt;= 0.080                    0.280       0.066\n                                                                  \n  Robust RMSEA                                               0.074\n  90 Percent confidence interval - lower                     0.058\n  90 Percent confidence interval - upper                     0.090\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.006\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.285\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.029       0.029\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  openness =~                                                           \n    O1                0.616    0.029   21.346    0.000    0.616    0.546\n    O2R               0.701    0.041   17.170    0.000    0.701    0.449\n    O3                0.792    0.032   24.649    0.000    0.792    0.649\n    O4                0.357    0.030   11.749    0.000    0.357    0.294\n    O5R               0.685    0.036   19.194    0.000    0.685    0.517\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .O1                4.819    0.022  223.110    0.000    4.819    4.273\n   .O2R               4.300    0.030  143.782    0.000    4.300    2.754\n   .O3                4.439    0.023  189.916    0.000    4.439    3.637\n   .O4                4.898    0.023  210.231    0.000    4.898    4.027\n   .O5R               4.516    0.025  177.976    0.000    4.516    3.409\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .O1                0.893    0.037   23.923    0.000    0.893    0.702\n   .O2R               1.947    0.068   28.607    0.000    1.947    0.798\n   .O3                0.862    0.050   17.172    0.000    0.862    0.579\n   .O4                1.352    0.052   25.967    0.000    1.352    0.914\n   .O5R               1.286    0.059   21.822    0.000    1.286    0.732\n    openness          1.000                               1.000    1.000\n\n\nExplanation:\nEstimator: Maximum Likelihood (ML).\nTest Statistics: The Chi-square test is significant (ùëù&lt;0.001), indicating a poor fit.\nFit Indices:\nCFI (0.94): above 0.90.\nTLI (0.88): Below the threshold of 0.90.\nRMSEA (0.068): Indicates relatively weak fit (‚â•0.05).\nSRMR (0.029): Great fit (‚â§0.08).\n\nresiduals(fit.one.f, type='cor')\n\n$type\n[1] \"cor.bollen\"\n\n$cov\n        O1    O2R     O3     O4    O5R\nO1   0.000                            \nO2R -0.026  0.000                     \nO3   0.037 -0.024  0.000              \nO4   0.013 -0.052  0.000  0.000       \nO5R -0.044  0.090 -0.022  0.027  0.000\n\n$mean\n O1 O2R  O3  O4 O5R \n  0   0   0   0   0 \n\n\nThe fit statistics from the Robust column in the summary suggest that this one-factor model provides a moderate fit to the data. While the Comparative Fit Index (CFI) of 0.94 indicates an acceptable fit, the Tucker-Lewis Index (TLI) of 0.88 is relatively lower, and the Root Mean Square Error of Approximation (RMSEA) is relatively high at 0.08.\nThe factor loadings (ùúÜÃÇ) show significant variation, ranging from 0.357 to 0.792, which implies that the assumption of equal loadings (tau equivalence) does not hold for this openness test. As a result, omega (œâu) should be a more suitable measure of reliability than Cronbach‚Äôs alpha. We can compute the œâu estimate by running the reliability function from the semTools package on the one-factor model object (fit1f).\n\nreliability(fit.one.f)\n\n        openness\nalpha  0.6025464\nomega  0.6103741\nomega2 0.6103741\nomega3 0.6098642\navevar 0.2484010\n\n\nomega and omega2 measure reliability based on the variance expected by the model, while omega3 measures it based on the actual variance seen in your data. The small difference between omega and omega3 suggests that the model‚Äôs predictions of variance are somewhat close to what‚Äôs observed in the sample.\n\n\n\n\nRecall that Coefficient Omega (œâ) is a reliability estimate that accounts for the factor structure of the test, providing a more accurate measure than Cronbach‚Äôs Alpha, especially in the presence of multidimensionality or when tau-equivalence is violated.\nSince factor loadings derived from polychoric correlations represent the link between the factor and the underlying latent response variables (not the actual responses from the items), using the œâu formula here would tell us how much of the variance in the latent response variables is explained by the factor. However, this doesn‚Äôt reflect the true variance in the sum of the observed item responses. Essentially, in this case, œâu would give us the reliability of a hypothetical total score based on the latent variables rather than the actual observed total score.\nTo correct for this, Green and Yang (2009b) proposed a new reliability estimate called œâu-cat, which adjusts the reliability calculation to align with the observed total score. This estimate is more accurate for unidimensional scales with categorical items, especially when the response patterns vary across items.\nSince the psychoticism items use a 4-point rating scale, I fit the one-factor model using polychoric correlations and the WLSMV estimator (weighted least squares with mean and variance adjustment). This approach is recommended for confirmatory factor analysis involving polychoric correlations, as it is more robust than the maximum likelihood (ML) estimator.\n\n#load the data\npotic &lt;- import(\"data/potic.csv\")\n\n# Specify model\nmod.one.fCat &lt;- 'psyctcsm =~ DDP1 + DDP2 +\nDDP3 + DDP4'\n\n\n# Estimate model\nfit.one.fCat &lt;- cfa(mod.one.fCat, data=potic, std.lv=TRUE, ordered=T, estimator='WLSMV')\n\n# Retrieving the results\nsummary(fit.one.fCat, fit.measures=TRUE, standardized=TRUE)\n\nlavaan 0.6-19 ended normally after 10 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        20\n\n                                                  Used       Total\n  Number of observations                           498         500\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                 7.117      14.910\n  Degrees of freedom                                 2           2\n  P-value (Chi-square)                           0.028       0.001\n  Scaling correction factor                                  0.480\n  Shift parameter                                            0.089\n    simple second-order correction                                \n\nModel Test Baseline Model:\n\n  Test statistic                              1635.647    1316.086\n  Degrees of freedom                                 6           6\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.244\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.997       0.990\n  Tucker-Lewis Index (TLI)                       0.991       0.970\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.969\n  Robust Tucker-Lewis Index (TLI)                            0.908\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.072       0.114\n  90 Percent confidence interval - lower         0.020       0.065\n  90 Percent confidence interval - upper         0.132       0.171\n  P-value H_0: RMSEA &lt;= 0.050                    0.200       0.019\n  P-value H_0: RMSEA &gt;= 0.080                    0.479       0.880\n                                                                  \n  Robust RMSEA                                               0.147\n  90 Percent confidence interval - lower                     0.089\n  90 Percent confidence interval - upper                     0.213\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.004\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.970\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.033       0.033\n\nParameter Estimates:\n\n  Parameterization                               Delta\n  Standard errors                           Robust.sem\n  Information                                 Expected\n  Information saturated (h1) model        Unstructured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  psyctcsm =~                                                           \n    DDP1              0.894    0.028   31.538    0.000    0.894    0.894\n    DDP2              0.753    0.028   26.711    0.000    0.753    0.753\n    DDP3              0.698    0.030   23.314    0.000    0.698    0.698\n    DDP4              0.513    0.040   12.738    0.000    0.513    0.513\n\nThresholds:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    DDP1|t1          -0.716    0.062  -11.591    0.000   -0.716   -0.716\n    DDP1|t2          -0.040    0.056   -0.716    0.474   -0.040   -0.040\n    DDP1|t3           0.296    0.057    5.185    0.000    0.296    0.296\n    DDP1|t4           1.034    0.069   15.065    0.000    1.034    1.034\n    DDP2|t1          -0.580    0.060   -9.693    0.000   -0.580   -0.580\n    DDP2|t2           0.208    0.057    3.668    0.000    0.208    0.208\n    DDP2|t3           0.562    0.060    9.431    0.000    0.562    0.562\n    DDP2|t4           1.096    0.070   15.570    0.000    1.096    1.096\n    DDP3|t1          -1.203    0.074  -16.298    0.000   -1.203   -1.203\n    DDP3|t2          -0.425    0.058   -7.318    0.000   -0.425   -0.425\n    DDP3|t3           0.081    0.056    1.432    0.152    0.081    0.081\n    DDP3|t4           0.913    0.066   13.909    0.000    0.913    0.913\n    DDP4|t1          -1.605    0.092  -17.382    0.000   -1.605   -1.605\n    DDP4|t2          -1.060    0.069  -15.285    0.000   -1.060   -1.060\n    DDP4|t3          -0.521    0.059   -8.817    0.000   -0.521   -0.521\n    DDP4|t4           0.431    0.058    7.406    0.000    0.431    0.431\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .DDP1              0.201                               0.201    0.201\n   .DDP2              0.433                               0.433    0.433\n   .DDP3              0.513                               0.513    0.513\n   .DDP4              0.737                               0.737    0.737\n    psyctcsm          1.000                               1.000    1.000\n\n\n\n# Estimate reliability\n\nreliability(fit.one.fCat)\n\nFor constructs with categorical indicators, Zumbo et al.`s (2007) \"ordinal alpha\" is calculated in addition to the standard alpha, which treats ordinal variables as numeric. See Chalmers (2018) for a critique of \"alpha.ord\" and the response by Zumbo & Kroc (2019). Likewise, average variance extracted is calculated from polychoric (polyserial) not Pearson correlations.\n\n\n           psyctcsm\nalpha     0.7680870\nalpha.ord 0.8007496\nomega     0.7902953\nomega2    0.7902953\nomega3    0.7932682\navevar    0.5289638\n\n\nWe can see that we have two estimates Cronbach‚Äôs alpha and differ a bit (0.80 & 0.77). The is because the 2nd alpha estimate is an example of ordinal alpha, which is calculated using a model based on polychoric correlations, while the first alpha was derived using the standard method based on product-moment covariances between the items. It‚Äôs important to note that ordinal alpha measures the reliability of the sum of the continuous, latent-response variables rather than the observed categorical item responses. Additionally, it still assumes equal factor loadings (tau equivalence). Because of these limitations, I suggest disregarding the alpha value reported by semTools::reliability when the model uses polychoric correlations.\nThe values shown in the omega and omega2 rows represent the œâu-cat estimate. The omega3 row shows a variation where the denominator uses the observed sample variance of ( X ). So, we can see œâu-cat estimates suggest that 79% of the variance in the total score for the psychoticism scale is explained by the single psychoticism factor.\n\n\n\nA bifactor model is a useful way to represent a multidimensional structure. In this model, there‚Äôs a general factor that affects all items, while additional specific factors (or group factors) explain the relationships (covariation) between certain subsets of items beyond what the general factor accounts for.\nFor the model to work correctly, the general factor needs to be uncorrelated with the specific factors. In contrast to other Confirmatory Factor Analysis (CFA) models where all factors can correlate freely, allowing the general factor to correlate with a specific factor in a bifactor model can lead to issues like non-convergence or incorrect solutions.\n\n\nWhen data fits well with a bifactor model, a reliability metric called omega hierarchical (\\(œâ_h\\)) is used. This measure reflects how much of the total score‚Äôs variance is attributable to the single general factor, even though the data involves multiple dimensions.\nHere, let‚Äôs demonstrate the estimation of \\(œâ_h\\) using R, I use data that from Flake, Ferland, & Flora, 2017 collected by administering the PCS to 154 students in an introductory statistics course.\n\npcs &lt;- import(\"data/pcs.csv\")\nnames(pcs)\n\n [1] \"TE1\"  \"TE2\"  \"TE3\"  \"TE4\"  \"TE5\"  \"OE1\"  \"OE2\"  \"OE3\"  \"OE4\"  \"LVA1\"\n[11] \"LVA2\" \"LVA3\" \"LVA4\" \"EM1\"  \"EM2\"  \"EM3\"  \"EM4\"  \"EM5\"  \"EM6\" \n\n\n\nmodBf &lt;- \"\ngen =~ TE1+TE2+TE3+TE4+TE5+OE1+OE2+OE3+OE4+LVA1+LVA2+LVA3+LVA4 +EM1+EM2+EM3+EM4+EM5+EM6\ns1 =~ TE1 + TE2 + TE3 + TE4 + TE5\ns2 =~ OE1 + OE2 + OE3 + OE4\ns3 =~ LVA1 + LVA2 + LVA3 + LVA4\ns4 =~ EM1 + EM2 + EM3 + EM4 + EM5 + EM6\n\"\n\n#Specify model\nfitBf &lt;- cfa(modBf, data=pcs, std.lv=T, estimator='MLR', orthogonal=T)\n\n#Retrieving the results\nsummary(fitBf, fit.measures=TRUE, standardized=T)\n\nlavaan 0.6-19 ended normally after 36 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        57\n\n                                                  Used       Total\n  Number of observations                           154         172\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               211.382     182.509\n  Degrees of freedom                               133         133\n  P-value (Chi-square)                           0.000       0.003\n  Scaling correction factor                                  1.158\n    Yuan-Bentler correction (Mplus variant)                       \n\nModel Test Baseline Model:\n\n  Test statistic                              2799.877    2260.239\n  Degrees of freedom                               171         171\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.239\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.970       0.976\n  Tucker-Lewis Index (TLI)                       0.962       0.970\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.978\n  Robust Tucker-Lewis Index (TLI)                            0.972\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -3456.819   -3456.819\n  Scaling correction factor                                  1.269\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)      -3351.128   -3351.128\n  Scaling correction factor                                  1.191\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                                7027.638    7027.638\n  Bayesian (BIC)                              7200.744    7200.744\n  Sample-size adjusted Bayesian (SABIC)       7020.331    7020.331\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.062       0.049\n  90 Percent confidence interval - lower         0.046       0.031\n  90 Percent confidence interval - upper         0.077       0.065\n  P-value H_0: RMSEA &lt;= 0.050                    0.108       0.520\n  P-value H_0: RMSEA &gt;= 0.080                    0.025       0.000\n                                                                  \n  Robust RMSEA                                               0.053\n  90 Percent confidence interval - lower                     0.032\n  90 Percent confidence interval - upper                     0.071\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.387\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.005\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.038       0.038\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  gen =~                                                                \n    TE1               1.041    0.071   14.715    0.000    1.041    0.843\n    TE2               1.045    0.084   12.430    0.000    1.045    0.794\n    TE3               0.848    0.090    9.392    0.000    0.848    0.721\n    TE4               0.984    0.075   13.097    0.000    0.984    0.834\n    TE5               1.004    0.082   12.264    0.000    1.004    0.819\n    OE1               0.787    0.083    9.537    0.000    0.787    0.631\n    OE2               0.819    0.080   10.207    0.000    0.819    0.695\n    OE3               0.738    0.089    8.319    0.000    0.738    0.605\n    OE4               0.742    0.087    8.512    0.000    0.742    0.636\n    LVA1              0.937    0.084   11.180    0.000    0.937    0.796\n    LVA2              0.863    0.071   12.205    0.000    0.863    0.797\n    LVA3              0.816    0.085    9.649    0.000    0.816    0.719\n    LVA4              0.865    0.098    8.802    0.000    0.865    0.695\n    EM1               0.968    0.095   10.215    0.000    0.968    0.715\n    EM2               0.930    0.078   11.957    0.000    0.930    0.800\n    EM3               0.959    0.091   10.542    0.000    0.959    0.731\n    EM4               0.885    0.091    9.679    0.000    0.885    0.732\n    EM5               1.043    0.086   12.121    0.000    1.043    0.816\n    EM6               1.108    0.100   11.054    0.000    1.108    0.750\n  s1 =~                                                                 \n    TE1               0.351    0.114    3.071    0.002    0.351    0.285\n    TE2               0.451    0.144    3.142    0.002    0.451    0.343\n    TE3               0.402    0.170    2.360    0.018    0.402    0.342\n    TE4               0.162    0.111    1.457    0.145    0.162    0.137\n    TE5               0.269    0.154    1.747    0.081    0.269    0.219\n  s2 =~                                                                 \n    OE1               0.626    0.107    5.860    0.000    0.626    0.502\n    OE2               0.516    0.096    5.399    0.000    0.516    0.438\n    OE3               0.673    0.107    6.291    0.000    0.673    0.552\n    OE4               0.739    0.085    8.738    0.000    0.739    0.634\n  s3 =~                                                                 \n    LVA1              0.253    0.107    2.357    0.018    0.253    0.215\n    LVA2              0.573    0.081    7.081    0.000    0.573    0.529\n    LVA3              0.422    0.104    4.051    0.000    0.422    0.372\n    LVA4              0.528    0.104    5.074    0.000    0.528    0.424\n  s4 =~                                                                 \n    EM1               0.506    0.152    3.324    0.001    0.506    0.374\n    EM2               0.346    0.086    4.026    0.000    0.346    0.298\n    EM3               0.567    0.121    4.682    0.000    0.567    0.432\n    EM4               0.562    0.098    5.707    0.000    0.562    0.464\n    EM5               0.479    0.097    4.930    0.000    0.479    0.375\n    EM6               0.651    0.148    4.403    0.000    0.651    0.440\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  gen ~~                                                                \n    s1                0.000                               0.000    0.000\n    s2                0.000                               0.000    0.000\n    s3                0.000                               0.000    0.000\n    s4                0.000                               0.000    0.000\n  s1 ~~                                                                 \n    s2                0.000                               0.000    0.000\n    s3                0.000                               0.000    0.000\n    s4                0.000                               0.000    0.000\n  s2 ~~                                                                 \n    s3                0.000                               0.000    0.000\n    s4                0.000                               0.000    0.000\n  s3 ~~                                                                 \n    s4                0.000                               0.000    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .TE1               0.318    0.067    4.777    0.000    0.318    0.209\n   .TE2               0.434    0.088    4.913    0.000    0.434    0.251\n   .TE3               0.501    0.104    4.827    0.000    0.501    0.363\n   .TE4               0.397    0.066    5.987    0.000    0.397    0.285\n   .TE5               0.421    0.073    5.799    0.000    0.421    0.281\n   .OE1               0.546    0.106    5.129    0.000    0.546    0.350\n   .OE2               0.451    0.075    6.003    0.000    0.451    0.325\n   .OE3               0.490    0.117    4.183    0.000    0.490    0.330\n   .OE4               0.263    0.071    3.718    0.000    0.263    0.194\n   .LVA1              0.442    0.064    6.873    0.000    0.442    0.320\n   .LVA2              0.100    0.062    1.607    0.108    0.100    0.085\n   .LVA3              0.443    0.075    5.892    0.000    0.443    0.344\n   .LVA4              0.523    0.088    5.954    0.000    0.523    0.337\n   .EM1               0.639    0.100    6.388    0.000    0.639    0.349\n   .EM2               0.365    0.060    6.049    0.000    0.365    0.271\n   .EM3               0.482    0.090    5.383    0.000    0.482    0.280\n   .EM4               0.364    0.083    4.395    0.000    0.364    0.249\n   .EM5               0.318    0.063    5.032    0.000    0.318    0.195\n   .EM6               0.534    0.117    4.564    0.000    0.534    0.244\n    gen               1.000                               1.000    1.000\n    s1                1.000                               1.000    1.000\n    s2                1.000                               1.000    1.000\n    s3                1.000                               1.000    1.000\n    s4                1.000                               1.000    1.000\n\n\n\nfitmeasures(fitBf)\n\n                         npar                          fmin \n                       57.000                         0.686 \n                        chisq                            df \n                      211.382                       133.000 \n                       pvalue                  chisq.scaled \n                        0.000                       182.509 \n                    df.scaled                 pvalue.scaled \n                      133.000                         0.003 \n         chisq.scaling.factor                baseline.chisq \n                        1.158                      2799.877 \n                  baseline.df               baseline.pvalue \n                      171.000                         0.000 \n        baseline.chisq.scaled            baseline.df.scaled \n                     2260.239                       171.000 \n       baseline.pvalue.scaled baseline.chisq.scaling.factor \n                        0.000                         1.239 \n                          cfi                           tli \n                        0.970                         0.962 \n                   cfi.scaled                    tli.scaled \n                        0.976                         0.970 \n                   cfi.robust                    tli.robust \n                        0.978                         0.972 \n                         nnfi                           rfi \n                        0.962                         0.903 \n                          nfi                          pnfi \n                        0.925                         0.719 \n                          ifi                           rni \n                        0.971                         0.970 \n                  nnfi.scaled                    rfi.scaled \n                        0.970                         0.896 \n                   nfi.scaled                   pnfi.scaled \n                        0.919                         0.715 \n                   ifi.scaled                    rni.scaled \n                        0.977                         0.976 \n                  nnfi.robust                    rni.robust \n                        0.972                         0.978 \n                         logl             unrestricted.logl \n                    -3456.819                     -3351.128 \n                          aic                           bic \n                     7027.638                      7200.744 \n                       ntotal                          bic2 \n                      154.000                      7020.331 \n            scaling.factor.h1             scaling.factor.h0 \n                        1.191                         1.269 \n                        rmsea                rmsea.ci.lower \n                        0.062                         0.046 \n               rmsea.ci.upper                rmsea.ci.level \n                        0.077                         0.900 \n                 rmsea.pvalue                rmsea.close.h0 \n                        0.108                         0.050 \n        rmsea.notclose.pvalue             rmsea.notclose.h0 \n                        0.025                         0.080 \n                 rmsea.scaled         rmsea.ci.lower.scaled \n                        0.049                         0.031 \n        rmsea.ci.upper.scaled           rmsea.pvalue.scaled \n                        0.065                         0.520 \n rmsea.notclose.pvalue.scaled                  rmsea.robust \n                        0.000                         0.053 \n        rmsea.ci.lower.robust         rmsea.ci.upper.robust \n                        0.032                         0.071 \n          rmsea.pvalue.robust  rmsea.notclose.pvalue.robust \n                        0.387                         0.005 \n                          rmr                    rmr_nomean \n                        0.056                         0.056 \n                         srmr                  srmr_bentler \n                        0.038                         0.038 \n          srmr_bentler_nomean                          crmr \n                        0.038                         0.040 \n                  crmr_nomean                    srmr_mplus \n                        0.040                         0.038 \n            srmr_mplus_nomean                         cn_05 \n                        0.038                       118.233 \n                        cn_01                           gfi \n                      127.659                         0.877 \n                         agfi                          pgfi \n                        0.824                         0.614 \n                          mfi                          ecvi \n                        0.775                         2.113 \n\n\nFrom the results above, we can the bifactor model fits the PCS data well, with robust model-fit statistics, CFI = 0.978, TLI = 0.972, RMSEA = 0.053. Thus, it is reasonable to calculate \\(œâ_h\\) to estimate how reliably the PCS total score measures the general psychological-cost factor.\n\nreliability(fitBf)\n\n             gen         s1        s2        s3        s4\nalpha  0.9638781 0.92504205 0.8992820 0.9052459 0.9405882\nomega  0.9741033 0.56377307 0.7884791 0.6766430 0.7816839\nomega2 0.9094893 0.09237594 0.3666293 0.1880759 0.2054075\nomega3 0.9077636 0.09240479 0.3666634 0.1878380 0.2053012\navevar        NA         NA        NA        NA        NA\n\n\nThe values shown under the ‚Äúgen‚Äù column relate to the general psychological cost factor. The omega estimate (0.974) doesn‚Äôt take the specific factors into account when calculating the variance of the total score, so it‚Äôs not the appropriate reliability measure for the PCS total score. Instead, the omega2 and omega3 values under ‚Äúgen‚Äù represent omega hierarchical (\\(œâ_h\\)). The difference between them is that omega2 uses the model-implied variance of the total score, while omega3 relies on the observed variance from the sample.\nIn simple terms, both \\(œâ_h\\) values tell us that 91% of the variance in the PCS total score is explained by the general psychological cost factor, after accounting for the specific factors that influence different content areas.\n\n\n\nIn the bifactor model example, I treated the multidimensional nature of the PCS items as a distraction when measuring a broad, general psychological cost construct. However, in other cases, researchers may propose a different structure where a broad overarching factor indirectly influences all the test items by acting through more specific, narrower constructs that directly affect different subsets of items. This kind of setup suggests a higher-order model, where a higher-order (or second-order) factor drives differences in several lower-order (first-order) factors, which, in turn, influence the individual item responses.\nIn this model, researchers assess how well the test captures both the overall score (reflecting the broad higher-order construct) and the subscale scores (reflecting the more specific lower-order constructs).\nWhen the data fit a higher-order model, the reliability of the total score is measured by omega-higher-order (\\(œâ_{ho}\\)), which represents the proportion of the total score‚Äôs variance that can be attributed to the higher-order factor. The calculation of œâho uses parameter estimates from the higher-order model.\n\n#Specify the higher-order factor model for the PCS items\n\nhomod &lt;- 'TE =~ TE1 + TE2 + TE3 + TE4 + TE5 \n      OE =~ OE1 + OE2 + OE3 + OE4\n      LV =~ LVA1 + LVA2 + LVA3 + LVA4\n      EM =~ EM1 + EM2 + EM3 + EM4 + EM5 + EM6\n      cost =~ TE + OE + LV + EM'\n\n\n#Estimate the model and get the results\nfitHo &lt;- cfa(homod, data=pcs, std.lv=T, estimator='MLM')\nsummary(fitHo, fit.measures=T)\n\nlavaan 0.6-19 ended normally after 57 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        42\n\n                                                  Used       Total\n  Number of observations                           154         172\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               243.444     185.699\n  Degrees of freedom                               148         148\n  P-value (Chi-square)                           0.000       0.019\n  Scaling correction factor                                  1.311\n    Satorra-Bentler correction                                    \n\nModel Test Baseline Model:\n\n  Test statistic                              2799.877    2282.637\n  Degrees of freedom                               171         171\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.227\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.964       0.982\n  Tucker-Lewis Index (TLI)                       0.958       0.979\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.981\n  Robust Tucker-Lewis Index (TLI)                            0.978\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -3472.850   -3472.850\n  Loglikelihood unrestricted model (H1)      -3351.128   -3351.128\n                                                                  \n  Akaike (AIC)                                7029.700    7029.700\n  Bayesian (BIC)                              7157.252    7157.252\n  Sample-size adjusted Bayesian (SABIC)       7024.315    7024.315\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.065       0.041\n  90 Percent confidence interval - lower         0.050       0.021\n  90 Percent confidence interval - upper         0.079       0.056\n  P-value H_0: RMSEA &lt;= 0.050                    0.052       0.832\n  P-value H_0: RMSEA &gt;= 0.080                    0.039       0.000\n                                                                  \n  Robust RMSEA                                               0.047\n  90 Percent confidence interval - lower                     0.020\n  90 Percent confidence interval - upper                     0.066\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.592\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.002\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.045       0.045\n\nParameter Estimates:\n\n  Standard errors                           Robust.sem\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  TE =~                                               \n    TE1               0.356    0.067    5.289    0.000\n    TE2               0.364    0.065    5.554    0.000\n    TE3               0.299    0.059    5.056    0.000\n    TE4               0.323    0.058    5.605    0.000\n    TE5               0.338    0.065    5.198    0.000\n  OE =~                                               \n    OE1               0.641    0.074    8.642    0.000\n    OE2               0.616    0.060   10.334    0.000\n    OE3               0.630    0.066    9.523    0.000\n    OE4               0.647    0.064   10.078    0.000\n  LV =~                                               \n    LVA1              0.442    0.056    7.836    0.000\n    LVA2              0.457    0.059    7.751    0.000\n    LVA3              0.427    0.059    7.286    0.000\n    LVA4              0.460    0.056    8.258    0.000\n  EM =~                                               \n    EM1               0.509    0.069    7.394    0.000\n    EM2               0.462    0.066    7.018    0.000\n    EM3               0.517    0.074    6.955    0.000\n    EM4               0.483    0.067    7.179    0.000\n    EM5               0.535    0.069    7.756    0.000\n    EM6               0.595    0.080    7.430    0.000\n  cost =~                                             \n    TE                2.914    0.595    4.894    0.000\n    OE                1.223    0.155    7.880    0.000\n    LV                1.951    0.281    6.933    0.000\n    EM                1.900    0.327    5.809    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .TE1               0.321    0.063    5.081    0.000\n   .TE2               0.473    0.069    6.837    0.000\n   .TE3               0.531    0.100    5.289    0.000\n   .TE4               0.398    0.073    5.494    0.000\n   .TE5               0.418    0.070    5.935    0.000\n   .OE1               0.531    0.099    5.353    0.000\n   .OE2               0.440    0.081    5.428    0.000\n   .OE3               0.495    0.099    5.001    0.000\n   .OE4               0.315    0.055    5.719    0.000\n   .LVA1              0.443    0.081    5.466    0.000\n   .LVA2              0.170    0.035    4.851    0.000\n   .LVA3              0.412    0.064    6.473    0.000\n   .LVA4              0.533    0.090    5.945    0.000\n   .EM1               0.637    0.085    7.508    0.000\n   .EM2               0.367    0.062    5.872    0.000\n   .EM3               0.493    0.075    6.564    0.000\n   .EM4               0.387    0.064    6.017    0.000\n   .EM5               0.315    0.062    5.059    0.000\n   .EM6               0.554    0.085    6.515    0.000\n   .TE                1.000                           \n   .OE                1.000                           \n   .LV                1.000                           \n   .EM                1.000                           \n    cost              1.000                           \n\n\n\n\n\nreliabilityL2(fitHo, 'cost')\n\n       omegaL1        omegaL2 partialOmegaL1 \n     0.9088176      0.9410190      0.9734520 \n\n\n\n#Obtain omega estimates for the subscale scores as measures of the lower-order factors\nreliability(fitHo)\n\n              TE        OE        LV        EM\nalpha  0.9250420 0.8992820 0.9052459 0.9405882\nomega  0.9260209 0.9000548 0.9077522 0.9415490\nomega2 0.9260209 0.9000548 0.9077522 0.9415490\nomega3 0.9256773 0.9014397 0.9125259 0.9404921\navevar 0.7155347 0.6925123 0.7111716 0.7299181\n\n\n\n\n\n\n\nSo far, the examples have relied on semTools‚Äô reliability (or reliabilityL2) function to calculate omega estimates based on CFA models. However, these omega estimates are only valid if the underlying model for the test is correctly specified. For instance, using \\(œâ_u\\) as a reliability estimate wouldn‚Äôt be appropriate if the true model is multidimensional, as indicated by a poor fit for a single-factor model.\nWhen a hypothesized CFA model doesn‚Äôt adequately fit the data‚Äîwhich is common in the early stages of test development‚ÄîExploratory Factor Analysis (EFA) can help identify the test‚Äôs dimensional structure. After determining the optimal number of factors for a test, you can use the omega function from the psych package (Revelle, 2020) to estimate omega based on the EFA parameters. This estimate will reflect the proportion of total score variance attributable to a general factor that influences all items.\n\n#Determine number of factors\n\nn_factors(pcs, package = \"all\")\n\n# Method Agreement Procedure:\n\nThe choice of 4 dimensions is supported by 7 (25.93%) methods out of 27 (beta, Scree (SE), EGA (glasso), Velicer's MAP, BIC, Fit_off, BIC).\n\n\n\n#Determine omega for 4 factor model\nomega(pcs, nfactors = 4, plot = F)\n\nLoading required namespace: GPArotation\n\n\nOmega \nCall: omegah(m = m, nfactors = nfactors, fm = fm, key = key, flip = flip, \n    digits = digits, title = title, sl = sl, labels = labels, \n    plot = plot, n.obs = n.obs, rotate = rotate, Phi = Phi, option = option, \n    covar = covar)\nAlpha:                 0.96 \nG.6:                   0.98 \nOmega Hierarchical:    0.85 \nOmega H asymptotic:    0.88 \nOmega Total            0.98 \n\nSchmid Leiman Factor loadings greater than  0.2 \n        g   F1*   F2*   F3*   F4*   h2   h2   u2   p2  com\nTE1  0.81              0.39       0.81 0.81 0.19 0.80 1.50\nTE2  0.76              0.40       0.75 0.75 0.25 0.77 1.53\nTE3  0.70              0.35       0.62 0.62 0.38 0.80 1.52\nTE4  0.78              0.29       0.72 0.72 0.28 0.84 1.41\nTE5  0.77              0.34       0.74 0.74 0.26 0.80 1.46\nOE1  0.61        0.55             0.67 0.67 0.33 0.56 2.02\nOE2  0.67        0.46             0.66 0.66 0.34 0.68 1.81\nOE3  0.61        0.54             0.68 0.68 0.32 0.54 2.02\nOE4  0.63        0.62             0.80 0.80 0.20 0.50 2.02\nLVA1 0.75                    0.28 0.67 0.67 0.33 0.85 1.37\nLVA2 0.80                    0.48 0.87 0.87 0.13 0.73 1.66\nLVA3 0.71        0.20        0.37 0.71 0.71 0.29 0.72 1.69\nLVA4 0.70                    0.43 0.67 0.67 0.33 0.72 1.68\nEM1  0.69  0.39                   0.66 0.66 0.34 0.73 1.64\nEM2  0.76  0.38                   0.75 0.75 0.25 0.77 1.57\nEM3  0.72  0.47                   0.73 0.73 0.27 0.71 1.76\nEM4  0.72  0.48                   0.74 0.74 0.26 0.70 1.76\nEM5  0.78  0.43                   0.81 0.81 0.19 0.76 1.59\nEM6  0.73  0.48                   0.78 0.78 0.22 0.68 1.78\n\nWith Sums of squares  of:\n    g   F1*   F2*   F3*   F4*    h2 \n 9.95  1.21  1.29  0.70  0.68 10.16 \n\ngeneral/max  0.98   max/min =   14.84\nmean percent general =  0.72    with sd =  0.1 and cv of  0.13 \nExplained Common Variance of the general factor =  0.72 \n\nThe degrees of freedom are 101  and the fit is  1 \nThe number of observations was  172  with Chi Square =  161.11  with prob &lt;  0.00013\nThe root mean square of the residuals is  0.02 \nThe df corrected root mean square of the residuals is  0.03\nRMSEA index =  0.059  and the 10 % confidence intervals are  0.041 0.076\nBIC =  -358.79\n\nCompare this with the adequacy of just a general factor and no group factors\nThe degrees of freedom for just the general factor are 152  and the fit is  4.49 \nThe number of observations was  172  with Chi Square =  732.57  with prob &lt;  8.2e-77\nThe root mean square of the residuals is  0.1 \nThe df corrected root mean square of the residuals is  0.11 \n\nRMSEA index =  0.149  and the 10 % confidence intervals are  0.139 0.16\nBIC =  -49.85 \n\nMeasures of factor score adequacy             \n                                                 g  F1*  F2*  F3*  F4*\nCorrelation of scores with factors            0.93 0.79 0.86 0.72 0.77\nMultiple R square of scores with factors      0.86 0.63 0.73 0.52 0.59\nMinimum correlation of factor score estimates 0.73 0.26 0.47 0.04 0.18\n\n Total, General and Subset omega for each subset\n                                                 g  F1*  F2*  F3* F4*\nOmega total for total scores and subscales    0.98 0.94 0.90 0.92 0.9\nOmega general for total scores and subscales  0.85 0.69 0.52 0.76 0.7\nOmega group for total scores and subscales    0.08 0.25 0.38 0.16 0.2\n\n\nThe results from the exploratory factor analysis indicate that the four-factor model provides a strong fit, with an overall omega total of 0.98, suggesting excellent reliability for the total score. The omega hierarchical value of 0.85 indicates that 85% of the total-score variance is attributable to a general factor, showing that the general psychological cost factor plays a dominant role in explaining the variance across items. Additionally, the individual subscales also show good reliability, with their omega total values ranging from 0.90 to 0.94."
  },
  {
    "objectID": "index.html#quarto",
    "href": "index.html#quarto",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "index.html#running-code",
    "href": "index.html#running-code",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "index.html#introduction-to-reliability-index-analysis",
    "href": "index.html#introduction-to-reliability-index-analysis",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "This tutorial will serve as a Guide to Enhanced Reliability Estimation with R\n\n\nReliability refers to the consistency and precision of measurement instruments. In psychological testing, it assesses the extent to which a test produces stable and consistent results.\n\n\nMeasurement Precision: Ensures that the scores accurately reflect the true attributes being measured.\nResearch Validity: High reliability is a prerequisite for valid conclusions and replicable research findings.\nError Reduction: Minimizes the impact of random errors, enhancing the clarity of observed relationships between constructs.\n\n\n\nInternal Consistency: Degree to which items within a test measure the same construct.\nTest-Retest Reliability: Consistency of scores over time.\nInter-Rater Reliability: Agreement between different raters or observers."
  },
  {
    "objectID": "index.html#classical-test-theory-ctt-and-coefficient-alpha",
    "href": "index.html#classical-test-theory-ctt-and-coefficient-alpha",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "Classical Test Theory Overview: CTT posits that each observed score is composed of a true score and an error score:\n\\[ X = T + E \\]\nwhere:\nùëã= Observed score ùëá= True score ùê∏= Error score\n\n\nThis is a widely used measure of internal consistency reliability within CTT. It estimates the extent to which items on a test measure the same underlying construct.\n\\[\n\\alpha = \\frac{N}{N-1} \\left(1 - \\frac{\\sum \\sigma^2_{E}}{\\sigma^2_{X}}\\right)\n\\]\nWhere:\n\\(\\alpha\\) = Cronbach‚Äôs Alpha\nùëÅ = Number of items in the test\n\\(\\sigma^2_{E}\\) = Variance of the error scores\n\\(\\sigma^2_{X}\\) = Variance of the observed total scores\n\n\nUnidimensionality: All items measure a single construct.\nTau Equivalence: Each item has the same true score variance.\nIndependence of Errors: Error terms are uncorrelated across items.\n\n\n\nSensitivity to Tau Equivalence: Violations can lead to underestimation or overestimation of reliability.\nAssumes Unidimensionality: Not suitable for multidimensional scales without adjustments.\nIgnores Factor Structure: Does not account for the underlying factor model of the test.\n\n\n\n\nCoefficient Omega is a more robust alternative to Cronbach‚Äôs Alpha, especially when the assumption of tau-equivalence (equal factor loadings) is violated. Omega takes into account the factor structure of the test, making it suitable for both unidimensional and multidimensional scales.\n\n\nOmega Total (œâ‚Çú): Accounts for all common factors, both general and specific.\nOmega Hierarchical (œâ‚Çï): Represents the proportion of variance attributable to a general factor alone.\nOmega Total is given by:\n\\[\n\\omega_t = \\frac{\\sum_{i=1}^{k} \\lambda_i}{\\sum_{i=1}^{k} \\lambda_i + \\sum_{i=1}^{k} \\theta_i}\n\\]\nWhere:\n\\(\\omega_t\\) = Omega Total\n\\(\\lambda_i\\) = Factor loading for item\n\\(\\theta_i\\) = Unique variance (error variance) for item\n\\(k\\) = Total number of items\nFor a hierarchical model, Omega Hierarchical is:\n\\[\n\\omega_h = \\frac{\\lambda_g^2}{\\lambda_g^2 + \\sum_{i=1}^{k} \\theta_i}\n\\]\nwhere:\n\\(\\omega_h\\) = Omega Hierarchical\n\\(\\lambda_g\\) = Factor loading of the general factor\n\\(\\theta_i\\) = Unique variance for item \\(i\\)\n\n\n\nFactor Structure Incorporation: Utilizes confirmatory factor analysis (CFA) to model the underlying structure.\nLess Sensitive to Tau Equivalence Violations: Provides more accurate reliability estimates when tau equivalence is not met.\nApplicability to Multidimensional Scales: Suitable for tests measuring multiple constructs."
  },
  {
    "objectID": "index.html#calculations-in-r",
    "href": "index.html#calculations-in-r",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "Here, I will walk through the step-by-step process of calculating Cronbach‚Äôs Alpha and Coefficient Omega using R.\nLoad the necessary packages.\n\npacman::p_load(psych,lavaan,semTools,tidyverse,semTools,psych,tidyverse,lavaan,rio,parameters,\n               nFactors,EGAnet,PCDimension)"
  },
  {
    "objectID": "index.html#simulating-dataset",
    "href": "index.html#simulating-dataset",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "Let‚Äôs simulate a unidimensional dataset representing responses to a psychological test with 10 items. Each item is assumed to load on a single underlying factor (the construct being measured).\n\nset.seed(999) #for reproducibility\n\n# Number of participants\nn &lt;- 200\n\n# Number of items\nk &lt;- 10\n\n# Simulate factor loadings\nlambda &lt;- rep(0.7, k)  # Equal loadings for simplicity\n\n# Simulate latent trait scores (true scores)\nlatent_trait &lt;- rnorm(n, mean = 0, sd = 1)\n\n# Simulate item responses with measurement error\n# Assuming unique variance (theta) = 1 - lambda^2\ntheta &lt;- 1 - lambda^2\n\n# Generate item responses\nitem_responses &lt;- matrix(NA, nrow = n, ncol = k)\nfor(i in 1:k){\n  item_responses[,i] &lt;- lambda[i] * latent_trait + rnorm(n, mean = 0, sd = sqrt(theta[i]))\n}\n\n# Convert to data frame and name the items\ntest_data &lt;- as.data.frame(item_responses)\ncolnames(test_data) &lt;- paste0(\"Item\", 1:k)\n\n#print the first few rows\nhead(test_data)\n\n       Item1      Item2      Item3      Item4      Item5       Item6\n1 -1.2556963  0.1350372  0.3267107 -0.4350214 -0.2341561 -0.55481802\n2  0.1676193 -0.5108128 -2.0763683 -2.3273491  0.6263964 -1.18749601\n3  0.8438537  0.6766952  0.7511039  0.7876390 -0.2862397  0.72385660\n4  0.5239119  0.5615599 -0.5887199 -0.6589739  0.8637441  0.96640344\n5  0.4627802 -0.5181453 -0.5907776 -0.2237230  0.4472270  0.39956550\n6  0.1496605 -0.4830604 -0.4002617 -0.6658249 -1.7279389 -0.05426333\n        Item7      Item8      Item9      Item10\n1  0.12906041  0.8743370  0.8313717 -1.89803952\n2  0.03811422  0.3958650 -0.9320266 -1.19657498\n3  0.59847277  0.6243699  1.0944689 -0.34952191\n4  0.26035818  1.8831289  0.4292459 -1.18586145\n5  0.87674212  0.1055399 -0.9695509  0.04756092\n6 -0.58928130 -0.1575603 -1.7274886 -1.21579287\n\n\nAs you can see, we have created a dataset (test_data) with 200 participants and 10 items. Each item response is a combination of the latent trait (latent_trait) and random measurement error. The items are designed to load equally on the latent trait for simplicity."
  },
  {
    "objectID": "index.html#calculating-cronbachs-alpha",
    "href": "index.html#calculating-cronbachs-alpha",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "Recall that Cronbach‚Äôs Alpha (Œ±) is a measure of internal consistency that measures how closely related a set of items are as a group.\n\n\n\n# Calculate Cronbach's Alpha using the psych package\n#alpha_result &lt;- psych::alpha(oppeness)\n\n# Print the result\n#print(alpha_result)\n\nBecause some items were negatively correlated with the first principal component, we probably should reverse them.\n\n# Reversing item O2 and O5\n\nq &lt;- c(\"O2\",\"O5\")\nreverse &lt;- function(x){\n  x.reversed &lt;- 7 +0 - x\n}\n\noppeness[, c(\"O2R\", \"O5R\")] &lt;- reverse(oppeness[,c(\"O2\",\"O5\")])\n\n# compare original and reversed responses\noppeness[1:6,]\n\n  O1 O2 O3 O4 O5 O2R O5R\n1  3  6  3  4  3   1   4\n2  4  2  4  3  3   5   4\n3  4  2  5  5  2   5   5\n4  3  3  4  3  5   4   2\n5  3  3  4  3  3   4   4\n6  4  3  5  6  1   4   6\n\n\nNow, we can compute the alpha\n\n# compute alpha coefficient \n\nalpha_result &lt;- psych::alpha(oppeness[, -c(2,5)])\n\n# Print the result\nprint(alpha_result)\n\n\nReliability analysis   \nCall: psych::alpha(x = oppeness[, -c(2, 5)])\n\n  raw_alpha std.alpha G6(smc) average_r S/N   ase mean   sd median_r\n       0.6      0.61    0.57      0.24 1.6 0.012  4.6 0.81     0.23\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.58   0.6  0.63\nDuhachek  0.58   0.6  0.63\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nO1       0.54      0.54    0.48      0.23 1.2    0.014 0.0087  0.23\nO3       0.50      0.50    0.44      0.20 1.0    0.015 0.0065  0.20\nO4       0.61      0.62    0.56      0.29 1.7    0.012 0.0040  0.29\nO2R      0.57      0.57    0.51      0.25 1.3    0.014 0.0077  0.21\nO5R      0.52      0.53    0.48      0.22 1.1    0.015 0.0109  0.21\n\n Item statistics \n       n raw.r std.r r.cor r.drop mean  sd\nO1  2726  0.61  0.65  0.51   0.39  4.8 1.1\nO3  2726  0.68  0.69  0.59   0.45  4.4 1.2\nO4  2726  0.50  0.52  0.29   0.22  4.9 1.2\nO2R 2726  0.66  0.60  0.44   0.34  4.3 1.6\nO5R 2726  0.67  0.66  0.52   0.42  4.5 1.3\n\nNon missing response frequency for each item\n       1    2    3    4    5    6 miss\nO1  0.01 0.04 0.08 0.22 0.33 0.33    0\nO3  0.03 0.05 0.10 0.28 0.34 0.20    0\nO4  0.02 0.05 0.06 0.17 0.32 0.39    0\nO2R 0.06 0.10 0.15 0.14 0.26 0.29    0\nO5R 0.02 0.07 0.13 0.19 0.32 0.27    0\n\n\nExplanation:\nraw_alpha: The Cronbach‚Äôs Alpha coefficient.\nstd.alpha: Standardized alpha, similar to raw_alpha.\nG6(smc): Generalizability theory estimate with squared multiple correlations.\naverage_r: Average inter-item correlation.\nS/N: Signal-to-noise ratio.\nase: Asymptotic standard error.\nConfidence Intervals: Lower and upper bounds for alpha.\nAs we can see, the Cronbach‚Äôs Alpha for the Openness items is 0.6, indicating strong internal consistency. The average inter-item correlation is 0.24, moderate and within psychological scales."
  },
  {
    "objectID": "index.html#performing-confirmatory-factor-analysis-cfa",
    "href": "index.html#performing-confirmatory-factor-analysis-cfa",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "Confirmatory Factor Analysis (CFA) is used to verify the factor structure of a set of observed variables. In our case, we assume a unidimensional structure.\n\n\nLet‚Äôs specify a one-factor model where all items load on a single latent factor.\n\n# Define a one-factor CFA model\ncfa_model &lt;- '\n  Factor1 =~ Item1 + Item2 + Item3 + Item4 + Item5 + \n             Item6 + Item7 + Item8 + Item9 + Item10\n'\n\n\n\n\nFit the Model Using lavaan:\n\n# Fit the CFA model\nfit &lt;- lavaan::cfa(model = cfa_model, data = test_data)\n\n# Summarize the fit\nsummary(fit, fit.measures = TRUE, standardized = TRUE)\n\nLength  Class   Mode \n     1 lavaan     S4 \n\n\nExplanation:\nEstimator: Maximum Likelihood (ML).\nTest Statistics: The Chi-square test is significant (ùëù&lt;0.001), indicating a poor fit.\nFit Indices:\nCFI (0.89): Below the acceptable threshold of 0.90.\nTLI (0.87): Below the acceptable threshold of 0.90.\nRMSEA (0.10): Indicates poor fit (acceptable is &lt;0.08).\nSRMR (0.12): Above the acceptable threshold of 0.08.\nInterpretation:\nThe one-factor model does not fit the data well based on these fit indices. This suggests that our simulated data may be multidimensional or that the factor loadings are not as expected.\nNote: Because we simulated data with equal loadings and a unidimensional structure, the poor fit indicates potential issues with our simulation parameters. For now, we can proceed with calculations, but in real scenarios, you may need to modify your model or review your data."
  },
  {
    "objectID": "index.html#confirmatory-factor-analysis-cfa",
    "href": "index.html#confirmatory-factor-analysis-cfa",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "Confirmatory Factor Analysis (CFA) is used to verify the factor structure of a set of observed variables. In our case, we assume a unidimensional structure.\n\n\nLet‚Äôs specify a one-factor model where all items load on a single latent factor.\n\n# Specify model\nmod1f &lt;- \"\nopenness =~ O1 + O2R + O3 + O4 + O5R\n\"\n\n\n\n\nFit the Model Using lavaan:\n\n#pacman::p_load(lavaan)\n# Estimate model\nfit.one.f &lt;- cfa(mod1f, data=oppeness, std.lv=T, missing='direct', \n             estimator='MLR')\n\n# The results can be viewed using the summary\n\nsummary(fit.one.f, fit.measures=T, standardized=T)\n\nlavaan 0.6-19 ended normally after 22 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        15\n\n  Number of observations                          2726\n  Number of missing patterns                         1\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                80.583      67.248\n  Degrees of freedom                                 5           5\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  1.198\n    Yuan-Bentler correction (Mplus variant)                       \n\nModel Test Baseline Model:\n\n  Test statistic                              1375.389    1049.226\n  Degrees of freedom                                10          10\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.311\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.945       0.940\n  Tucker-Lewis Index (TLI)                       0.889       0.880\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.946\n  Robust Tucker-Lewis Index (TLI)                            0.891\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -22078.661  -22078.661\n  Scaling correction factor                                  1.167\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)     -22038.369  -22038.369\n  Scaling correction factor                                  1.174\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                               44187.322   44187.322\n  Bayesian (BIC)                             44275.980   44275.980\n  Sample-size adjusted Bayesian (SABIC)      44228.321   44228.321\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.074       0.068\n  90 Percent confidence interval - lower         0.061       0.055\n  90 Percent confidence interval - upper         0.089       0.081\n  P-value H_0: RMSEA &lt;= 0.050                    0.002       0.012\n  P-value H_0: RMSEA &gt;= 0.080                    0.280       0.066\n                                                                  \n  Robust RMSEA                                               0.074\n  90 Percent confidence interval - lower                     0.058\n  90 Percent confidence interval - upper                     0.090\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.006\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.285\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.029       0.029\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  openness =~                                                           \n    O1                0.616    0.029   21.346    0.000    0.616    0.546\n    O2R               0.701    0.041   17.170    0.000    0.701    0.449\n    O3                0.792    0.032   24.649    0.000    0.792    0.649\n    O4                0.357    0.030   11.749    0.000    0.357    0.294\n    O5R               0.685    0.036   19.194    0.000    0.685    0.517\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .O1                4.819    0.022  223.110    0.000    4.819    4.273\n   .O2R               4.300    0.030  143.782    0.000    4.300    2.754\n   .O3                4.439    0.023  189.916    0.000    4.439    3.637\n   .O4                4.898    0.023  210.231    0.000    4.898    4.027\n   .O5R               4.516    0.025  177.976    0.000    4.516    3.409\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .O1                0.893    0.037   23.923    0.000    0.893    0.702\n   .O2R               1.947    0.068   28.607    0.000    1.947    0.798\n   .O3                0.862    0.050   17.172    0.000    0.862    0.579\n   .O4                1.352    0.052   25.967    0.000    1.352    0.914\n   .O5R               1.286    0.059   21.822    0.000    1.286    0.732\n    openness          1.000                               1.000    1.000\n\n\nExplanation:\nEstimator: Maximum Likelihood (ML).\nTest Statistics: The Chi-square test is significant (ùëù&lt;0.001), indicating a poor fit.\nFit Indices:\nCFI (0.94): above 0.90.\nTLI (0.88): Below the threshold of 0.90.\nRMSEA (0.068): Indicates relatively weak fit (‚â•0.05).\nSRMR (0.029): Great fit (‚â§0.08).\n\nresiduals(fit.one.f, type='cor')\n\n$type\n[1] \"cor.bollen\"\n\n$cov\n        O1    O2R     O3     O4    O5R\nO1   0.000                            \nO2R -0.026  0.000                     \nO3   0.037 -0.024  0.000              \nO4   0.013 -0.052  0.000  0.000       \nO5R -0.044  0.090 -0.022  0.027  0.000\n\n$mean\n O1 O2R  O3  O4 O5R \n  0   0   0   0   0 \n\n\nThe fit statistics from the Robust column in the summary suggest that this one-factor model provides a moderate fit to the data. While the Comparative Fit Index (CFI) of 0.94 indicates an acceptable fit, the Tucker-Lewis Index (TLI) of 0.88 is relatively lower, and the Root Mean Square Error of Approximation (RMSEA) is relatively high at 0.08.\nThe factor loadings (ùúÜÃÇ) show significant variation, ranging from 0.357 to 0.792, which implies that the assumption of equal loadings (tau equivalence) does not hold for this openness test. As a result, omega (œâu) should be a more suitable measure of reliability than Cronbach‚Äôs alpha. We can compute the œâu estimate by running the reliability function from the semTools package on the one-factor model object (fit1f).\n\nreliability(fit.one.f)\n\n        openness\nalpha  0.6025464\nomega  0.6103741\nomega2 0.6103741\nomega3 0.6098642\navevar 0.2484010\n\n\nomega and omega2 measure reliability based on the variance expected by the model, while omega3 measures it based on the actual variance seen in your data. The small difference between omega and omega3 suggests that the model‚Äôs predictions of variance are somewhat close to what‚Äôs observed in the sample."
  },
  {
    "objectID": "index.html#calculating-coefficient-omega",
    "href": "index.html#calculating-coefficient-omega",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "Recall that Coefficient Omega (œâ) is a reliability estimate that accounts for the factor structure of the test, providing a more accurate measure than Cronbach‚Äôs Alpha, especially in the presence of multidimensionality or when tau-equivalence is violated.\n#Categorical omega\nI fitted the one-factor model to the interitem polychoric correlations using WLSMV, a robust weighted least squares estimator that is recommended over the ML estimator for CFA with polychoric correlations.\n\n# read in data\nlibrary(rio)\npotic &lt;- import(\"potic.csv\")\n\n# Specify model\nmod.one.fCat &lt;- 'psyctcsm =~ DDP1 + DDP2 +\nDDP3 + DDP4'\n\n\n# Estimate model\nfit.one.fCat &lt;- cfa(mod.one.fCat, data=potic, std.lv=TRUE, ordered=T, estimator='WLSMV')\n\n# Retrieving the results\nsummary(fit.one.fCat, fit.measures=TRUE, standardized=TRUE)\n\nlavaan 0.6-19 ended normally after 10 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        20\n\n                                                  Used       Total\n  Number of observations                           498         500\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                 7.117      14.910\n  Degrees of freedom                                 2           2\n  P-value (Chi-square)                           0.028       0.001\n  Scaling correction factor                                  0.480\n  Shift parameter                                            0.089\n    simple second-order correction                                \n\nModel Test Baseline Model:\n\n  Test statistic                              1635.647    1316.086\n  Degrees of freedom                                 6           6\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.244\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.997       0.990\n  Tucker-Lewis Index (TLI)                       0.991       0.970\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.969\n  Robust Tucker-Lewis Index (TLI)                            0.908\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.072       0.114\n  90 Percent confidence interval - lower         0.020       0.065\n  90 Percent confidence interval - upper         0.132       0.171\n  P-value H_0: RMSEA &lt;= 0.050                    0.200       0.019\n  P-value H_0: RMSEA &gt;= 0.080                    0.479       0.880\n                                                                  \n  Robust RMSEA                                               0.147\n  90 Percent confidence interval - lower                     0.089\n  90 Percent confidence interval - upper                     0.213\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.004\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.970\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.033       0.033\n\nParameter Estimates:\n\n  Parameterization                               Delta\n  Standard errors                           Robust.sem\n  Information                                 Expected\n  Information saturated (h1) model        Unstructured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  psyctcsm =~                                                           \n    DDP1              0.894    0.028   31.538    0.000    0.894    0.894\n    DDP2              0.753    0.028   26.711    0.000    0.753    0.753\n    DDP3              0.698    0.030   23.314    0.000    0.698    0.698\n    DDP4              0.513    0.040   12.738    0.000    0.513    0.513\n\nThresholds:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    DDP1|t1          -0.716    0.062  -11.591    0.000   -0.716   -0.716\n    DDP1|t2          -0.040    0.056   -0.716    0.474   -0.040   -0.040\n    DDP1|t3           0.296    0.057    5.185    0.000    0.296    0.296\n    DDP1|t4           1.034    0.069   15.065    0.000    1.034    1.034\n    DDP2|t1          -0.580    0.060   -9.693    0.000   -0.580   -0.580\n    DDP2|t2           0.208    0.057    3.668    0.000    0.208    0.208\n    DDP2|t3           0.562    0.060    9.431    0.000    0.562    0.562\n    DDP2|t4           1.096    0.070   15.570    0.000    1.096    1.096\n    DDP3|t1          -1.203    0.074  -16.298    0.000   -1.203   -1.203\n    DDP3|t2          -0.425    0.058   -7.318    0.000   -0.425   -0.425\n    DDP3|t3           0.081    0.056    1.432    0.152    0.081    0.081\n    DDP3|t4           0.913    0.066   13.909    0.000    0.913    0.913\n    DDP4|t1          -1.605    0.092  -17.382    0.000   -1.605   -1.605\n    DDP4|t2          -1.060    0.069  -15.285    0.000   -1.060   -1.060\n    DDP4|t3          -0.521    0.059   -8.817    0.000   -0.521   -0.521\n    DDP4|t4           0.431    0.058    7.406    0.000    0.431    0.431\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .DDP1              0.201                               0.201    0.201\n   .DDP2              0.433                               0.433    0.433\n   .DDP3              0.513                               0.513    0.513\n   .DDP4              0.737                               0.737    0.737\n    psyctcsm          1.000                               1.000    1.000"
  },
  {
    "objectID": "index.html#loading-the-bfi-dataset",
    "href": "index.html#loading-the-bfi-dataset",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "The Big Five Inventory (BFI) is a widely used dataset in personality psychology, measuring the five major dimensions of personality. We‚Äôll focus on the Openness trait for this tutorial.\n\n# Make sure you've loaded the psych package\n\n\n# Load the BFI dataset\ndata(bfi)\n\n# load data file\nbfi &lt;- bfi\nnames(bfi)\n\n [1] \"A1\"        \"A2\"        \"A3\"        \"A4\"        \"A5\"        \"C1\"       \n [7] \"C2\"        \"C3\"        \"C4\"        \"C5\"        \"E1\"        \"E2\"       \n[13] \"E3\"        \"E4\"        \"E5\"        \"N1\"        \"N2\"        \"N3\"       \n[19] \"N4\"        \"N5\"        \"O1\"        \"O2\"        \"O3\"        \"O4\"       \n[25] \"O5\"        \"gender\"    \"education\" \"age\"      \n\n# View the structure of the dataset\n#str(bfi)\n\nThe dataset contains 2,800 participants with various demographic and personality-related variables. A1 to A5 correspond to items measuring the Openness trait.\n\n\nFor this tutorial, we‚Äôll focus on five items measuring the Openness trait. These items are typically labeled as A1 to A5 in the BFI dataset.\n\n\n\n# Select columns that contain \"O\" in their names and remove rows with NA values\noppeness &lt;- bfi %&gt;%\n  select(matches(\"^O\")) %&gt;%\n  drop_na()\n\nhead(oppeness)\n\n  O1 O2 O3 O4 O5\n1  3  6  3  4  3\n2  4  2  4  3  3\n3  4  2  5  5  2\n4  3  3  4  3  5\n5  3  3  4  3  3\n6  4  3  5  6  1\n\n\nEach A variable represents a Likert-type item measuring Openness. Responses range from 1 to 6, treated as continuous variables for analysis.\n\n\n\n\nBefore we continue, let‚Äôs check any missing data.\n\n# Check for missing values\nsum(is.na(oppeness))\n\n[1] 0\n\n\nIn this dataset, there are no missing values in the Openness items. If missing values were present, then we need to address that."
  },
  {
    "objectID": "index.html#calculating-categorical-omega",
    "href": "index.html#calculating-categorical-omega",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "Recall that Coefficient Omega (œâ) is a reliability estimate that accounts for the factor structure of the test, providing a more accurate measure than Cronbach‚Äôs Alpha, especially in the presence of multidimensionality or when tau-equivalence is violated.\nSince factor loadings derived from polychoric correlations represent the link between the factor and the underlying latent response variables (not the actual responses from the items), using the œâu formula here would tell us how much of the variance in the latent response variables is explained by the factor. However, this doesn‚Äôt reflect the true variance in the sum of the observed item responses. Essentially, in this case, œâu would give us the reliability of a hypothetical total score based on the latent variables rather than the actual observed total score.\nTo correct for this, Green and Yang (2009b) proposed a new reliability estimate called œâu-cat, which adjusts the reliability calculation to align with the observed total score. This estimate is more accurate for unidimensional scales with categorical items, especially when the response patterns vary across items.\nSince the psychoticism items use a 4-point rating scale, I fit the one-factor model using polychoric correlations and the WLSMV estimator (weighted least squares with mean and variance adjustment). This approach is recommended for confirmatory factor analysis involving polychoric correlations, as it is more robust than the maximum likelihood (ML) estimator.\n\n#load the data\npotic &lt;- import(\"data/potic.csv\")\n\n# Specify model\nmod.one.fCat &lt;- 'psyctcsm =~ DDP1 + DDP2 +\nDDP3 + DDP4'\n\n\n# Estimate model\nfit.one.fCat &lt;- cfa(mod.one.fCat, data=potic, std.lv=TRUE, ordered=T, estimator='WLSMV')\n\n# Retrieving the results\nsummary(fit.one.fCat, fit.measures=TRUE, standardized=TRUE)\n\nlavaan 0.6-19 ended normally after 10 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        20\n\n                                                  Used       Total\n  Number of observations                           498         500\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                 7.117      14.910\n  Degrees of freedom                                 2           2\n  P-value (Chi-square)                           0.028       0.001\n  Scaling correction factor                                  0.480\n  Shift parameter                                            0.089\n    simple second-order correction                                \n\nModel Test Baseline Model:\n\n  Test statistic                              1635.647    1316.086\n  Degrees of freedom                                 6           6\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.244\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.997       0.990\n  Tucker-Lewis Index (TLI)                       0.991       0.970\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.969\n  Robust Tucker-Lewis Index (TLI)                            0.908\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.072       0.114\n  90 Percent confidence interval - lower         0.020       0.065\n  90 Percent confidence interval - upper         0.132       0.171\n  P-value H_0: RMSEA &lt;= 0.050                    0.200       0.019\n  P-value H_0: RMSEA &gt;= 0.080                    0.479       0.880\n                                                                  \n  Robust RMSEA                                               0.147\n  90 Percent confidence interval - lower                     0.089\n  90 Percent confidence interval - upper                     0.213\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.004\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.970\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.033       0.033\n\nParameter Estimates:\n\n  Parameterization                               Delta\n  Standard errors                           Robust.sem\n  Information                                 Expected\n  Information saturated (h1) model        Unstructured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  psyctcsm =~                                                           \n    DDP1              0.894    0.028   31.538    0.000    0.894    0.894\n    DDP2              0.753    0.028   26.711    0.000    0.753    0.753\n    DDP3              0.698    0.030   23.314    0.000    0.698    0.698\n    DDP4              0.513    0.040   12.738    0.000    0.513    0.513\n\nThresholds:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    DDP1|t1          -0.716    0.062  -11.591    0.000   -0.716   -0.716\n    DDP1|t2          -0.040    0.056   -0.716    0.474   -0.040   -0.040\n    DDP1|t3           0.296    0.057    5.185    0.000    0.296    0.296\n    DDP1|t4           1.034    0.069   15.065    0.000    1.034    1.034\n    DDP2|t1          -0.580    0.060   -9.693    0.000   -0.580   -0.580\n    DDP2|t2           0.208    0.057    3.668    0.000    0.208    0.208\n    DDP2|t3           0.562    0.060    9.431    0.000    0.562    0.562\n    DDP2|t4           1.096    0.070   15.570    0.000    1.096    1.096\n    DDP3|t1          -1.203    0.074  -16.298    0.000   -1.203   -1.203\n    DDP3|t2          -0.425    0.058   -7.318    0.000   -0.425   -0.425\n    DDP3|t3           0.081    0.056    1.432    0.152    0.081    0.081\n    DDP3|t4           0.913    0.066   13.909    0.000    0.913    0.913\n    DDP4|t1          -1.605    0.092  -17.382    0.000   -1.605   -1.605\n    DDP4|t2          -1.060    0.069  -15.285    0.000   -1.060   -1.060\n    DDP4|t3          -0.521    0.059   -8.817    0.000   -0.521   -0.521\n    DDP4|t4           0.431    0.058    7.406    0.000    0.431    0.431\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .DDP1              0.201                               0.201    0.201\n   .DDP2              0.433                               0.433    0.433\n   .DDP3              0.513                               0.513    0.513\n   .DDP4              0.737                               0.737    0.737\n    psyctcsm          1.000                               1.000    1.000\n\n\n\n# Estimate reliability\n\nreliability(fit.one.fCat)\n\nFor constructs with categorical indicators, Zumbo et al.`s (2007) \"ordinal alpha\" is calculated in addition to the standard alpha, which treats ordinal variables as numeric. See Chalmers (2018) for a critique of \"alpha.ord\" and the response by Zumbo & Kroc (2019). Likewise, average variance extracted is calculated from polychoric (polyserial) not Pearson correlations.\n\n\n           psyctcsm\nalpha     0.7680870\nalpha.ord 0.8007496\nomega     0.7902953\nomega2    0.7902953\nomega3    0.7932682\navevar    0.5289638\n\n\nWe can see that we have two estimates Cronbach‚Äôs alpha and differ a bit (0.80 & 0.77). The is because the 2nd alpha estimate is an example of ordinal alpha, which is calculated using a model based on polychoric correlations, while the first alpha was derived using the standard method based on product-moment covariances between the items. It‚Äôs important to note that ordinal alpha measures the reliability of the sum of the continuous, latent-response variables rather than the observed categorical item responses. Additionally, it still assumes equal factor loadings (tau equivalence). Because of these limitations, I suggest disregarding the alpha value reported by semTools::reliability when the model uses polychoric correlations.\nThe values shown in the omega and omega2 rows represent the œâu-cat estimate. The omega3 row shows a variation where the denominator uses the observed sample variance of ( X ). So, we can see œâu-cat estimates suggest that 79% of the variance in the total score for the psychoticism scale is explained by the single psychoticism factor."
  },
  {
    "objectID": "index.html#bifactor-models",
    "href": "index.html#bifactor-models",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "A bifactor model is a useful way to represent a multidimensional structure. In this model, there‚Äôs a general factor that affects all items, while additional specific factors (or group factors) explain the relationships (covariation) between certain subsets of items beyond what the general factor accounts for.\nFor the model to work correctly, the general factor needs to be uncorrelated with the specific factors. In contrast to other Confirmatory Factor Analysis (CFA) models where all factors can correlate freely, allowing the general factor to correlate with a specific factor in a bifactor model can lead to issues like non-convergence or incorrect solutions.\n\n\nWhen data fits well with a bifactor model, a reliability metric called omega hierarchical (\\(œâ_h\\)) is used. This measure reflects how much of the total score‚Äôs variance is attributable to the single general factor, even though the data involves multiple dimensions.\nHere, let‚Äôs demonstrate the estimation of \\(œâ_h\\) using R, I use data that from Flake, Ferland, & Flora, 2017 collected by administering the PCS to 154 students in an introductory statistics course.\n\npcs &lt;- import(\"data/pcs.csv\")\nnames(pcs)\n\n [1] \"TE1\"  \"TE2\"  \"TE3\"  \"TE4\"  \"TE5\"  \"OE1\"  \"OE2\"  \"OE3\"  \"OE4\"  \"LVA1\"\n[11] \"LVA2\" \"LVA3\" \"LVA4\" \"EM1\"  \"EM2\"  \"EM3\"  \"EM4\"  \"EM5\"  \"EM6\" \n\n\n\nmodBf &lt;- \"\ngen =~ TE1+TE2+TE3+TE4+TE5+OE1+OE2+OE3+OE4+LVA1+LVA2+LVA3+LVA4 +EM1+EM2+EM3+EM4+EM5+EM6\ns1 =~ TE1 + TE2 + TE3 + TE4 + TE5\ns2 =~ OE1 + OE2 + OE3 + OE4\ns3 =~ LVA1 + LVA2 + LVA3 + LVA4\ns4 =~ EM1 + EM2 + EM3 + EM4 + EM5 + EM6\n\"\n\n#Specify model\nfitBf &lt;- cfa(modBf, data=pcs, std.lv=T, estimator='MLR', orthogonal=T)\n\n#Retrieving the results\nsummary(fitBf, fit.measures=TRUE, standardized=T)\n\nlavaan 0.6-19 ended normally after 36 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        57\n\n                                                  Used       Total\n  Number of observations                           154         172\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               211.382     182.509\n  Degrees of freedom                               133         133\n  P-value (Chi-square)                           0.000       0.003\n  Scaling correction factor                                  1.158\n    Yuan-Bentler correction (Mplus variant)                       \n\nModel Test Baseline Model:\n\n  Test statistic                              2799.877    2260.239\n  Degrees of freedom                               171         171\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.239\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.970       0.976\n  Tucker-Lewis Index (TLI)                       0.962       0.970\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.978\n  Robust Tucker-Lewis Index (TLI)                            0.972\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -3456.819   -3456.819\n  Scaling correction factor                                  1.269\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)      -3351.128   -3351.128\n  Scaling correction factor                                  1.191\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                                7027.638    7027.638\n  Bayesian (BIC)                              7200.744    7200.744\n  Sample-size adjusted Bayesian (SABIC)       7020.331    7020.331\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.062       0.049\n  90 Percent confidence interval - lower         0.046       0.031\n  90 Percent confidence interval - upper         0.077       0.065\n  P-value H_0: RMSEA &lt;= 0.050                    0.108       0.520\n  P-value H_0: RMSEA &gt;= 0.080                    0.025       0.000\n                                                                  \n  Robust RMSEA                                               0.053\n  90 Percent confidence interval - lower                     0.032\n  90 Percent confidence interval - upper                     0.071\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.387\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.005\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.038       0.038\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  gen =~                                                                \n    TE1               1.041    0.071   14.715    0.000    1.041    0.843\n    TE2               1.045    0.084   12.430    0.000    1.045    0.794\n    TE3               0.848    0.090    9.392    0.000    0.848    0.721\n    TE4               0.984    0.075   13.097    0.000    0.984    0.834\n    TE5               1.004    0.082   12.264    0.000    1.004    0.819\n    OE1               0.787    0.083    9.537    0.000    0.787    0.631\n    OE2               0.819    0.080   10.207    0.000    0.819    0.695\n    OE3               0.738    0.089    8.319    0.000    0.738    0.605\n    OE4               0.742    0.087    8.512    0.000    0.742    0.636\n    LVA1              0.937    0.084   11.180    0.000    0.937    0.796\n    LVA2              0.863    0.071   12.205    0.000    0.863    0.797\n    LVA3              0.816    0.085    9.649    0.000    0.816    0.719\n    LVA4              0.865    0.098    8.802    0.000    0.865    0.695\n    EM1               0.968    0.095   10.215    0.000    0.968    0.715\n    EM2               0.930    0.078   11.957    0.000    0.930    0.800\n    EM3               0.959    0.091   10.542    0.000    0.959    0.731\n    EM4               0.885    0.091    9.679    0.000    0.885    0.732\n    EM5               1.043    0.086   12.121    0.000    1.043    0.816\n    EM6               1.108    0.100   11.054    0.000    1.108    0.750\n  s1 =~                                                                 \n    TE1               0.351    0.114    3.071    0.002    0.351    0.285\n    TE2               0.451    0.144    3.142    0.002    0.451    0.343\n    TE3               0.402    0.170    2.360    0.018    0.402    0.342\n    TE4               0.162    0.111    1.457    0.145    0.162    0.137\n    TE5               0.269    0.154    1.747    0.081    0.269    0.219\n  s2 =~                                                                 \n    OE1               0.626    0.107    5.860    0.000    0.626    0.502\n    OE2               0.516    0.096    5.399    0.000    0.516    0.438\n    OE3               0.673    0.107    6.291    0.000    0.673    0.552\n    OE4               0.739    0.085    8.738    0.000    0.739    0.634\n  s3 =~                                                                 \n    LVA1              0.253    0.107    2.357    0.018    0.253    0.215\n    LVA2              0.573    0.081    7.081    0.000    0.573    0.529\n    LVA3              0.422    0.104    4.051    0.000    0.422    0.372\n    LVA4              0.528    0.104    5.074    0.000    0.528    0.424\n  s4 =~                                                                 \n    EM1               0.506    0.152    3.324    0.001    0.506    0.374\n    EM2               0.346    0.086    4.026    0.000    0.346    0.298\n    EM3               0.567    0.121    4.682    0.000    0.567    0.432\n    EM4               0.562    0.098    5.707    0.000    0.562    0.464\n    EM5               0.479    0.097    4.930    0.000    0.479    0.375\n    EM6               0.651    0.148    4.403    0.000    0.651    0.440\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  gen ~~                                                                \n    s1                0.000                               0.000    0.000\n    s2                0.000                               0.000    0.000\n    s3                0.000                               0.000    0.000\n    s4                0.000                               0.000    0.000\n  s1 ~~                                                                 \n    s2                0.000                               0.000    0.000\n    s3                0.000                               0.000    0.000\n    s4                0.000                               0.000    0.000\n  s2 ~~                                                                 \n    s3                0.000                               0.000    0.000\n    s4                0.000                               0.000    0.000\n  s3 ~~                                                                 \n    s4                0.000                               0.000    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .TE1               0.318    0.067    4.777    0.000    0.318    0.209\n   .TE2               0.434    0.088    4.913    0.000    0.434    0.251\n   .TE3               0.501    0.104    4.827    0.000    0.501    0.363\n   .TE4               0.397    0.066    5.987    0.000    0.397    0.285\n   .TE5               0.421    0.073    5.799    0.000    0.421    0.281\n   .OE1               0.546    0.106    5.129    0.000    0.546    0.350\n   .OE2               0.451    0.075    6.003    0.000    0.451    0.325\n   .OE3               0.490    0.117    4.183    0.000    0.490    0.330\n   .OE4               0.263    0.071    3.718    0.000    0.263    0.194\n   .LVA1              0.442    0.064    6.873    0.000    0.442    0.320\n   .LVA2              0.100    0.062    1.607    0.108    0.100    0.085\n   .LVA3              0.443    0.075    5.892    0.000    0.443    0.344\n   .LVA4              0.523    0.088    5.954    0.000    0.523    0.337\n   .EM1               0.639    0.100    6.388    0.000    0.639    0.349\n   .EM2               0.365    0.060    6.049    0.000    0.365    0.271\n   .EM3               0.482    0.090    5.383    0.000    0.482    0.280\n   .EM4               0.364    0.083    4.395    0.000    0.364    0.249\n   .EM5               0.318    0.063    5.032    0.000    0.318    0.195\n   .EM6               0.534    0.117    4.564    0.000    0.534    0.244\n    gen               1.000                               1.000    1.000\n    s1                1.000                               1.000    1.000\n    s2                1.000                               1.000    1.000\n    s3                1.000                               1.000    1.000\n    s4                1.000                               1.000    1.000\n\n\n\nfitmeasures(fitBf)\n\n                         npar                          fmin \n                       57.000                         0.686 \n                        chisq                            df \n                      211.382                       133.000 \n                       pvalue                  chisq.scaled \n                        0.000                       182.509 \n                    df.scaled                 pvalue.scaled \n                      133.000                         0.003 \n         chisq.scaling.factor                baseline.chisq \n                        1.158                      2799.877 \n                  baseline.df               baseline.pvalue \n                      171.000                         0.000 \n        baseline.chisq.scaled            baseline.df.scaled \n                     2260.239                       171.000 \n       baseline.pvalue.scaled baseline.chisq.scaling.factor \n                        0.000                         1.239 \n                          cfi                           tli \n                        0.970                         0.962 \n                   cfi.scaled                    tli.scaled \n                        0.976                         0.970 \n                   cfi.robust                    tli.robust \n                        0.978                         0.972 \n                         nnfi                           rfi \n                        0.962                         0.903 \n                          nfi                          pnfi \n                        0.925                         0.719 \n                          ifi                           rni \n                        0.971                         0.970 \n                  nnfi.scaled                    rfi.scaled \n                        0.970                         0.896 \n                   nfi.scaled                   pnfi.scaled \n                        0.919                         0.715 \n                   ifi.scaled                    rni.scaled \n                        0.977                         0.976 \n                  nnfi.robust                    rni.robust \n                        0.972                         0.978 \n                         logl             unrestricted.logl \n                    -3456.819                     -3351.128 \n                          aic                           bic \n                     7027.638                      7200.744 \n                       ntotal                          bic2 \n                      154.000                      7020.331 \n            scaling.factor.h1             scaling.factor.h0 \n                        1.191                         1.269 \n                        rmsea                rmsea.ci.lower \n                        0.062                         0.046 \n               rmsea.ci.upper                rmsea.ci.level \n                        0.077                         0.900 \n                 rmsea.pvalue                rmsea.close.h0 \n                        0.108                         0.050 \n        rmsea.notclose.pvalue             rmsea.notclose.h0 \n                        0.025                         0.080 \n                 rmsea.scaled         rmsea.ci.lower.scaled \n                        0.049                         0.031 \n        rmsea.ci.upper.scaled           rmsea.pvalue.scaled \n                        0.065                         0.520 \n rmsea.notclose.pvalue.scaled                  rmsea.robust \n                        0.000                         0.053 \n        rmsea.ci.lower.robust         rmsea.ci.upper.robust \n                        0.032                         0.071 \n          rmsea.pvalue.robust  rmsea.notclose.pvalue.robust \n                        0.387                         0.005 \n                          rmr                    rmr_nomean \n                        0.056                         0.056 \n                         srmr                  srmr_bentler \n                        0.038                         0.038 \n          srmr_bentler_nomean                          crmr \n                        0.038                         0.040 \n                  crmr_nomean                    srmr_mplus \n                        0.040                         0.038 \n            srmr_mplus_nomean                         cn_05 \n                        0.038                       118.233 \n                        cn_01                           gfi \n                      127.659                         0.877 \n                         agfi                          pgfi \n                        0.824                         0.614 \n                          mfi                          ecvi \n                        0.775                         2.113 \n\n\nFrom the results above, we can the bifactor model fits the PCS data well, with robust model-fit statistics, CFI = 0.978, TLI = 0.972, RMSEA = 0.053. Thus, it is reasonable to calculate \\(œâ_h\\) to estimate how reliably the PCS total score measures the general psychological-cost factor.\n\nreliability(fitBf)\n\n             gen         s1        s2        s3        s4\nalpha  0.9638781 0.92504205 0.8992820 0.9052459 0.9405882\nomega  0.9741033 0.56377307 0.7884791 0.6766430 0.7816839\nomega2 0.9094893 0.09237594 0.3666293 0.1880759 0.2054075\nomega3 0.9077636 0.09240479 0.3666634 0.1878380 0.2053012\navevar        NA         NA        NA        NA        NA\n\n\nThe values shown under the ‚Äúgen‚Äù column relate to the general psychological cost factor. The omega estimate (0.974) doesn‚Äôt take the specific factors into account when calculating the variance of the total score, so it‚Äôs not the appropriate reliability measure for the PCS total score. Instead, the omega2 and omega3 values under ‚Äúgen‚Äù represent omega hierarchical (\\(œâ_h\\)). The difference between them is that omega2 uses the model-implied variance of the total score, while omega3 relies on the observed variance from the sample.\nIn simple terms, both \\(œâ_h\\) values tell us that 91% of the variance in the PCS total score is explained by the general psychological cost factor, after accounting for the specific factors that influence different content areas.\n\n\n\nIn the bifactor model example, I treated the multidimensional nature of the PCS items as a distraction when measuring a broad, general psychological cost construct. However, in other cases, researchers may propose a different structure where a broad overarching factor indirectly influences all the test items by acting through more specific, narrower constructs that directly affect different subsets of items. This kind of setup suggests a higher-order model, where a higher-order (or second-order) factor drives differences in several lower-order (first-order) factors, which, in turn, influence the individual item responses.\nIn this model, researchers assess how well the test captures both the overall score (reflecting the broad higher-order construct) and the subscale scores (reflecting the more specific lower-order constructs).\nWhen the data fit a higher-order model, the reliability of the total score is measured by omega-higher-order (\\(œâ_{ho}\\)), which represents the proportion of the total score‚Äôs variance that can be attributed to the higher-order factor. The calculation of œâho uses parameter estimates from the higher-order model.\n\n#Specify the higher-order factor model for the PCS items\n\nhomod &lt;- 'TE =~ TE1 + TE2 + TE3 + TE4 + TE5 \n      OE =~ OE1 + OE2 + OE3 + OE4\n      LV =~ LVA1 + LVA2 + LVA3 + LVA4\n      EM =~ EM1 + EM2 + EM3 + EM4 + EM5 + EM6\n      cost =~ TE + OE + LV + EM'\n\n\n#Estimate the model and get the results\nfitHo &lt;- cfa(homod, data=pcs, std.lv=T, estimator='MLM')\nsummary(fitHo, fit.measures=T)\n\nlavaan 0.6-19 ended normally after 57 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        42\n\n                                                  Used       Total\n  Number of observations                           154         172\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               243.444     185.699\n  Degrees of freedom                               148         148\n  P-value (Chi-square)                           0.000       0.019\n  Scaling correction factor                                  1.311\n    Satorra-Bentler correction                                    \n\nModel Test Baseline Model:\n\n  Test statistic                              2799.877    2282.637\n  Degrees of freedom                               171         171\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.227\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.964       0.982\n  Tucker-Lewis Index (TLI)                       0.958       0.979\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.981\n  Robust Tucker-Lewis Index (TLI)                            0.978\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -3472.850   -3472.850\n  Loglikelihood unrestricted model (H1)      -3351.128   -3351.128\n                                                                  \n  Akaike (AIC)                                7029.700    7029.700\n  Bayesian (BIC)                              7157.252    7157.252\n  Sample-size adjusted Bayesian (SABIC)       7024.315    7024.315\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.065       0.041\n  90 Percent confidence interval - lower         0.050       0.021\n  90 Percent confidence interval - upper         0.079       0.056\n  P-value H_0: RMSEA &lt;= 0.050                    0.052       0.832\n  P-value H_0: RMSEA &gt;= 0.080                    0.039       0.000\n                                                                  \n  Robust RMSEA                                               0.047\n  90 Percent confidence interval - lower                     0.020\n  90 Percent confidence interval - upper                     0.066\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.592\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.002\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.045       0.045\n\nParameter Estimates:\n\n  Standard errors                           Robust.sem\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  TE =~                                               \n    TE1               0.356    0.067    5.289    0.000\n    TE2               0.364    0.065    5.554    0.000\n    TE3               0.299    0.059    5.056    0.000\n    TE4               0.323    0.058    5.605    0.000\n    TE5               0.338    0.065    5.198    0.000\n  OE =~                                               \n    OE1               0.641    0.074    8.642    0.000\n    OE2               0.616    0.060   10.334    0.000\n    OE3               0.630    0.066    9.523    0.000\n    OE4               0.647    0.064   10.078    0.000\n  LV =~                                               \n    LVA1              0.442    0.056    7.836    0.000\n    LVA2              0.457    0.059    7.751    0.000\n    LVA3              0.427    0.059    7.286    0.000\n    LVA4              0.460    0.056    8.258    0.000\n  EM =~                                               \n    EM1               0.509    0.069    7.394    0.000\n    EM2               0.462    0.066    7.018    0.000\n    EM3               0.517    0.074    6.955    0.000\n    EM4               0.483    0.067    7.179    0.000\n    EM5               0.535    0.069    7.756    0.000\n    EM6               0.595    0.080    7.430    0.000\n  cost =~                                             \n    TE                2.914    0.595    4.894    0.000\n    OE                1.223    0.155    7.880    0.000\n    LV                1.951    0.281    6.933    0.000\n    EM                1.900    0.327    5.809    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .TE1               0.321    0.063    5.081    0.000\n   .TE2               0.473    0.069    6.837    0.000\n   .TE3               0.531    0.100    5.289    0.000\n   .TE4               0.398    0.073    5.494    0.000\n   .TE5               0.418    0.070    5.935    0.000\n   .OE1               0.531    0.099    5.353    0.000\n   .OE2               0.440    0.081    5.428    0.000\n   .OE3               0.495    0.099    5.001    0.000\n   .OE4               0.315    0.055    5.719    0.000\n   .LVA1              0.443    0.081    5.466    0.000\n   .LVA2              0.170    0.035    4.851    0.000\n   .LVA3              0.412    0.064    6.473    0.000\n   .LVA4              0.533    0.090    5.945    0.000\n   .EM1               0.637    0.085    7.508    0.000\n   .EM2               0.367    0.062    5.872    0.000\n   .EM3               0.493    0.075    6.564    0.000\n   .EM4               0.387    0.064    6.017    0.000\n   .EM5               0.315    0.062    5.059    0.000\n   .EM6               0.554    0.085    6.515    0.000\n   .TE                1.000                           \n   .OE                1.000                           \n   .LV                1.000                           \n   .EM                1.000                           \n    cost              1.000                           \n\n\n\n\n\nreliabilityL2(fitHo, 'cost')\n\n       omegaL1        omegaL2 partialOmegaL1 \n     0.9088176      0.9410190      0.9734520 \n\n\n\n#Obtain omega estimates for the subscale scores as measures of the lower-order factors\nreliability(fitHo)\n\n              TE        OE        LV        EM\nalpha  0.9250420 0.8992820 0.9052459 0.9405882\nomega  0.9260209 0.9000548 0.9077522 0.9415490\nomega2 0.9260209 0.9000548 0.9077522 0.9415490\nomega3 0.9256773 0.9014397 0.9125259 0.9404921\navevar 0.7155347 0.6925123 0.7111716 0.7299181"
  },
  {
    "objectID": "index.html#exploratory-omega-estimates",
    "href": "index.html#exploratory-omega-estimates",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "So far, the examples have relied on semTools‚Äô reliability (or reliabilityL2) function to calculate omega estimates based on CFA models. However, these omega estimates are only valid if the underlying model for the test is correctly specified. For instance, using \\(œâ_u\\) as a reliability estimate wouldn‚Äôt be appropriate if the true model is multidimensional, as indicated by a poor fit for a single-factor model.\nWhen a hypothesized CFA model doesn‚Äôt adequately fit the data‚Äîwhich is common in the early stages of test development‚ÄîExploratory Factor Analysis (EFA) can help identify the test‚Äôs dimensional structure. After determining the optimal number of factors for a test, you can use the omega function from the psych package (Revelle, 2020) to estimate omega based on the EFA parameters. This estimate will reflect the proportion of total score variance attributable to a general factor that influences all items.\n\n#Determine number of factors\n\nn_factors(pcs, package = \"all\")\n\n# Method Agreement Procedure:\n\nThe choice of 4 dimensions is supported by 7 (25.93%) methods out of 27 (beta, Scree (SE), EGA (glasso), Velicer's MAP, BIC, Fit_off, BIC).\n\n\n\n#Determine omega for 4 factor model\nomega(pcs, nfactors = 4, plot = F)\n\nLoading required namespace: GPArotation\n\n\nOmega \nCall: omegah(m = m, nfactors = nfactors, fm = fm, key = key, flip = flip, \n    digits = digits, title = title, sl = sl, labels = labels, \n    plot = plot, n.obs = n.obs, rotate = rotate, Phi = Phi, option = option, \n    covar = covar)\nAlpha:                 0.96 \nG.6:                   0.98 \nOmega Hierarchical:    0.85 \nOmega H asymptotic:    0.88 \nOmega Total            0.98 \n\nSchmid Leiman Factor loadings greater than  0.2 \n        g   F1*   F2*   F3*   F4*   h2   h2   u2   p2  com\nTE1  0.81              0.39       0.81 0.81 0.19 0.80 1.50\nTE2  0.76              0.40       0.75 0.75 0.25 0.77 1.53\nTE3  0.70              0.35       0.62 0.62 0.38 0.80 1.52\nTE4  0.78              0.29       0.72 0.72 0.28 0.84 1.41\nTE5  0.77              0.34       0.74 0.74 0.26 0.80 1.46\nOE1  0.61        0.55             0.67 0.67 0.33 0.56 2.02\nOE2  0.67        0.46             0.66 0.66 0.34 0.68 1.81\nOE3  0.61        0.54             0.68 0.68 0.32 0.54 2.02\nOE4  0.63        0.62             0.80 0.80 0.20 0.50 2.02\nLVA1 0.75                    0.28 0.67 0.67 0.33 0.85 1.37\nLVA2 0.80                    0.48 0.87 0.87 0.13 0.73 1.66\nLVA3 0.71        0.20        0.37 0.71 0.71 0.29 0.72 1.69\nLVA4 0.70                    0.43 0.67 0.67 0.33 0.72 1.68\nEM1  0.69  0.39                   0.66 0.66 0.34 0.73 1.64\nEM2  0.76  0.38                   0.75 0.75 0.25 0.77 1.57\nEM3  0.72  0.47                   0.73 0.73 0.27 0.71 1.76\nEM4  0.72  0.48                   0.74 0.74 0.26 0.70 1.76\nEM5  0.78  0.43                   0.81 0.81 0.19 0.76 1.59\nEM6  0.73  0.48                   0.78 0.78 0.22 0.68 1.78\n\nWith Sums of squares  of:\n    g   F1*   F2*   F3*   F4*    h2 \n 9.95  1.21  1.29  0.70  0.68 10.16 \n\ngeneral/max  0.98   max/min =   14.84\nmean percent general =  0.72    with sd =  0.1 and cv of  0.13 \nExplained Common Variance of the general factor =  0.72 \n\nThe degrees of freedom are 101  and the fit is  1 \nThe number of observations was  172  with Chi Square =  161.11  with prob &lt;  0.00013\nThe root mean square of the residuals is  0.02 \nThe df corrected root mean square of the residuals is  0.03\nRMSEA index =  0.059  and the 10 % confidence intervals are  0.041 0.076\nBIC =  -358.79\n\nCompare this with the adequacy of just a general factor and no group factors\nThe degrees of freedom for just the general factor are 152  and the fit is  4.49 \nThe number of observations was  172  with Chi Square =  732.57  with prob &lt;  8.2e-77\nThe root mean square of the residuals is  0.1 \nThe df corrected root mean square of the residuals is  0.11 \n\nRMSEA index =  0.149  and the 10 % confidence intervals are  0.139 0.16\nBIC =  -49.85 \n\nMeasures of factor score adequacy             \n                                                 g  F1*  F2*  F3*  F4*\nCorrelation of scores with factors            0.93 0.79 0.86 0.72 0.77\nMultiple R square of scores with factors      0.86 0.63 0.73 0.52 0.59\nMinimum correlation of factor score estimates 0.73 0.26 0.47 0.04 0.18\n\n Total, General and Subset omega for each subset\n                                                 g  F1*  F2*  F3* F4*\nOmega total for total scores and subscales    0.98 0.94 0.90 0.92 0.9\nOmega general for total scores and subscales  0.85 0.69 0.52 0.76 0.7\nOmega group for total scores and subscales    0.08 0.25 0.38 0.16 0.2\n\n\nThe results from the exploratory factor analysis indicate that the four-factor model provides a strong fit, with an overall omega total of 0.98, suggesting excellent reliability for the total score. The omega hierarchical value of 0.85 indicates that 85% of the total-score variance is attributable to a general factor, showing that the general psychological cost factor plays a dominant role in explaining the variance across items. Additionally, the individual subscales also show good reliability, with their omega total values ranging from 0.90 to 0.94."
  },
  {
    "objectID": "index.html#simple-linear-regression-slr",
    "href": "index.html#simple-linear-regression-slr",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "Simple Linear Regression (SLR)",
    "text": "Simple Linear Regression (SLR)\nLinear model and Linear regression are technically synonyms and we often use either terms when quantifying the effect of a ‚Äúcontinuous‚Äù independent variable on a‚Äùcontinuous‚Äù dependent variable. The difference between this and ANOVA is that ANOVA is usually used when quantifying the effect of a ‚Äúdiscrete (or categorical)‚Äù independent variable on a‚Äùcontinuous‚Äù dependent variable. So, it is important to note that- ANOVA is also a linear regression! In fact, if you run ‚Äúanova‚Äù function on linear model object, you‚Äôll most likely get the same p-value.\nRegression generally refers to the fact that we are quantifying the relationship between a response variable and (one or more) predictor variables. In the case of SLR, both the response and the predictor are numeric variables and we are using a single predictor (independent) variable. Later we will use multiple predictor variables (multiple regression). Also, this models tells us that our model for Y is a linear combination of the predictors X. (In this case just one predictor)! For now, this always results in a model that is a line, but this is not always the case (and we may see this later on in the tutorial).\nLike ANOVA, in SLR, we often talk about the assumptions that this model makes. This include-\n\nLinearity- the relationship between Y and x is linear, of the form \\(\\beta_0 + \\beta_1x\\).\nIndependent. The errors \\(\\epsilon\\) are independent.\nNormality. The errors, \\(\\epsilon\\) are normally distributed. I.e. the ‚Äúerror‚Äù around the line follows a normal distribution.\nEquality of Variance. At each value of x, the variance of Y is the same.\n\nTo learn extensively about the model assumptions, you may want to check this invited lecture I gave last Winter. Testing Model Assumptions.\nFor this lab, we will be using a year dataset on Corvettes sales in Virginia Beach, Virginia. Using this data, ten Corvettes (between 1 and 6yrs old) were randomly selected and the below data shows the sales price (in hundreds of dollars) denoted by y and the age (in years) denoted by x.\n\n\n\n\n\n\nTasks\n\nGraph the data in a scatterplot to determine if there is a possible linear relationship.\nCompute and interpret the linear correlation coefficient, r.\nDetermine the regression equation for the data.\nGraph the regression equation and the data points.\nIdentify outliers and potential influential observations.\nCompute and interpret the coefficient of determination, r2.\nObtain the residuals and create a residual plot. Decide whether it is reasonable to consider that the assumptions for regression analysis are met by the variables in questions.\nUsing 5% significance level, can we say the data provide sufficient evidence to conclude that the slope of the population regression line is not 0 and, hence, that age is useful as a predictor of sales price for Corvettes?\nObtain and interpret a 95% confidence interval for the slope, Œ≤, of the population regression line that relates age to sales price for Corvettes.\nObtain a point estimate for the mean sales price of all 4-year-old Corvettes.\nDetermine a 95% confidence interval for the mean sales price of all 4-year-old Corvettes.\nFind the predicted sales price of Jack Smith‚Äôs 4-year-old Corvette.\nDetermine a 95% prediction interval for the sales price of Jack Smith‚Äôs 4-year-old Corvette.\n\nThis is the link to the main google drive folder for all the data to complete this tutorial!\nTo start, we need to load in the packages and data\n\npacman::p_load(ggplot2,dplyr,ggplot2,ggpubr,lmtest)\n\n# Load data\ndf &lt;- read.csv(\"data/corvettes.csv\")\n\n# Rename columns ( x = Age and y = Price)\ndf &lt;- df %&gt;%\n  rename(Age = x, Price = y)\n\n#check the first few rows\nhead(df)\n\n  Age Price\n1   6 12500\n2   6 11500\n3   6 13000\n4   4 16000\n5   2 21900\n6   5 15000\n\n\n1: Graph the Data in a Scatterplot Let‚Äôs create a scatterplot to visualize the relationship between Age and SalesPrice. Assuming these are the relevant columns, update the column names if needed.\n\n# Scatterplot of Age vs. SalesPrice\n\nggplot(df, aes(x = Age, y = Price)) +\n  geom_point() +\n  labs(title = \"Scatterplot of Age vs. Sales Price\", x = \"Age\", y = \"Price\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nInterpretation- The points seem to follow a linear pattern, although with a negative relationship.\n2: Compute and Interpret the Linear Correlation Coefficient\nThe Pearson Correlation is a statistical method that calculates the strength and direction of linear relationships between continuous variables. It produces a sample correlation coefficient, r, which can be used to evaluate whether there is a linear relationship among the same variables in the population. This population correlation coefficient is represented by œÅ (‚Äúrho‚Äù) and is a parametric measure.\nPearson correlation indicates:\n\nWhether there is a statistically significant linear relationship between two continuous variables\nIt also shows the strength of this linear relationship (i.e., how close the relationship is to being a perfectly straight line)\nFinally, it reveals the direction of this linear relationship (increasing or decreasing)\n\nIt is however important to note that Pearson Correlation cannot address non-linear relationships or relationships among categorical variables. To address relationships that involve categorical variables and/or non-linear relationships, you need to consider the equivalent non-parametric test (e.g., Spearman‚Äôs rank correlation).\nAlso, while Pearson Correlation reveals associations among (continuous) variables, you should remember that ‚ÄúCorrelation does not imply causation,‚Äù no matter how large the correlation coefficient is.\n\n# Compute correlation\ndf_cor &lt;- cor(df$Age, df$Price)\ndf_cor\n\n[1] -0.9678716\n\n\nInterpretation\nThe correlation coefficient is -0.968. This r-value indicates a robust negative linear correlation, given its proximity to -1 and negative sign. This strong negative linear correlation suggests that data points should closely cluster around a downward-sloping regression line, (which aligns with the graph above). Consequently, the presence of a strong negative linear relationship between Age and Price supports the continuation of linear regression analysis.\n3. Regression equation for the data.\n\n# Fit linear model\nmod &lt;- lm(Price ~ Age, data = df)\n\n# model summary\nsummary(mod)\n\n\nCall:\nlm(formula = Price ~ Age, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1999.03  -781.31   -63.59   896.12  2420.39 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  29160.2     1143.3   25.51 5.98e-09 ***\nAge          -2790.3      256.3  -10.89 4.48e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1425 on 8 degrees of freedom\nMultiple R-squared:  0.9368,    Adjusted R-squared:  0.9289 \nF-statistic: 118.5 on 1 and 8 DF,  p-value: 4.484e-06\n\n\nFrom the output, we can interpret the regression equation:\nPrice = \\(\\beta_0\\) \\(+\\) \\(\\beta_1 .\\) Age\nwhere \\(\\beta_0\\)‚Äã is the intercept and \\(\\beta_1\\)‚Äã is the slope.\nSo, from the result above, the regression equation is: Price = 29160.2 - (2790.3)(Age). So what if a newly sold Corvettes was 10years old? What would be the price? Y = 29160.2 - (2790.3)(10) which equals $1257.2\n4: Graph the Regression Equation and the Data Points\nAdd the regression line to our scatterplot.\n\n# Scatterplot with regression line & equation\n\nggplot(df, aes(x = Age, y = Price)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  stat_regline_equation(\n    aes(label = ..eq.label..),\n    label.x = 3, label.y = max(df$Price) - 1000, \n    coef.digits = 2\n  ) +\n  # Add R^2\n  stat_regline_equation(\n    aes(label = ..rr.label..),\n    label.x = 3, label.y = max(df$Price), \n    rr.digits = 2\n  ) +\n  labs(title = \"Scatterplot with Regression Line\", x = \"Age\", y = \"Price\") +\n  theme_minimal()\n\nWarning in stat_regline_equation(aes(label = ..eq.label..), label.x = 3, :\nIgnoring unknown parameters: `coef.digits`\n\n\nWarning in stat_regline_equation(aes(label = ..rr.label..), label.x = 3, :\nIgnoring unknown parameters: `rr.digits`\n\n\nWarning: The dot-dot notation (`..eq.label..`) was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `after_stat(eq.label)` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n5: Identify Outliers\nFrom the plot, there seem to be no points that lie far from the cluster of data points or far from the regression line; thus, no possible outliers.\n6. Compute and interpret the coefficient of determination, \\(r^2\\).\n\n# r-squared value\nrsquared &lt;- summary(mod)$r.squared\nrsquared\n\n[1] 0.9367754\n\n\nThe \\(r^2\\) = 0.937; therefore, about 93.7% of the variation in the price data is explained by age. I.e., as the car gets older, the value/price drops! The regression equation appears to be very useful for making predictions since the value of \\(r^2\\) is close to 1.\nNote- we also have adjusted R-square. R-square technically measures the variation of a regression model (variation in Y given x). R-squared either increases or remains the same when new predictors are added to the model. Adjusted R-squared measures the variation for a multiple regression model, and helps you determine goodness of fit. For the purpose of this SLR (one predictor, we are not adding more), so we can decide to intepret any of them. But if you have multiple predictors, you may want to look into Adj. \\(r^2\\))!\n7. Residuals\nLet‚Äôs plot residuals to check for patterns, which can indicate whether regression assumptions are met.\n\n# Get residuals\ndf$residuals &lt;- resid(mod)\n\n# Residual plot\nggplot(df, aes(x = Age, y = residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Residual Plot\", x = \"Age\", y = \"Residuals\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWe can also check the assumption of constant variance using the Breusch-Pagan Test.\nThe \\(H_0\\) and \\(H_A\\) can be considered to be:\n\\(H_0\\) : Homoscedasticity. The errors have constant variance about the true model.\n\\(H_a\\) : Heteroscedasticity. The errors have non-constant variance about the true model.\n\nbptest(mod)\n\n\n    studentized Breusch-Pagan test\n\ndata:  mod\nBP = 2.293, df = 1, p-value = 0.13\n\n\nInterpretation- The residual plot shows a random scatter of the points. Here, we can see that at any fitted value, the mean of the residuals is roughly 0. As such, the linearity assumption holds true.In fact, that is why we generally add a horizontal line at \\(y = 0\\) to emphasize this point.\nAlso, from the bpTest, we see a large p-value (0.13), so we do not reject the null hypothesis of homoscedasticity, and thus conclude constant variance assumption about the true model.\nAlso, to assess the normality of the residuals\n\n# 2. Q-Q Plot of Residuals\nggplot(df, aes(sample = residuals)) +\n  stat_qq() +\n  stat_qq_line(color = \"red\") +\n  labs(title = \"Q-Q Plot of Residuals\", x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWe can also use the shapiro test to confirm the normality\n\nshapiro.test(resid(mod))\n\n\n    Shapiro-Wilk normality test\n\ndata:  resid(mod)\nW = 0.97896, p-value = 0.9594\n\n\n\\(H_0\\): The residuals are normally distributed.\n\\(H_a\\): The residuals are not normally distributed.\nIf the p-value is low (&lt; 0.05), it suggests evidence against the \\(H_0\\), indicating that the residuals may not follow a normal distribution. However, if the p-value is high (&gt; 0.05), it supports the \\(H_0\\), suggesting that the residuals are approximately normally distributed.\nIn short, we can say if the points of the plot do not closely follow a straight line, this would suggest that the data do not come from a normal distribution.\n8. Using 5% significance level, can we say the data provide sufficient evidence to conclude that the slope of the population regression line is not 0 and, hence, that age is useful as a predictor of sales price for Corvettes?\nHere, we need to state the hypothesis. The hypothesis from the question above is that-\n\\(H_0\\): \\(\\beta = 0\\) (Age is not a useful predictor of price.)\n\\(H_a\\): \\(\\beta \\neq 0\\) (Age is a useful predictor of price.)\nNow that we‚Äôve done that, remember our alpha = 0.05 and our critical value or rejection region is that we should reject the null hypothesis if alpha is less than 0.05. Finally, to answer the question, check the regression output and see the ‚Äúcoefficient‚Äù. From the result of the regression, you can see that p-value &lt;0.001\n\n# Get p-value for slope\np_value &lt;- summary(mod)$coefficients[2, 4]\np_value\n\n[1] 4.484274e-06\n\n\nInterpretation- Since the P-value &lt; 0.05, we have evidence to reject the null hypothesis. In other words, we have enough evidence to conclude that the slope of the population regression line is not zero. In other words, age is a useful predictor of price for Corvettes.\n9. Obtain and interpret a 95% confidence interval for the slope, Œ≤ , of the population regression line that relates age to sales price for Corvettes.\n\n# 95% confidence interval for the slope\nconfint(mod, \"Age\", level = 0.95)\n\n        2.5 %    97.5 %\nAge -3381.295 -2199.288\n\n\nLook at the result above, We are 95% confident that the slope of the true regression line is somewhere between -3381.295 and -2199.288. In other words, we are 95% confident that for every year older Corvettes get, their average price decreases somewhere between $3,381.295 and $2,199.288.\n10. Obtain a point estimate for the mean sales price of all 4-year-old Corvettes.\nWe can use the model to predict the mean price for a Corvette of age 4.\n\n# Predict mean sales price for age 4\npredict(mod, newdata = data.frame(Age = 4))\n\n       1 \n17999.03 \n\n\nLook at the result, the point estimate (PRE_1) is $17,999.03.\n11. Determine a 95% confidence interval for the mean sales price of all 4-year-old Corvettes.\n\n# 95% confidence interval for mean price of 4-year-old Corvettes\npredict(mod, newdata = data.frame(Age = 4), interval = \"confidence\", level = 0.95)\n\n       fit      lwr     upr\n1 17999.03 16958.46 19039.6\n\n\nFrom the result, we are 95% confident that the mean sales price of all four-year-old Corvettes is somewhere between $16,958.46 and $19,039.6.\n12. Find the predicted sales price of Jack Smith‚Äôs selected 4-year-old Corvette.\n\n# Predicted sales price for a specific 4-year-old Corvette\npredict(mod, newdata = data.frame(Age = 4))\n\n       1 \n17999.03 \n\n\nThe predicted sales price is $17,999.03.\n13. Determine a 95% prediction interval for the sales price of Jack Smith‚Äôs 4-year-old Corvette.\n\n# 95% prediction interval for Jack's 4-year-old Corvette\npredict(mod, newdata = data.frame(Age = 4), interval = \"prediction\", level = 0.95)\n\n       fit      lwr      upr\n1 17999.03 14552.92 21445.14\n\n\nWe are 95% certain that the individual sales price of Jack Smith ºs Corvette will be somewhere between $14,552.92 and $21,445.14."
  },
  {
    "objectID": "index.html#build-multiple-regression-in-r",
    "href": "index.html#build-multiple-regression-in-r",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "Build Multiple Regression in R",
    "text": "Build Multiple Regression in R\nNext, we‚Äôll conduct a multiple linear regression using mpg as the dependent variable and both wt and year as predictors.\n\n# Fit the multiple linear regression model\nmlr_model &lt;- lm(mpg ~ wt + year, data = auto)\n\nsummary(mlr_model)\n\n\nCall:\nlm(formula = mpg ~ wt + year, data = auto)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.852 -2.292 -0.100  2.039 14.325 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1.464e+01  4.023e+00  -3.638 0.000312 ***\nwt          -6.635e-03  2.149e-04 -30.881  &lt; 2e-16 ***\nyear         7.614e-01  4.973e-02  15.312  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.431 on 387 degrees of freedom\nMultiple R-squared:  0.8082,    Adjusted R-squared:  0.8072 \nF-statistic: 815.6 on 2 and 387 DF,  p-value: &lt; 2.2e-16\n\n\nQuestions\n\nLooking at the result, you should see tables that are similar to the ones in our previous example (our model summary is new). Take a look at the ‚Äúmodel summary‚Äù to determine the new R squared and Standard Error of the Estimate. Compare that with the previous regression output- has the inclusion of additional variables (year) resulted in an improvement in our model?\n\nNote- the new R squared has improved, and the Standard Error has reduced! This indicates that our multiple regression model is more precise than the previous linear regression model.\n\nDo all our variables hold statistical significance?\n\nYou can verify this by checking the table. The Pr(&gt; t|) indicate whether our independent variables have a statistically significant association with our dependent variable. It also helps us determine whether our model is a good fit for explaining the variation in the mpg.\nIn our case, we have evidence to believe it is, given that the significance is way below 0.05 (&lt;0.001).\nLastly, check the ‚Äúestimate‚Äù column. Here we find the value for each of our independent variables (wt and year) and also the intercept.\nSo, how can we write our multiple regression equation? mpg (Y) = -14.64 ‚Äì 0.0066(weight) + 0.761(year). Thus, if we added a new car and had some basic data like the year and weight, we would be able to estimate, with a relatively high degree of confidence, how many mpg would be used given the predictors.\nInterpretation\nHere, the constant = -14.64 represents our estimate for the intercept, i.e.- the mean miles per gallon for a car that has a weight of 0 pounds and was manufactured in 1900 (the start year of our dataset). As we can see here that the estimate is negative, which, in the real world, is physically impossible. However, this is not surprising because we cannot realistically expect our model to accurately predict the fuel efficiency of cars from 1900 that weigh 0 pounds because such vehicles never existed anyways! So, like simple linear regression, this value (intercept) represent the mean of Y when all predictors are set to 0.\nHowever, the interpretation of the coefficients of our predictors is slightly different from previous SLR. For instance, the estimate of -0.0066 for ‚Äúwt‚Äù = the expected average change in miles per gallon for a one-unit increase in weight for cars of a specific model year, with the year being held constant. Note that this estimate is negative, which aligns with our expectations, as, in general, fuel efficiency tends to decrease for larger vehicles. However, in the context of multiple linear regression, this interpretation is contingent upon a fixed value for another predictor, such as ‚Äúyear‚Äù in our case. This means that the relationship between fuel efficiency and weight might not hold true when additional factors, like the model year, are taken into account, potentially causing a reversal in the sign of our coefficient.\nLastly, the estimate of 0.761 for ‚Äúyear‚Äù = the expected average change in miles per gallon for a one-year increase in the model year for cars with a specific weight, where weight is held constant now. It is not far from expectation that this estimate is positive since one would anticipate that, over time, as technology advances, cars with the specific weight would achieve better fuel efficiency compared to their earlier counterparts.\nNote- Sometimes, you may discover that the model is not statistically significant, or that one independent variable does not hold statistical significance. In such instances, you may want to rerun the model, eliminating insignificant or redundant variables. Ideally, it is good to do some variable importance selection on your predictors before including them in the model (or use some prior knowledge of the system). It may take several attempts to run multiple regression models to find the best-fitting model for the data. Generally, it is good to have model with a low standard error of the estimate, high R squared and relatively simple. A model with three independent variables, a relatively high R squared and low standard error may be preferable to a model with 19 independent variables and a high R squared and low standard error (this is why variable importance is crucial)!\nTo do variable importance selection, you can calculate the multicollinearity. In R, you can compute the Variance Inflation Factor (VIF).\n\n# Calculate VIF for the multiple linear regression model\n\nvif_mod &lt;- vif(mlr_model)\nvif_mod\n\n      wt     year \n1.103646 1.103646 \n\n\nThe VIF values indicate the degree of multicollinearity for each variable in the model. In our case, the VIF (for both wt and year) is around 1.104. Ideally, a VIF of 1 means that variables are not correlated and no multicollinearity in the regression model. Generally, a VIF &gt;6 is considered a sign of high multicollinearity between the predictor variables and can affect the stability and interpretability of your regression model. You may need to address multicollinearity by either removing one of the correlated variables (redundant) or you can use dimensionality reduction techniques like Principal Component Analysis (PCA) to reduce dimensions."
  },
  {
    "objectID": "index.html#understanding-moderation-in-statistical-analysis",
    "href": "index.html#understanding-moderation-in-statistical-analysis",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "Understanding Moderation in Statistical Analysis",
    "text": "Understanding Moderation in Statistical Analysis\nModeration examines how the relationship between two variables is influenced by a third variable. Specifically, it assesses the extent to which the impact of one variable on another varies depending on the level or presence of an additional variable.\nAssumptions Regarding the Dependent Variable:\nModeration analysis relies on linear regression techniques, so the outcome variable should be continuous. Also, the predictors in the model can be either continuous or categorical (binary).\nAs with regression analysis, there are assumptions that are quite important here:\n\nLinearity: A crucial assumption for moderation is that the interaction between the variables is linear. This implies that the effect of the independent variable (X) on the dependent variable (Y) changes at a consistent rate as the moderator variable (M) increases or decreases. Moreover, the primary relationship between X and Y should also be linear. Ensuring both the moderation effect and the original relationship are linear is essential for accurate interpretation.\nOther Assumptions: Beyond linearity, moderation shares the same assumptions as multiple regression, such as homoscedasticity, independence of errors, and normality of residuals.\n\nSo, essentially, moderation analysis allows us to determine whether the relationship between two variables is shaped by a third variable. For accurate interpretation, both the moderation effect and the direct relationship between the primary variables should show linearity. Aside from this, moderation operates under the standard assumptions of multiple regression.\nWhen we say that a moderator influences the relationship between two other variables, we mean that the nature or strength of that relationship changes based on the level or category of the moderator. In other words, the relationship between X and Y isn‚Äôt uniform across all conditions but varies with moderator M.\n\nExploring Moderation and Its Relationship to Interaction\nAs in any statistical models, we have to evaluate moderation effects through statistical methods. Ideally, if you visualize the relationship between two variables across different levels of a moderator and notice that the regression lines are not parallel, this indicates moderation. Why is that? Parallel lines suggest that the relationship between the two primary variables remains constant regardless of the moderator‚Äôs level, meaning the moderator doesn‚Äôt influence the relationship. However, if the lines have different slopes, it signifies that the strength or direction of the relationship changes depending on the moderator.\n\n\n\nModeration Effect Plot\n\n\nYou might have heard of interaction terms before? This is technically the same logic. We say we have interaction when the effect of one variable on an outcome depends on the level of another variable. Essentially, this is what we‚Äôre observing with moderation. In fact, we call the graph illustrating non-parallel slopes as an ‚Äúinteraction plot‚Äù rather than a ‚Äúmoderation plot.‚Äù So, how do moderation and interaction differ?\nI‚Äôd say the distinction between moderation and interaction is subtle and primarily lies in their interpretation rather than their mathematical foundation. Moderation implies a specific primary relationship: Variable X influences Variable Y, and Variable M alters this influence. In contrast, an interaction doesn‚Äôt necessarily assume a direct primary relationship. It simply indicates that both X and M are related to Y and that their combined effect on Y is not purely additive. This means that the relationship between X and Y might vary at different levels of M, or alternatively, the relationship between M and Y might change depending on the level of X. The interaction can work in either direction.\n\n\n\nModeration\n\n\n\n\nExample ‚Äì Age as a Moderator\nImagine a study exploring the relationship between the number of hours employees engage in professional development activities and their overall job performance. Suppose a basic regression analysis reveals that more hours spent on professional development are associated with higher job performance:\n\n#lm(job_performance ~ professional_hours, data = employee_data) %&gt;% summary()\n\nHowever, we might wonder if this positive relationship is true for all employees, regardless of their age. Specifically, does the impact of professional development hours on job performance differ between younger employees and those who are more experienced or older? In this context, age acts as a potential moderator. We hypothesize that the effect of professional development on job performance may vary depending on an employee‚Äôs age group.\nHypothesis:\n\nYounger Employees: Might benefit more from professional development hours as they are still building their skills and knowledge.\nOlder Employees: May experience a different level of impact, possibly due to having more established skills or different learning preferences.\n\nSimulating Data in R:\nTo test this moderation effect, we can simulate some data in R. Here‚Äôs a basic example:\n\n#load libraries\npacman::p_load(dplyr, ggplot2,magrittr,interactions)\n\n\n#set seed\nset.seed(999)\n\n\n# Let's simulate data\n\n# sample size\nn &lt;- 500\n\n# Simulate age with a higher probability for Younger and Older groups\nemployee_data &lt;- data.frame(\n  professional_hours = rnorm(n, mean = 20, sd = 5),\n  age = sample(c(25:40, 41:60), n, replace = TRUE, prob = c(rep(0.6/16, 16), rep(0.4/20, 20))) )\n\n\n\n# We can also create a binary moderator variable: Younger (&lt;=40) vs. Older (&gt;40)\nemployee_data &lt;- employee_data %&gt;%\n  mutate(age_group = ifelse(age &lt;= 40, \"Younger\", \"Older\"))\n\n# Assume job performance is influenced by professional_hours and moderated by age_group\nemployee_data &lt;- employee_data %&gt;%\n  mutate(job_performance = \n           ifelse(age_group == \"Younger\", \n                  50 + 5 * professional_hours + rnorm(500, 0, 1.5), \n                  50 + 1 * professional_hours + rnorm(500, 0, 1.5)))\n\nNow, we can fit the model. We are interested in how age influences the relationship between hours spent on professional development activities (professional_hours) and overall job performance (job_performance).\n\n#fit linear model first\n\nmod &lt;- lm(job_performance ~ professional_hours + age, data = employee_data) %&gt;% summary()\n\nmod\n\n\nCall:\nlm(formula = job_performance ~ professional_hours + age, data = employee_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-76.964 -15.344   1.889  16.449  47.747 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        176.85613    5.50243   32.14   &lt;2e-16 ***\nprofessional_hours   3.49500    0.19917   17.55   &lt;2e-16 ***\nage                 -3.25877    0.09528  -34.20   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.61 on 497 degrees of freedom\nMultiple R-squared:  0.7487,    Adjusted R-squared:  0.7477 \nF-statistic: 740.3 on 2 and 497 DF,  p-value: &lt; 2.2e-16\n\n\nFrom the result above, we can see Intercept ~ 184.78251. This value represents the estimated job performance score for an employee who has zero hours of professional development. While an employee with no professional development hours is unlikely in a real-world scenario, the intercept provides a baseline for the model.\nProfessional Development Hours (3.25): The coefficient for professional_hours is 3.25, which is highly significant (p-value &lt; 2e-16). This means that we have a strong positive relationship between professional development hours and job performance. Also, for each additional hour an employee spends on professional development activities, their job performance score is expected to increase by approximately 3.25 units, holding age constant.\nAge (-3.35): Each additional year of age is associated with a 3.35-unit decrease in job performance score, holding professional development hours constant. This negative relationship is also highly significant (p &lt; 2e-16), suggesting that older employees in this sample tend to have lower job performance scores when controlling for their professional development hours.\nStatistical Significance: The p-value associated with professional_hours and age is &lt; 0.001. This confirms that the relationship between our independent variables and dependent variable (job performance) is statistically significant at all conventional level of significance.\nModel Fit:\nMultiple R-squared (0.7578): Approximately 75.78% of the variability in job performance is explained by professional development hours alone. Adjusted R-squared (0.7568): After adjusting for the number of predictors, about 75.68% of the variance in job performance is explained by the model. F-statistic (777.4, p &lt; 2.2e-16): The overall model is statistically significant, suggesting that professional development hours reliably predict job performance.\nPlease note: Due to stochasticity, the values above may change slightly when you run yours since we‚Äôre using simulated data - but it should not change that much.\nNote:\nThe coefficients represent the unique main effects of each predictor. Specifically, professional development hours and age each have a significant impact on job performance independently of one another.\nWhile this model highlights the direct individual relationships, it does not inform us about whether the effect of professional development hours on job performance varies by age. In other words, we haven‚Äôt yet tested if age moderates the relationship between professional development and job performance.\nTo explore whether age acts as a moderator, we need to include an interaction (moderation) term between professional_hours and age in our model. This will allow us to assess if the impact of professional development on job performance differs across different age groups.\n\n# Finally, fit a moderation model\nmodel &lt;- lm(job_performance ~ professional_hours * age_group, data = employee_data)\nsummary(model)\n\n\nCall:\nlm(formula = job_performance ~ professional_hours * age_group, \n    data = employee_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.3865 -1.0182 -0.1125  1.1429  4.5200 \n\nCoefficients:\n                                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                         50.19846    0.49537 101.336   &lt;2e-16 ***\nprofessional_hours                   0.99558    0.02436  40.863   &lt;2e-16 ***\nage_groupYounger                    -0.24337    0.60698  -0.401    0.689    \nprofessional_hours:age_groupYounger  4.00837    0.02989 134.119   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.531 on 496 degrees of freedom\nMultiple R-squared:  0.9987,    Adjusted R-squared:  0.9987 \nF-statistic: 1.312e+05 on 3 and 496 DF,  p-value: &lt; 2.2e-16\n\n\nFrom the result above, we observe that the \\(R^2\\) value has increased from 0.7578 in the initial multiple regression model to 0.9988 after introducing the interaction/moderation term. This increase indicates that the model with the interaction term fits the data significantly better. Additionally, once we add the interaction between professional_hours and age_group, the unique effect of age_group becomes non-significant. Why does this shift occur? By including the interaction, we appropriately attribute variance to the combined effect of professional_hours and age_group rather than isolating their individual linear effects. This adjustment provides a more accurate representation of each variable‚Äôs unique impact. It‚Äôs important to remember that in regression modeling, each coefficient reflects the unique main effect of its corresponding variable while controlling for the others in the model.\nLooking at the interaction/moderation term, it appears to be highly significant. But what does this imply? Moderation effects can be complex to interpret, so visualizing the relationship with a graph is often helpful. However, before we create the plot, let‚Äôs attempt to understand it conceptually.\nRecall that the interaction term models how the relationship between professional_hours and job_performance varies based on age_group.\nIn our model, the coefficient for the interaction term is 3.97368. This means that the effect of professional_hours on job_performance is 3.97368 units stronger for the ‚ÄúYounger‚Äù age group compared to the ‚ÄúOlder‚Äù age group.\nSpecifically:\nFor Older Employees: The effect of professional_hours on job_performance is 1.00426 (the coefficient for professional_hours).\nFor Younger Employees: The effect of professional_hours on job_performance is 1.00426 + 3.97368 = 4.97794.\nThis indicates that professional development hours have a significantly stronger positive impact on job performance for Younger employees than for Older employees. In other words, the relationship between professional development and job performance is contingent upon the employee‚Äôs age group‚Äîa classic case of moderation.\nWhat Does This Mean for Our Study?\nThe interaction suggests that the effectiveness of professional development activities in enhancing job performance varies by age. We can say that younger employees benefit more from additional professional development hours compared to their older counterparts.\n\nMain Effect of Professional Hours: Indicates the overall relationship between professional development hours and job performance.\nMain Effect of Age Group: Shows any direct differences in job performance between younger and older employees, regardless of professional hours.\nInteraction Term (professional_hours:age_group): Reveals whether the relationship between professional hours and job performance differs by age group.\n\nVisualization:\nThis moderated relationship can be visualized by plotting separate regression lines for different age groups, showing how the slope of the relationship between professional development hours and job performance changes with age.\nlet‚Äôs create an interaction plot:\n\nmod1 &lt;- lm(job_performance ~ professional_hours * age_group, data = employee_data)\n\ninteractions::interact_plot(mod1, \"professional_hours\", modx = \"age_group\",\n                            modx.labels = c(\"Older\", \"Younger\"),\n                            legend.main = \"Age_Group\",\n                            y.label = \"Job Performance\",\n                            x.label = \"Professional Hours\")\n\n\n\n\n\n\n\n\nWe can also use ggplot to do the same thing\n\nggplot(employee_data, aes(x = professional_hours, y = job_performance, color = age_group)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"Moderation Effect of Age on Professional Development and Job Performance\",\n       x = \"Professional Development Hours\",\n       y = \"Job Performance\",\n       color = \"Age Group\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe interaction plot shows that job performance increases with professional hours for both younger and older employees. However, the effect is much stronger for younger employees, as indicated by the steeper slope of their line compared to that of the older employees. This suggests that younger employees‚Äô job performance is more positively influenced by additional professional hours than that of older employees. By visualizing the interaction, We can see that age_group moderates the relationship between professional_hours and job_performance."
  }
]