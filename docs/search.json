[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to EDUC 6003 Advanced Statistics. This website will be used for all the tutorials of this course. We will be using R/RStudio throughout the semester. However, anyone interested in using Python should feel free to do so (and I‚Äôm happy to chat about that). If you‚Äôre very new to R for statistical analysis and would like a quick intro, please refer to this website R Workshop for Statistical Analysis.\nIn fact, this website was built entirely using R!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "This tutorial will serve as a Guide to Enhanced Reliability Estimation with R\n\n\nReliability refers to the consistency and precision of measurement instruments. In psychological testing, it assesses the extent to which a test produces stable and consistent results.\n\n\nMeasurement Precision: Ensures that the scores accurately reflect the true attributes being measured.\nResearch Validity: High reliability is a prerequisite for valid conclusions and replicable research findings.\nError Reduction: Minimizes the impact of random errors, enhancing the clarity of observed relationships between constructs.\n\n\n\nInternal Consistency: Degree to which items within a test measure the same construct.\nTest-Retest Reliability: Consistency of scores over time.\nInter-Rater Reliability: Agreement between different raters or observers.\n\n\n\n\n\nClassical Test Theory Overview: CTT posits that each observed score is composed of a true score and an error score:\n\\[ X = T + E \\]\nwhere:\nùëã= Observed score ùëá= True score ùê∏= Error score\n\n\nThis is a widely used measure of internal consistency reliability within CTT. It estimates the extent to which items on a test measure the same underlying construct.\n\\[\n\\alpha = \\frac{N}{N-1} \\left(1 - \\frac{\\sum \\sigma^2_{E}}{\\sigma^2_{X}}\\right)\n\\]\nWhere:\n\\(\\alpha\\) = Cronbach‚Äôs Alpha\nùëÅ = Number of items in the test\n\\(\\sigma^2_{E}\\) = Variance of the error scores\n\\(\\sigma^2_{X}\\) = Variance of the observed total scores\n\n\nUnidimensionality: All items measure a single construct.\nTau Equivalence: Each item has the same true score variance.\nIndependence of Errors: Error terms are uncorrelated across items.\n\n\n\nSensitivity to Tau Equivalence: Violations can lead to underestimation or overestimation of reliability.\nAssumes Unidimensionality: Not suitable for multidimensional scales without adjustments.\nIgnores Factor Structure: Does not account for the underlying factor model of the test.\n\n\n\n\nCoefficient Omega is a more robust alternative to Cronbach‚Äôs Alpha, especially when the assumption of tau-equivalence (equal factor loadings) is violated. Omega takes into account the factor structure of the test, making it suitable for both unidimensional and multidimensional scales.\n\n\nOmega Total (œâ‚Çú): Accounts for all common factors, both general and specific.\nOmega Hierarchical (œâ‚Çï): Represents the proportion of variance attributable to a general factor alone.\nOmega Total is given by:\n\\[\n\\omega_t = \\frac{\\sum_{i=1}^{k} \\lambda_i}{\\sum_{i=1}^{k} \\lambda_i + \\sum_{i=1}^{k} \\theta_i}\n\\]\nWhere:\n\\(\\omega_t\\) = Omega Total\n\\(\\lambda_i\\) = Factor loading for item\n\\(\\theta_i\\) = Unique variance (error variance) for item\n\\(k\\) = Total number of items\nFor a hierarchical model, Omega Hierarchical is:\n\\[\n\\omega_h = \\frac{\\lambda_g^2}{\\lambda_g^2 + \\sum_{i=1}^{k} \\theta_i}\n\\]\nwhere:\n\\(\\omega_h\\) = Omega Hierarchical\n\\(\\lambda_g\\) = Factor loading of the general factor\n\\(\\theta_i\\) = Unique variance for item \\(i\\)\n\n\n\nFactor Structure Incorporation: Utilizes confirmatory factor analysis (CFA) to model the underlying structure.\nLess Sensitive to Tau Equivalence Violations: Provides more accurate reliability estimates when tau equivalence is not met.\nApplicability to Multidimensional Scales: Suitable for tests measuring multiple constructs.\n\n\n\n\n\nHere, I will walk through the step-by-step process of calculating Cronbach‚Äôs Alpha and Coefficient Omega using R.\nLoad the necessary packages.\n\npacman::p_load(psych,lavaan,semTools,tidyverse,semTools,psych,tidyverse,lavaan,rio)\n\n\n\n\nThe Big Five Inventory (BFI) is a widely used dataset in personality psychology, measuring the five major dimensions of personality. We‚Äôll focus on the Openness trait for this tutorial.\n\n# Make sure you've loaded the psych package\n\n\n# Load the BFI dataset\ndata(bfi)\n\n# load data file\nbfi &lt;- bfi\nnames(bfi)\n\n [1] \"A1\"        \"A2\"        \"A3\"        \"A4\"        \"A5\"        \"C1\"       \n [7] \"C2\"        \"C3\"        \"C4\"        \"C5\"        \"E1\"        \"E2\"       \n[13] \"E3\"        \"E4\"        \"E5\"        \"N1\"        \"N2\"        \"N3\"       \n[19] \"N4\"        \"N5\"        \"O1\"        \"O2\"        \"O3\"        \"O4\"       \n[25] \"O5\"        \"gender\"    \"education\" \"age\"      \n\n# View the structure of the dataset\n#str(bfi)\n\nThe dataset contains 2,800 participants with various demographic and personality-related variables. A1 to A5 correspond to items measuring the Openness trait.\n\n\nFor this tutorial, we‚Äôll focus on five items measuring the Openness trait. These items are typically labeled as A1 to A5 in the BFI dataset.\n\n\n\n# Select columns that contain \"O\" in their names and remove rows with NA values\noppeness &lt;- bfi %&gt;%\n  select(matches(\"^O\")) %&gt;%\n  drop_na()\n\nhead(oppeness)\n\n  O1 O2 O3 O4 O5\n1  3  6  3  4  3\n2  4  2  4  3  3\n3  4  2  5  5  2\n4  3  3  4  3  5\n5  3  3  4  3  3\n6  4  3  5  6  1\n\n\nEach A variable represents a Likert-type item measuring Openness. Responses range from 1 to 6, treated as continuous variables for analysis.\n\n\n\n\nBefore we continue, let‚Äôs check any missing data.\n\n# Check for missing values\nsum(is.na(oppeness))\n\n[1] 0\n\n\nIn this dataset, there are no missing values in the Openness items. If missing values were present, then we need to address that.\n\n\n\n\nRecall that Cronbach‚Äôs Alpha (Œ±) is a measure of internal consistency that measures how closely related a set of items are as a group.\n\n\n\n# Calculate Cronbach's Alpha using the psych package\n#alpha_result &lt;- psych::alpha(oppeness)\n\n# Print the result\n#print(alpha_result)\n\nBecause some items were negatively correlated with the first principal component, we probably should reverse them.\n\n# Reversing item O2 and O5\n\nq &lt;- c(\"O2\",\"O5\")\nreverse &lt;- function(x){\n  x.reversed &lt;- 7 +0 - x\n}\n\noppeness[, c(\"O2R\", \"O5R\")] &lt;- reverse(oppeness[,c(\"O2\",\"O5\")])\n\n# compare original and reversed responses\noppeness[1:6,]\n\n  O1 O2 O3 O4 O5 O2R O5R\n1  3  6  3  4  3   1   4\n2  4  2  4  3  3   5   4\n3  4  2  5  5  2   5   5\n4  3  3  4  3  5   4   2\n5  3  3  4  3  3   4   4\n6  4  3  5  6  1   4   6\n\n\nNow, we can compute the alpha\n\n# compute alpha coefficient \n\nalpha_result &lt;- psych::alpha(oppeness[, -c(2,5)])\n\n# Print the result\nprint(alpha_result)\n\n\nReliability analysis   \nCall: psych::alpha(x = oppeness[, -c(2, 5)])\n\n  raw_alpha std.alpha G6(smc) average_r S/N   ase mean   sd median_r\n       0.6      0.61    0.57      0.24 1.6 0.012  4.6 0.81     0.23\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.58   0.6  0.63\nDuhachek  0.58   0.6  0.63\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nO1       0.54      0.54    0.48      0.23 1.2    0.014 0.0087  0.23\nO3       0.50      0.50    0.44      0.20 1.0    0.015 0.0065  0.20\nO4       0.61      0.62    0.56      0.29 1.7    0.012 0.0040  0.29\nO2R      0.57      0.57    0.51      0.25 1.3    0.014 0.0077  0.21\nO5R      0.52      0.53    0.48      0.22 1.1    0.015 0.0109  0.21\n\n Item statistics \n       n raw.r std.r r.cor r.drop mean  sd\nO1  2726  0.61  0.65  0.51   0.39  4.8 1.1\nO3  2726  0.68  0.69  0.59   0.45  4.4 1.2\nO4  2726  0.50  0.52  0.29   0.22  4.9 1.2\nO2R 2726  0.66  0.60  0.44   0.34  4.3 1.6\nO5R 2726  0.67  0.66  0.52   0.42  4.5 1.3\n\nNon missing response frequency for each item\n       1    2    3    4    5    6 miss\nO1  0.01 0.04 0.08 0.22 0.33 0.33    0\nO3  0.03 0.05 0.10 0.28 0.34 0.20    0\nO4  0.02 0.05 0.06 0.17 0.32 0.39    0\nO2R 0.06 0.10 0.15 0.14 0.26 0.29    0\nO5R 0.02 0.07 0.13 0.19 0.32 0.27    0\n\n\nExplanation:\nraw_alpha: The Cronbach‚Äôs Alpha coefficient.\nstd.alpha: Standardized alpha, similar to raw_alpha.\nG6(smc): Generalizability theory estimate with squared multiple correlations.\naverage_r: Average inter-item correlation.\nS/N: Signal-to-noise ratio.\nase: Asymptotic standard error.\nConfidence Intervals: Lower and upper bounds for alpha.\nAs we can see, the Cronbach‚Äôs Alpha for the Openness items is 0.6, indicating strong internal consistency. The average inter-item correlation is 0.24, moderate and within psychological scales.\n\n\n\n\nConfirmatory Factor Analysis (CFA) is used to verify the factor structure of a set of observed variables. In our case, we assume a unidimensional structure.\n\n\nLet‚Äôs specify a one-factor model where all items load on a single latent factor.\n\n# Specify model\nmod1f &lt;- \"\nopenness =~ O1 + O2R + O3 + O4 + O5R\n\"\n\n\n\n\nFit the Model Using lavaan:\n\n#pacman::p_load(lavaan)\n# Estimate model\nfit.one.f &lt;- cfa(mod1f, data=oppeness, std.lv=T, missing='direct', \n             estimator='MLR')\n\n# The results can be viewed using the summary\n\nsummary(fit.one.f, fit.measures=T, standardized=T)\n\nlavaan 0.6-19 ended normally after 22 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        15\n\n  Number of observations                          2726\n  Number of missing patterns                         1\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                80.583      67.248\n  Degrees of freedom                                 5           5\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  1.198\n    Yuan-Bentler correction (Mplus variant)                       \n\nModel Test Baseline Model:\n\n  Test statistic                              1375.389    1049.226\n  Degrees of freedom                                10          10\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.311\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.945       0.940\n  Tucker-Lewis Index (TLI)                       0.889       0.880\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.946\n  Robust Tucker-Lewis Index (TLI)                            0.891\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -22078.661  -22078.661\n  Scaling correction factor                                  1.167\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)     -22038.369  -22038.369\n  Scaling correction factor                                  1.174\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                               44187.322   44187.322\n  Bayesian (BIC)                             44275.980   44275.980\n  Sample-size adjusted Bayesian (SABIC)      44228.321   44228.321\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.074       0.068\n  90 Percent confidence interval - lower         0.061       0.055\n  90 Percent confidence interval - upper         0.089       0.081\n  P-value H_0: RMSEA &lt;= 0.050                    0.002       0.012\n  P-value H_0: RMSEA &gt;= 0.080                    0.280       0.066\n                                                                  \n  Robust RMSEA                                               0.074\n  90 Percent confidence interval - lower                     0.058\n  90 Percent confidence interval - upper                     0.090\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.006\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.285\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.029       0.029\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  openness =~                                                           \n    O1                0.616    0.029   21.346    0.000    0.616    0.546\n    O2R               0.701    0.041   17.170    0.000    0.701    0.449\n    O3                0.792    0.032   24.649    0.000    0.792    0.649\n    O4                0.357    0.030   11.749    0.000    0.357    0.294\n    O5R               0.685    0.036   19.194    0.000    0.685    0.517\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .O1                4.819    0.022  223.110    0.000    4.819    4.273\n   .O2R               4.300    0.030  143.782    0.000    4.300    2.754\n   .O3                4.439    0.023  189.916    0.000    4.439    3.637\n   .O4                4.898    0.023  210.231    0.000    4.898    4.027\n   .O5R               4.516    0.025  177.976    0.000    4.516    3.409\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .O1                0.893    0.037   23.923    0.000    0.893    0.702\n   .O2R               1.947    0.068   28.607    0.000    1.947    0.798\n   .O3                0.862    0.050   17.172    0.000    0.862    0.579\n   .O4                1.352    0.052   25.967    0.000    1.352    0.914\n   .O5R               1.286    0.059   21.822    0.000    1.286    0.732\n    openness          1.000                               1.000    1.000\n\n\nExplanation:\nEstimator: Maximum Likelihood (ML).\nTest Statistics: The Chi-square test is significant (ùëù&lt;0.001), indicating a poor fit.\nFit Indices:\nCFI (0.94): above 0.90.\nTLI (0.88): Below the threshold of 0.90.\nRMSEA (0.068): Indicates relatively weak fit (‚â•0.05).\nSRMR (0.029): Great fit (‚â§0.08).\n\nresiduals(fit.one.f, type='cor')\n\n$type\n[1] \"cor.bollen\"\n\n$cov\n        O1    O2R     O3     O4    O5R\nO1   0.000                            \nO2R -0.026  0.000                     \nO3   0.037 -0.024  0.000              \nO4   0.013 -0.052  0.000  0.000       \nO5R -0.044  0.090 -0.022  0.027  0.000\n\n$mean\n O1 O2R  O3  O4 O5R \n  0   0   0   0   0 \n\n\nThe fit statistics from the Robust column in the summary suggest that this one-factor model provides a moderate fit to the data. While the Comparative Fit Index (CFI) of 0.94 indicates an acceptable fit, the Tucker-Lewis Index (TLI) of 0.88 is relatively lower, and the Root Mean Square Error of Approximation (RMSEA) is relatively high at 0.08.\nThe factor loadings (ùúÜÃÇ) show significant variation, ranging from 0.357 to 0.792, which implies that the assumption of equal loadings (tau equivalence) does not hold for this openness test. As a result, omega (œâu) should be a more suitable measure of reliability than Cronbach‚Äôs alpha. We can compute the œâu estimate by running the reliability function from the semTools package on the one-factor model object (fit1f).\n\nreliability(fit.one.f)\n\n        openness\nalpha  0.6025464\nomega  0.6103741\nomega2 0.6103741\nomega3 0.6098642\navevar 0.2484010\n\n\nomega and omega2 measure reliability based on the variance expected by the model, while omega3 measures it based on the actual variance seen in your data. The small difference between omega and omega3 suggests that the model‚Äôs predictions of variance are somewhat close to what‚Äôs observed in the sample.\n\n\n\n\nRecall that Coefficient Omega (œâ) is a reliability estimate that accounts for the factor structure of the test, providing a more accurate measure than Cronbach‚Äôs Alpha, especially in the presence of multidimensionality or when tau-equivalence is violated.\nSince factor loadings derived from polychoric correlations represent the link between the factor and the underlying latent response variables (not the actual responses from the items), using the œâu formula here would tell us how much of the variance in the latent response variables is explained by the factor. However, this doesn‚Äôt reflect the true variance in the sum of the observed item responses. Essentially, in this case, œâu would give us the reliability of a hypothetical total score based on the latent variables rather than the actual observed total score.\nTo correct for this, Green and Yang (2009b) proposed a new reliability estimate called œâu-cat, which adjusts the reliability calculation to align with the observed total score. This estimate is more accurate for unidimensional scales with categorical items, especially when the response patterns vary across items.\nSince the psychoticism items use a 4-point rating scale, I fit the one-factor model using polychoric correlations and the WLSMV estimator (weighted least squares with mean and variance adjustment). This approach is recommended for confirmatory factor analysis involving polychoric correlations, as it is more robust than the maximum likelihood (ML) estimator.\n\n#load the data\npotic &lt;- import(\"potic.csv\")\n\n# Specify model\nmod.one.fCat &lt;- 'psyctcsm =~ DDP1 + DDP2 +\nDDP3 + DDP4'\n\n\n# Estimate model\nfit.one.fCat &lt;- cfa(mod.one.fCat, data=potic, std.lv=TRUE, ordered=T, estimator='WLSMV')\n\n# Retrieving the results\nsummary(fit.one.fCat, fit.measures=TRUE, standardized=TRUE)\n\nlavaan 0.6-19 ended normally after 10 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        20\n\n                                                  Used       Total\n  Number of observations                           498         500\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                 7.117      14.910\n  Degrees of freedom                                 2           2\n  P-value (Chi-square)                           0.028       0.001\n  Scaling correction factor                                  0.480\n  Shift parameter                                            0.089\n    simple second-order correction                                \n\nModel Test Baseline Model:\n\n  Test statistic                              1635.647    1316.086\n  Degrees of freedom                                 6           6\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.244\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.997       0.990\n  Tucker-Lewis Index (TLI)                       0.991       0.970\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.969\n  Robust Tucker-Lewis Index (TLI)                            0.908\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.072       0.114\n  90 Percent confidence interval - lower         0.020       0.065\n  90 Percent confidence interval - upper         0.132       0.171\n  P-value H_0: RMSEA &lt;= 0.050                    0.200       0.019\n  P-value H_0: RMSEA &gt;= 0.080                    0.479       0.880\n                                                                  \n  Robust RMSEA                                               0.147\n  90 Percent confidence interval - lower                     0.089\n  90 Percent confidence interval - upper                     0.213\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.004\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.970\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.033       0.033\n\nParameter Estimates:\n\n  Parameterization                               Delta\n  Standard errors                           Robust.sem\n  Information                                 Expected\n  Information saturated (h1) model        Unstructured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  psyctcsm =~                                                           \n    DDP1              0.894    0.028   31.538    0.000    0.894    0.894\n    DDP2              0.753    0.028   26.711    0.000    0.753    0.753\n    DDP3              0.698    0.030   23.314    0.000    0.698    0.698\n    DDP4              0.513    0.040   12.738    0.000    0.513    0.513\n\nThresholds:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    DDP1|t1          -0.716    0.062  -11.591    0.000   -0.716   -0.716\n    DDP1|t2          -0.040    0.056   -0.716    0.474   -0.040   -0.040\n    DDP1|t3           0.296    0.057    5.185    0.000    0.296    0.296\n    DDP1|t4           1.034    0.069   15.065    0.000    1.034    1.034\n    DDP2|t1          -0.580    0.060   -9.693    0.000   -0.580   -0.580\n    DDP2|t2           0.208    0.057    3.668    0.000    0.208    0.208\n    DDP2|t3           0.562    0.060    9.431    0.000    0.562    0.562\n    DDP2|t4           1.096    0.070   15.570    0.000    1.096    1.096\n    DDP3|t1          -1.203    0.074  -16.298    0.000   -1.203   -1.203\n    DDP3|t2          -0.425    0.058   -7.318    0.000   -0.425   -0.425\n    DDP3|t3           0.081    0.056    1.432    0.152    0.081    0.081\n    DDP3|t4           0.913    0.066   13.909    0.000    0.913    0.913\n    DDP4|t1          -1.605    0.092  -17.382    0.000   -1.605   -1.605\n    DDP4|t2          -1.060    0.069  -15.285    0.000   -1.060   -1.060\n    DDP4|t3          -0.521    0.059   -8.817    0.000   -0.521   -0.521\n    DDP4|t4           0.431    0.058    7.406    0.000    0.431    0.431\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .DDP1              0.201                               0.201    0.201\n   .DDP2              0.433                               0.433    0.433\n   .DDP3              0.513                               0.513    0.513\n   .DDP4              0.737                               0.737    0.737\n    psyctcsm          1.000                               1.000    1.000\n\n\n\n# Estimate reliability\n\nreliability(fit.one.fCat)\n\nFor constructs with categorical indicators, Zumbo et al.`s (2007) \"ordinal alpha\" is calculated in addition to the standard alpha, which treats ordinal variables as numeric. See Chalmers (2018) for a critique of \"alpha.ord\" and the response by Zumbo & Kroc (2019). Likewise, average variance extracted is calculated from polychoric (polyserial) not Pearson correlations.\n\n\n           psyctcsm\nalpha     0.7680870\nalpha.ord 0.8007496\nomega     0.7902953\nomega2    0.7902953\nomega3    0.7932682\navevar    0.5289638\n\n\nWe can see that we have two estimates Cronbach‚Äôs alpha and differ a bit (0.80 & 0.77). The is because the 2nd alpha estimate is an example of ordinal alpha, which is calculated using a model based on polychoric correlations, while the first alpha was derived using the standard method based on product-moment covariances between the items. It‚Äôs important to note that ordinal alpha measures the reliability of the sum of the continuous, latent-response variables rather than the observed categorical item responses. Additionally, it still assumes equal factor loadings (tau equivalence). Because of these limitations, I suggest disregarding the alpha value reported by semTools::reliability when the model uses polychoric correlations.\nThe values shown in the omega and omega2 rows represent the œâu-cat estimate. The omega3 row shows a variation where the denominator uses the observed sample variance of ( X ). So, we can see œâu-cat estimates suggest that 79% of the variance in the total score for the psychoticism scale is explained by the single psychoticism factor."
  },
  {
    "objectID": "index.html#quarto",
    "href": "index.html#quarto",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "index.html#running-code",
    "href": "index.html#running-code",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "index.html#introduction-to-reliability-index-analysis",
    "href": "index.html#introduction-to-reliability-index-analysis",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "This tutorial will serve as a Guide to Enhanced Reliability Estimation with R\n\n\nReliability refers to the consistency and precision of measurement instruments. In psychological testing, it assesses the extent to which a test produces stable and consistent results.\n\n\nMeasurement Precision: Ensures that the scores accurately reflect the true attributes being measured.\nResearch Validity: High reliability is a prerequisite for valid conclusions and replicable research findings.\nError Reduction: Minimizes the impact of random errors, enhancing the clarity of observed relationships between constructs.\n\n\n\nInternal Consistency: Degree to which items within a test measure the same construct.\nTest-Retest Reliability: Consistency of scores over time.\nInter-Rater Reliability: Agreement between different raters or observers."
  },
  {
    "objectID": "index.html#classical-test-theory-ctt-and-coefficient-alpha",
    "href": "index.html#classical-test-theory-ctt-and-coefficient-alpha",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "Classical Test Theory Overview: CTT posits that each observed score is composed of a true score and an error score:\n\\[ X = T + E \\]\nwhere:\nùëã= Observed score ùëá= True score ùê∏= Error score\n\n\nThis is a widely used measure of internal consistency reliability within CTT. It estimates the extent to which items on a test measure the same underlying construct.\n\\[\n\\alpha = \\frac{N}{N-1} \\left(1 - \\frac{\\sum \\sigma^2_{E}}{\\sigma^2_{X}}\\right)\n\\]\nWhere:\n\\(\\alpha\\) = Cronbach‚Äôs Alpha\nùëÅ = Number of items in the test\n\\(\\sigma^2_{E}\\) = Variance of the error scores\n\\(\\sigma^2_{X}\\) = Variance of the observed total scores\n\n\nUnidimensionality: All items measure a single construct.\nTau Equivalence: Each item has the same true score variance.\nIndependence of Errors: Error terms are uncorrelated across items.\n\n\n\nSensitivity to Tau Equivalence: Violations can lead to underestimation or overestimation of reliability.\nAssumes Unidimensionality: Not suitable for multidimensional scales without adjustments.\nIgnores Factor Structure: Does not account for the underlying factor model of the test.\n\n\n\n\nCoefficient Omega is a more robust alternative to Cronbach‚Äôs Alpha, especially when the assumption of tau-equivalence (equal factor loadings) is violated. Omega takes into account the factor structure of the test, making it suitable for both unidimensional and multidimensional scales.\n\n\nOmega Total (œâ‚Çú): Accounts for all common factors, both general and specific.\nOmega Hierarchical (œâ‚Çï): Represents the proportion of variance attributable to a general factor alone.\nOmega Total is given by:\n\\[\n\\omega_t = \\frac{\\sum_{i=1}^{k} \\lambda_i}{\\sum_{i=1}^{k} \\lambda_i + \\sum_{i=1}^{k} \\theta_i}\n\\]\nWhere:\n\\(\\omega_t\\) = Omega Total\n\\(\\lambda_i\\) = Factor loading for item\n\\(\\theta_i\\) = Unique variance (error variance) for item\n\\(k\\) = Total number of items\nFor a hierarchical model, Omega Hierarchical is:\n\\[\n\\omega_h = \\frac{\\lambda_g^2}{\\lambda_g^2 + \\sum_{i=1}^{k} \\theta_i}\n\\]\nwhere:\n\\(\\omega_h\\) = Omega Hierarchical\n\\(\\lambda_g\\) = Factor loading of the general factor\n\\(\\theta_i\\) = Unique variance for item \\(i\\)\n\n\n\nFactor Structure Incorporation: Utilizes confirmatory factor analysis (CFA) to model the underlying structure.\nLess Sensitive to Tau Equivalence Violations: Provides more accurate reliability estimates when tau equivalence is not met.\nApplicability to Multidimensional Scales: Suitable for tests measuring multiple constructs."
  },
  {
    "objectID": "index.html#calculations-in-r",
    "href": "index.html#calculations-in-r",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "Here, I will walk through the step-by-step process of calculating Cronbach‚Äôs Alpha and Coefficient Omega using R.\nLoad the necessary packages.\n\npacman::p_load(psych,lavaan,semTools,tidyverse,semTools,psych,tidyverse,lavaan,rio)"
  },
  {
    "objectID": "index.html#simulating-dataset",
    "href": "index.html#simulating-dataset",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "Let‚Äôs simulate a unidimensional dataset representing responses to a psychological test with 10 items. Each item is assumed to load on a single underlying factor (the construct being measured).\n\nset.seed(999) #for reproducibility\n\n# Number of participants\nn &lt;- 200\n\n# Number of items\nk &lt;- 10\n\n# Simulate factor loadings\nlambda &lt;- rep(0.7, k)  # Equal loadings for simplicity\n\n# Simulate latent trait scores (true scores)\nlatent_trait &lt;- rnorm(n, mean = 0, sd = 1)\n\n# Simulate item responses with measurement error\n# Assuming unique variance (theta) = 1 - lambda^2\ntheta &lt;- 1 - lambda^2\n\n# Generate item responses\nitem_responses &lt;- matrix(NA, nrow = n, ncol = k)\nfor(i in 1:k){\n  item_responses[,i] &lt;- lambda[i] * latent_trait + rnorm(n, mean = 0, sd = sqrt(theta[i]))\n}\n\n# Convert to data frame and name the items\ntest_data &lt;- as.data.frame(item_responses)\ncolnames(test_data) &lt;- paste0(\"Item\", 1:k)\n\n#print the first few rows\nhead(test_data)\n\n       Item1      Item2      Item3      Item4      Item5       Item6\n1 -1.2556963  0.1350372  0.3267107 -0.4350214 -0.2341561 -0.55481802\n2  0.1676193 -0.5108128 -2.0763683 -2.3273491  0.6263964 -1.18749601\n3  0.8438537  0.6766952  0.7511039  0.7876390 -0.2862397  0.72385660\n4  0.5239119  0.5615599 -0.5887199 -0.6589739  0.8637441  0.96640344\n5  0.4627802 -0.5181453 -0.5907776 -0.2237230  0.4472270  0.39956550\n6  0.1496605 -0.4830604 -0.4002617 -0.6658249 -1.7279389 -0.05426333\n        Item7      Item8      Item9      Item10\n1  0.12906041  0.8743370  0.8313717 -1.89803952\n2  0.03811422  0.3958650 -0.9320266 -1.19657498\n3  0.59847277  0.6243699  1.0944689 -0.34952191\n4  0.26035818  1.8831289  0.4292459 -1.18586145\n5  0.87674212  0.1055399 -0.9695509  0.04756092\n6 -0.58928130 -0.1575603 -1.7274886 -1.21579287\n\n\nAs you can see, we have created a dataset (test_data) with 200 participants and 10 items. Each item response is a combination of the latent trait (latent_trait) and random measurement error. The items are designed to load equally on the latent trait for simplicity."
  },
  {
    "objectID": "index.html#calculating-cronbachs-alpha",
    "href": "index.html#calculating-cronbachs-alpha",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "Recall that Cronbach‚Äôs Alpha (Œ±) is a measure of internal consistency that measures how closely related a set of items are as a group.\n\n\n\n# Calculate Cronbach's Alpha using the psych package\n#alpha_result &lt;- psych::alpha(oppeness)\n\n# Print the result\n#print(alpha_result)\n\nBecause some items were negatively correlated with the first principal component, we probably should reverse them.\n\n# Reversing item O2 and O5\n\nq &lt;- c(\"O2\",\"O5\")\nreverse &lt;- function(x){\n  x.reversed &lt;- 7 +0 - x\n}\n\noppeness[, c(\"O2R\", \"O5R\")] &lt;- reverse(oppeness[,c(\"O2\",\"O5\")])\n\n# compare original and reversed responses\noppeness[1:6,]\n\n  O1 O2 O3 O4 O5 O2R O5R\n1  3  6  3  4  3   1   4\n2  4  2  4  3  3   5   4\n3  4  2  5  5  2   5   5\n4  3  3  4  3  5   4   2\n5  3  3  4  3  3   4   4\n6  4  3  5  6  1   4   6\n\n\nNow, we can compute the alpha\n\n# compute alpha coefficient \n\nalpha_result &lt;- psych::alpha(oppeness[, -c(2,5)])\n\n# Print the result\nprint(alpha_result)\n\n\nReliability analysis   \nCall: psych::alpha(x = oppeness[, -c(2, 5)])\n\n  raw_alpha std.alpha G6(smc) average_r S/N   ase mean   sd median_r\n       0.6      0.61    0.57      0.24 1.6 0.012  4.6 0.81     0.23\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.58   0.6  0.63\nDuhachek  0.58   0.6  0.63\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nO1       0.54      0.54    0.48      0.23 1.2    0.014 0.0087  0.23\nO3       0.50      0.50    0.44      0.20 1.0    0.015 0.0065  0.20\nO4       0.61      0.62    0.56      0.29 1.7    0.012 0.0040  0.29\nO2R      0.57      0.57    0.51      0.25 1.3    0.014 0.0077  0.21\nO5R      0.52      0.53    0.48      0.22 1.1    0.015 0.0109  0.21\n\n Item statistics \n       n raw.r std.r r.cor r.drop mean  sd\nO1  2726  0.61  0.65  0.51   0.39  4.8 1.1\nO3  2726  0.68  0.69  0.59   0.45  4.4 1.2\nO4  2726  0.50  0.52  0.29   0.22  4.9 1.2\nO2R 2726  0.66  0.60  0.44   0.34  4.3 1.6\nO5R 2726  0.67  0.66  0.52   0.42  4.5 1.3\n\nNon missing response frequency for each item\n       1    2    3    4    5    6 miss\nO1  0.01 0.04 0.08 0.22 0.33 0.33    0\nO3  0.03 0.05 0.10 0.28 0.34 0.20    0\nO4  0.02 0.05 0.06 0.17 0.32 0.39    0\nO2R 0.06 0.10 0.15 0.14 0.26 0.29    0\nO5R 0.02 0.07 0.13 0.19 0.32 0.27    0\n\n\nExplanation:\nraw_alpha: The Cronbach‚Äôs Alpha coefficient.\nstd.alpha: Standardized alpha, similar to raw_alpha.\nG6(smc): Generalizability theory estimate with squared multiple correlations.\naverage_r: Average inter-item correlation.\nS/N: Signal-to-noise ratio.\nase: Asymptotic standard error.\nConfidence Intervals: Lower and upper bounds for alpha.\nAs we can see, the Cronbach‚Äôs Alpha for the Openness items is 0.6, indicating strong internal consistency. The average inter-item correlation is 0.24, moderate and within psychological scales."
  },
  {
    "objectID": "index.html#performing-confirmatory-factor-analysis-cfa",
    "href": "index.html#performing-confirmatory-factor-analysis-cfa",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "Confirmatory Factor Analysis (CFA) is used to verify the factor structure of a set of observed variables. In our case, we assume a unidimensional structure.\n\n\nLet‚Äôs specify a one-factor model where all items load on a single latent factor.\n\n# Define a one-factor CFA model\ncfa_model &lt;- '\n  Factor1 =~ Item1 + Item2 + Item3 + Item4 + Item5 + \n             Item6 + Item7 + Item8 + Item9 + Item10\n'\n\n\n\n\nFit the Model Using lavaan:\n\n# Fit the CFA model\nfit &lt;- lavaan::cfa(model = cfa_model, data = test_data)\n\n# Summarize the fit\nsummary(fit, fit.measures = TRUE, standardized = TRUE)\n\nLength  Class   Mode \n     1 lavaan     S4 \n\n\nExplanation:\nEstimator: Maximum Likelihood (ML).\nTest Statistics: The Chi-square test is significant (ùëù&lt;0.001), indicating a poor fit.\nFit Indices:\nCFI (0.89): Below the acceptable threshold of 0.90.\nTLI (0.87): Below the acceptable threshold of 0.90.\nRMSEA (0.10): Indicates poor fit (acceptable is &lt;0.08).\nSRMR (0.12): Above the acceptable threshold of 0.08.\nInterpretation:\nThe one-factor model does not fit the data well based on these fit indices. This suggests that our simulated data may be multidimensional or that the factor loadings are not as expected.\nNote: Because we simulated data with equal loadings and a unidimensional structure, the poor fit indicates potential issues with our simulation parameters. For now, we can proceed with calculations, but in real scenarios, you may need to modify your model or review your data."
  },
  {
    "objectID": "index.html#confirmatory-factor-analysis-cfa",
    "href": "index.html#confirmatory-factor-analysis-cfa",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "Confirmatory Factor Analysis (CFA) is used to verify the factor structure of a set of observed variables. In our case, we assume a unidimensional structure.\n\n\nLet‚Äôs specify a one-factor model where all items load on a single latent factor.\n\n# Specify model\nmod1f &lt;- \"\nopenness =~ O1 + O2R + O3 + O4 + O5R\n\"\n\n\n\n\nFit the Model Using lavaan:\n\n#pacman::p_load(lavaan)\n# Estimate model\nfit.one.f &lt;- cfa(mod1f, data=oppeness, std.lv=T, missing='direct', \n             estimator='MLR')\n\n# The results can be viewed using the summary\n\nsummary(fit.one.f, fit.measures=T, standardized=T)\n\nlavaan 0.6-19 ended normally after 22 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        15\n\n  Number of observations                          2726\n  Number of missing patterns                         1\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                80.583      67.248\n  Degrees of freedom                                 5           5\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  1.198\n    Yuan-Bentler correction (Mplus variant)                       \n\nModel Test Baseline Model:\n\n  Test statistic                              1375.389    1049.226\n  Degrees of freedom                                10          10\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.311\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.945       0.940\n  Tucker-Lewis Index (TLI)                       0.889       0.880\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.946\n  Robust Tucker-Lewis Index (TLI)                            0.891\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -22078.661  -22078.661\n  Scaling correction factor                                  1.167\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)     -22038.369  -22038.369\n  Scaling correction factor                                  1.174\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                               44187.322   44187.322\n  Bayesian (BIC)                             44275.980   44275.980\n  Sample-size adjusted Bayesian (SABIC)      44228.321   44228.321\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.074       0.068\n  90 Percent confidence interval - lower         0.061       0.055\n  90 Percent confidence interval - upper         0.089       0.081\n  P-value H_0: RMSEA &lt;= 0.050                    0.002       0.012\n  P-value H_0: RMSEA &gt;= 0.080                    0.280       0.066\n                                                                  \n  Robust RMSEA                                               0.074\n  90 Percent confidence interval - lower                     0.058\n  90 Percent confidence interval - upper                     0.090\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.006\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.285\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.029       0.029\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  openness =~                                                           \n    O1                0.616    0.029   21.346    0.000    0.616    0.546\n    O2R               0.701    0.041   17.170    0.000    0.701    0.449\n    O3                0.792    0.032   24.649    0.000    0.792    0.649\n    O4                0.357    0.030   11.749    0.000    0.357    0.294\n    O5R               0.685    0.036   19.194    0.000    0.685    0.517\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .O1                4.819    0.022  223.110    0.000    4.819    4.273\n   .O2R               4.300    0.030  143.782    0.000    4.300    2.754\n   .O3                4.439    0.023  189.916    0.000    4.439    3.637\n   .O4                4.898    0.023  210.231    0.000    4.898    4.027\n   .O5R               4.516    0.025  177.976    0.000    4.516    3.409\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .O1                0.893    0.037   23.923    0.000    0.893    0.702\n   .O2R               1.947    0.068   28.607    0.000    1.947    0.798\n   .O3                0.862    0.050   17.172    0.000    0.862    0.579\n   .O4                1.352    0.052   25.967    0.000    1.352    0.914\n   .O5R               1.286    0.059   21.822    0.000    1.286    0.732\n    openness          1.000                               1.000    1.000\n\n\nExplanation:\nEstimator: Maximum Likelihood (ML).\nTest Statistics: The Chi-square test is significant (ùëù&lt;0.001), indicating a poor fit.\nFit Indices:\nCFI (0.94): above 0.90.\nTLI (0.88): Below the threshold of 0.90.\nRMSEA (0.068): Indicates relatively weak fit (‚â•0.05).\nSRMR (0.029): Great fit (‚â§0.08).\n\nresiduals(fit.one.f, type='cor')\n\n$type\n[1] \"cor.bollen\"\n\n$cov\n        O1    O2R     O3     O4    O5R\nO1   0.000                            \nO2R -0.026  0.000                     \nO3   0.037 -0.024  0.000              \nO4   0.013 -0.052  0.000  0.000       \nO5R -0.044  0.090 -0.022  0.027  0.000\n\n$mean\n O1 O2R  O3  O4 O5R \n  0   0   0   0   0 \n\n\nThe fit statistics from the Robust column in the summary suggest that this one-factor model provides a moderate fit to the data. While the Comparative Fit Index (CFI) of 0.94 indicates an acceptable fit, the Tucker-Lewis Index (TLI) of 0.88 is relatively lower, and the Root Mean Square Error of Approximation (RMSEA) is relatively high at 0.08.\nThe factor loadings (ùúÜÃÇ) show significant variation, ranging from 0.357 to 0.792, which implies that the assumption of equal loadings (tau equivalence) does not hold for this openness test. As a result, omega (œâu) should be a more suitable measure of reliability than Cronbach‚Äôs alpha. We can compute the œâu estimate by running the reliability function from the semTools package on the one-factor model object (fit1f).\n\nreliability(fit.one.f)\n\n        openness\nalpha  0.6025464\nomega  0.6103741\nomega2 0.6103741\nomega3 0.6098642\navevar 0.2484010\n\n\nomega and omega2 measure reliability based on the variance expected by the model, while omega3 measures it based on the actual variance seen in your data. The small difference between omega and omega3 suggests that the model‚Äôs predictions of variance are somewhat close to what‚Äôs observed in the sample."
  },
  {
    "objectID": "index.html#calculating-coefficient-omega",
    "href": "index.html#calculating-coefficient-omega",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "Recall that Coefficient Omega (œâ) is a reliability estimate that accounts for the factor structure of the test, providing a more accurate measure than Cronbach‚Äôs Alpha, especially in the presence of multidimensionality or when tau-equivalence is violated.\n#Categorical omega\nI fitted the one-factor model to the interitem polychoric correlations using WLSMV, a robust weighted least squares estimator that is recommended over the ML estimator for CFA with polychoric correlations.\n\n# read in data\nlibrary(rio)\npotic &lt;- import(\"potic.csv\")\n\n# Specify model\nmod.one.fCat &lt;- 'psyctcsm =~ DDP1 + DDP2 +\nDDP3 + DDP4'\n\n\n# Estimate model\nfit.one.fCat &lt;- cfa(mod.one.fCat, data=potic, std.lv=TRUE, ordered=T, estimator='WLSMV')\n\n# Retrieving the results\nsummary(fit.one.fCat, fit.measures=TRUE, standardized=TRUE)\n\nlavaan 0.6-19 ended normally after 10 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        20\n\n                                                  Used       Total\n  Number of observations                           498         500\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                 7.117      14.910\n  Degrees of freedom                                 2           2\n  P-value (Chi-square)                           0.028       0.001\n  Scaling correction factor                                  0.480\n  Shift parameter                                            0.089\n    simple second-order correction                                \n\nModel Test Baseline Model:\n\n  Test statistic                              1635.647    1316.086\n  Degrees of freedom                                 6           6\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.244\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.997       0.990\n  Tucker-Lewis Index (TLI)                       0.991       0.970\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.969\n  Robust Tucker-Lewis Index (TLI)                            0.908\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.072       0.114\n  90 Percent confidence interval - lower         0.020       0.065\n  90 Percent confidence interval - upper         0.132       0.171\n  P-value H_0: RMSEA &lt;= 0.050                    0.200       0.019\n  P-value H_0: RMSEA &gt;= 0.080                    0.479       0.880\n                                                                  \n  Robust RMSEA                                               0.147\n  90 Percent confidence interval - lower                     0.089\n  90 Percent confidence interval - upper                     0.213\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.004\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.970\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.033       0.033\n\nParameter Estimates:\n\n  Parameterization                               Delta\n  Standard errors                           Robust.sem\n  Information                                 Expected\n  Information saturated (h1) model        Unstructured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  psyctcsm =~                                                           \n    DDP1              0.894    0.028   31.538    0.000    0.894    0.894\n    DDP2              0.753    0.028   26.711    0.000    0.753    0.753\n    DDP3              0.698    0.030   23.314    0.000    0.698    0.698\n    DDP4              0.513    0.040   12.738    0.000    0.513    0.513\n\nThresholds:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    DDP1|t1          -0.716    0.062  -11.591    0.000   -0.716   -0.716\n    DDP1|t2          -0.040    0.056   -0.716    0.474   -0.040   -0.040\n    DDP1|t3           0.296    0.057    5.185    0.000    0.296    0.296\n    DDP1|t4           1.034    0.069   15.065    0.000    1.034    1.034\n    DDP2|t1          -0.580    0.060   -9.693    0.000   -0.580   -0.580\n    DDP2|t2           0.208    0.057    3.668    0.000    0.208    0.208\n    DDP2|t3           0.562    0.060    9.431    0.000    0.562    0.562\n    DDP2|t4           1.096    0.070   15.570    0.000    1.096    1.096\n    DDP3|t1          -1.203    0.074  -16.298    0.000   -1.203   -1.203\n    DDP3|t2          -0.425    0.058   -7.318    0.000   -0.425   -0.425\n    DDP3|t3           0.081    0.056    1.432    0.152    0.081    0.081\n    DDP3|t4           0.913    0.066   13.909    0.000    0.913    0.913\n    DDP4|t1          -1.605    0.092  -17.382    0.000   -1.605   -1.605\n    DDP4|t2          -1.060    0.069  -15.285    0.000   -1.060   -1.060\n    DDP4|t3          -0.521    0.059   -8.817    0.000   -0.521   -0.521\n    DDP4|t4           0.431    0.058    7.406    0.000    0.431    0.431\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .DDP1              0.201                               0.201    0.201\n   .DDP2              0.433                               0.433    0.433\n   .DDP3              0.513                               0.513    0.513\n   .DDP4              0.737                               0.737    0.737\n    psyctcsm          1.000                               1.000    1.000"
  },
  {
    "objectID": "index.html#loading-the-bfi-dataset",
    "href": "index.html#loading-the-bfi-dataset",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "The Big Five Inventory (BFI) is a widely used dataset in personality psychology, measuring the five major dimensions of personality. We‚Äôll focus on the Openness trait for this tutorial.\n\n# Make sure you've loaded the psych package\n\n\n# Load the BFI dataset\ndata(bfi)\n\n# load data file\nbfi &lt;- bfi\nnames(bfi)\n\n [1] \"A1\"        \"A2\"        \"A3\"        \"A4\"        \"A5\"        \"C1\"       \n [7] \"C2\"        \"C3\"        \"C4\"        \"C5\"        \"E1\"        \"E2\"       \n[13] \"E3\"        \"E4\"        \"E5\"        \"N1\"        \"N2\"        \"N3\"       \n[19] \"N4\"        \"N5\"        \"O1\"        \"O2\"        \"O3\"        \"O4\"       \n[25] \"O5\"        \"gender\"    \"education\" \"age\"      \n\n# View the structure of the dataset\n#str(bfi)\n\nThe dataset contains 2,800 participants with various demographic and personality-related variables. A1 to A5 correspond to items measuring the Openness trait.\n\n\nFor this tutorial, we‚Äôll focus on five items measuring the Openness trait. These items are typically labeled as A1 to A5 in the BFI dataset.\n\n\n\n# Select columns that contain \"O\" in their names and remove rows with NA values\noppeness &lt;- bfi %&gt;%\n  select(matches(\"^O\")) %&gt;%\n  drop_na()\n\nhead(oppeness)\n\n  O1 O2 O3 O4 O5\n1  3  6  3  4  3\n2  4  2  4  3  3\n3  4  2  5  5  2\n4  3  3  4  3  5\n5  3  3  4  3  3\n6  4  3  5  6  1\n\n\nEach A variable represents a Likert-type item measuring Openness. Responses range from 1 to 6, treated as continuous variables for analysis.\n\n\n\n\nBefore we continue, let‚Äôs check any missing data.\n\n# Check for missing values\nsum(is.na(oppeness))\n\n[1] 0\n\n\nIn this dataset, there are no missing values in the Openness items. If missing values were present, then we need to address that."
  },
  {
    "objectID": "index.html#calculating-categorical-omega",
    "href": "index.html#calculating-categorical-omega",
    "title": "EDUC 6003 Advanced Statistics",
    "section": "",
    "text": "Recall that Coefficient Omega (œâ) is a reliability estimate that accounts for the factor structure of the test, providing a more accurate measure than Cronbach‚Äôs Alpha, especially in the presence of multidimensionality or when tau-equivalence is violated.\nSince factor loadings derived from polychoric correlations represent the link between the factor and the underlying latent response variables (not the actual responses from the items), using the œâu formula here would tell us how much of the variance in the latent response variables is explained by the factor. However, this doesn‚Äôt reflect the true variance in the sum of the observed item responses. Essentially, in this case, œâu would give us the reliability of a hypothetical total score based on the latent variables rather than the actual observed total score.\nTo correct for this, Green and Yang (2009b) proposed a new reliability estimate called œâu-cat, which adjusts the reliability calculation to align with the observed total score. This estimate is more accurate for unidimensional scales with categorical items, especially when the response patterns vary across items.\nSince the psychoticism items use a 4-point rating scale, I fit the one-factor model using polychoric correlations and the WLSMV estimator (weighted least squares with mean and variance adjustment). This approach is recommended for confirmatory factor analysis involving polychoric correlations, as it is more robust than the maximum likelihood (ML) estimator.\n\n#load the data\npotic &lt;- import(\"potic.csv\")\n\n# Specify model\nmod.one.fCat &lt;- 'psyctcsm =~ DDP1 + DDP2 +\nDDP3 + DDP4'\n\n\n# Estimate model\nfit.one.fCat &lt;- cfa(mod.one.fCat, data=potic, std.lv=TRUE, ordered=T, estimator='WLSMV')\n\n# Retrieving the results\nsummary(fit.one.fCat, fit.measures=TRUE, standardized=TRUE)\n\nlavaan 0.6-19 ended normally after 10 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        20\n\n                                                  Used       Total\n  Number of observations                           498         500\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                 7.117      14.910\n  Degrees of freedom                                 2           2\n  P-value (Chi-square)                           0.028       0.001\n  Scaling correction factor                                  0.480\n  Shift parameter                                            0.089\n    simple second-order correction                                \n\nModel Test Baseline Model:\n\n  Test statistic                              1635.647    1316.086\n  Degrees of freedom                                 6           6\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.244\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.997       0.990\n  Tucker-Lewis Index (TLI)                       0.991       0.970\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.969\n  Robust Tucker-Lewis Index (TLI)                            0.908\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.072       0.114\n  90 Percent confidence interval - lower         0.020       0.065\n  90 Percent confidence interval - upper         0.132       0.171\n  P-value H_0: RMSEA &lt;= 0.050                    0.200       0.019\n  P-value H_0: RMSEA &gt;= 0.080                    0.479       0.880\n                                                                  \n  Robust RMSEA                                               0.147\n  90 Percent confidence interval - lower                     0.089\n  90 Percent confidence interval - upper                     0.213\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.004\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.970\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.033       0.033\n\nParameter Estimates:\n\n  Parameterization                               Delta\n  Standard errors                           Robust.sem\n  Information                                 Expected\n  Information saturated (h1) model        Unstructured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  psyctcsm =~                                                           \n    DDP1              0.894    0.028   31.538    0.000    0.894    0.894\n    DDP2              0.753    0.028   26.711    0.000    0.753    0.753\n    DDP3              0.698    0.030   23.314    0.000    0.698    0.698\n    DDP4              0.513    0.040   12.738    0.000    0.513    0.513\n\nThresholds:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    DDP1|t1          -0.716    0.062  -11.591    0.000   -0.716   -0.716\n    DDP1|t2          -0.040    0.056   -0.716    0.474   -0.040   -0.040\n    DDP1|t3           0.296    0.057    5.185    0.000    0.296    0.296\n    DDP1|t4           1.034    0.069   15.065    0.000    1.034    1.034\n    DDP2|t1          -0.580    0.060   -9.693    0.000   -0.580   -0.580\n    DDP2|t2           0.208    0.057    3.668    0.000    0.208    0.208\n    DDP2|t3           0.562    0.060    9.431    0.000    0.562    0.562\n    DDP2|t4           1.096    0.070   15.570    0.000    1.096    1.096\n    DDP3|t1          -1.203    0.074  -16.298    0.000   -1.203   -1.203\n    DDP3|t2          -0.425    0.058   -7.318    0.000   -0.425   -0.425\n    DDP3|t3           0.081    0.056    1.432    0.152    0.081    0.081\n    DDP3|t4           0.913    0.066   13.909    0.000    0.913    0.913\n    DDP4|t1          -1.605    0.092  -17.382    0.000   -1.605   -1.605\n    DDP4|t2          -1.060    0.069  -15.285    0.000   -1.060   -1.060\n    DDP4|t3          -0.521    0.059   -8.817    0.000   -0.521   -0.521\n    DDP4|t4           0.431    0.058    7.406    0.000    0.431    0.431\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .DDP1              0.201                               0.201    0.201\n   .DDP2              0.433                               0.433    0.433\n   .DDP3              0.513                               0.513    0.513\n   .DDP4              0.737                               0.737    0.737\n    psyctcsm          1.000                               1.000    1.000\n\n\n\n# Estimate reliability\n\nreliability(fit.one.fCat)\n\nFor constructs with categorical indicators, Zumbo et al.`s (2007) \"ordinal alpha\" is calculated in addition to the standard alpha, which treats ordinal variables as numeric. See Chalmers (2018) for a critique of \"alpha.ord\" and the response by Zumbo & Kroc (2019). Likewise, average variance extracted is calculated from polychoric (polyserial) not Pearson correlations.\n\n\n           psyctcsm\nalpha     0.7680870\nalpha.ord 0.8007496\nomega     0.7902953\nomega2    0.7902953\nomega3    0.7932682\navevar    0.5289638\n\n\nWe can see that we have two estimates Cronbach‚Äôs alpha and differ a bit (0.80 & 0.77). The is because the 2nd alpha estimate is an example of ordinal alpha, which is calculated using a model based on polychoric correlations, while the first alpha was derived using the standard method based on product-moment covariances between the items. It‚Äôs important to note that ordinal alpha measures the reliability of the sum of the continuous, latent-response variables rather than the observed categorical item responses. Additionally, it still assumes equal factor loadings (tau equivalence). Because of these limitations, I suggest disregarding the alpha value reported by semTools::reliability when the model uses polychoric correlations.\nThe values shown in the omega and omega2 rows represent the œâu-cat estimate. The omega3 row shows a variation where the denominator uses the observed sample variance of ( X ). So, we can see œâu-cat estimates suggest that 79% of the variance in the total score for the psychoticism scale is explained by the single psychoticism factor."
  }
]